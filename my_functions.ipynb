{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6a53b5",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b07e47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-28T06:22:27.421103Z",
     "start_time": "2022-05-28T06:22:27.399139Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "import pandas as pd\n",
    "import pygsheets, math\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import pymysql as sql\n",
    "from datetime import date,timedelta\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def getDataFromSheets(workBookName, worksheetName, colStart = None, colEnd = None, authorisToken = r'/Users/shubham_mantri/Downloads/coastal-airlock-315709-d614c773b55d.json'):\n",
    "    \"\"\"\n",
    "    This function will return the worksheet as dataframe.\n",
    "    \"\"\"\n",
    "    workSheetData = None\n",
    "    print(f\"Getting data from sheet {workBookName}...\")\n",
    "    \n",
    "    try:\n",
    "        Connection = pygsheets.authorize(service_file = authorisToken)\n",
    "        workBook = Connection.open(workBookName)\n",
    "        workSheet = workBook.worksheet_by_title(worksheetName)\n",
    "        workSheetData = workSheet.get_as_df(start = colStart, end = colEnd)\n",
    "        print(f\"Data Fetched from workBook:{workBookName} > WorkSheet:{worksheetName}...\")\n",
    "    \n",
    "    except Exception as E:\n",
    "        print(E)\n",
    "    \n",
    "    return workSheetData\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def insertDataIntoSheets(data, workBookName, worksheetName, colStart = None, colEnd = None,start=(1,1), authorisToken = r'/Users/shubham_mantri/Downloads/coastal-airlock-315709-d614c773b55d.json'):\n",
    "    \"\"\"\n",
    "    This function will insert add the data of dataframe to the given sheet.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Inserting data into sheet {workBookName}...\")\n",
    "        Connection = pygsheets.authorize(service_file = authorisToken)\n",
    "        workBook = Connection.open(workBookName)\n",
    "        workSheet = workBook.worksheet_by_title(worksheetName)\n",
    "        workSheet.clear(start = colStart, end = colEnd)\n",
    "        workSheet.set_dataframe(data, start=start,copy_index=False)\n",
    "        print(f\"Data inserted into workBook:{workBookName} > WorkSheet:{worksheetName}...\")\n",
    "    \n",
    "    except Exception as E:\n",
    "        print(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa5f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T17:45:31.816671Z",
     "start_time": "2022-05-23T17:45:30.922417Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/shubham_mantri/Downloads/RTO Till 05-04-2022.csv\")\n",
    "\n",
    "df = df.loc[df['payment_method']=='cod',:]\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "df['complete_address'] = df['customer_address'] +' '+ df['customer_address_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da60e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T17:45:32.894651Z",
     "start_time": "2022-05-23T17:45:32.882768Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25a904",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c7159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T17:44:09.515938Z",
     "start_time": "2022-05-23T17:44:09.195256Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.corpus import brown\n",
    "from english_words import english_words_set\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d03adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def feature_extraction(df):\n",
    "    def complete_address(address1,address2):\n",
    "        return ((str(address1) if not pd.isna(address1) else \"\") + (\" \" if not (pd.isna(address2) or pd.isna(address1)) else \"\") + (str(address2) if not pd.isna(address2) else \"\"))\n",
    "    df['complete_address'] = df.apply(lambda x: complete_address(x['address_line_1'],x['address_line_2']),axis=1)\n",
    "    df['order_placed_date']=pd.to_datetime(df['order_placed_date'],errors='coerce')\n",
    "    df['expected_delivery_date'] = pd.to_datetime(df['expected_delivery_date'],errors='coerce')\n",
    "    df['order_placed_date']=pd.to_datetime(df['order_placed_date'],errors='coerce')\n",
    "    def get_regex_features(s):\n",
    "        s = str(s)\n",
    "        l = len(s)\n",
    "        numbers = sum(c.isdigit() for c in s)\n",
    "        letters = sum(c.isalpha() for c in s)\n",
    "        spaces  = sum(c.isspace() for c in s)\n",
    "        others  = len(s) - numbers - letters - spaces\n",
    "        num_pc = numbers/l\n",
    "        ltr_pc = letters/l\n",
    "        spc_pc = spaces/l\n",
    "        otr_pc = others/l\n",
    "        num_unique_chars = len(set(list(s)))\n",
    "        pc_unique_chars_to_len = num_unique_chars/l\n",
    "        return numbers, letters, spaces, others, num_pc, ltr_pc, spc_pc, otr_pc, num_unique_chars, pc_unique_chars_to_len\n",
    "\n",
    "    def get_tokens(s):\n",
    "        s = str(s)\n",
    "        pattern = re.compile(r'\\W+') # split at space and spl. char\n",
    "        tokens = pattern.split(s)\n",
    "        return '_'.join(tokens)\n",
    "\n",
    "    def get_avg_token_len(t):\n",
    "        tokens = t.split('_')\n",
    "        res = sum(map(len, tokens))/float(len(tokens))\n",
    "        return res\n",
    "\n",
    "    def remove_ints_from_tokens(tokens):\n",
    "        tokens = list(filter(None, tokens))\n",
    "\n",
    "        is_integer = lambda s: s.isdigit() or (s[0] == '-' and s[1:].isdigit())\n",
    "        no_integers = list(filter(is_integer, tokens))\n",
    "        tokens_no_ints = [x for x in tokens if x not in no_integers]\n",
    "\n",
    "        return tokens_no_ints\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    addr_cols = ['complete_address']\n",
    "\n",
    "    for col in addr_cols:\n",
    "        col_name = col + '_tokens'\n",
    "        df[col_name] = df[col].apply(lambda x: get_tokens(x))\n",
    "    \n",
    "    for col in addr_cols:\n",
    "        col_name = col + '_len'\n",
    "        df[col_name] = df[col].apply(lambda x: len(x) if not pd.isna(x) else 0)\n",
    "    \n",
    "\n",
    "    for col in addr_cols:\n",
    "        num = col + '_len_number'\n",
    "        ltr = col + '_len_letter'\n",
    "        spc = col + '_len_space'\n",
    "        otr = col + '_len_others'\n",
    "        num_pc = col + '_len_number_pc'\n",
    "        ltr_pc = col + '_len_letter_pc'\n",
    "        spc_pc = col + '_len_space_pc'\n",
    "        otr_pc = col + '_len_others_pc'\n",
    "        num_unique_chars = col + '_num_unique_chars'\n",
    "        pc_unique_chars_to_len = col +'_pc_unique_chars_to_len'\n",
    "        df[[num, ltr, spc, otr,num_pc, ltr_pc, spc_pc, otr_pc, num_unique_chars, pc_unique_chars_to_len ]] = df[[col]].apply(get_regex_features, axis = 1,  result_type='expand')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_avg_token_len(t):\n",
    "        tokens = t.split('_')\n",
    "        res = sum(map(len, tokens))/float(len(tokens))\n",
    "        return res\n",
    "\n",
    "    for col in addr_cols:\n",
    "        col_name = col + '_avg_token_len'\n",
    "        df[col_name] = df[col + '_tokens'].apply(get_avg_token_len)\n",
    "\n",
    "\n",
    "    def get_num_unique_tokens(t):\n",
    "        tokens = t.split('_')\n",
    "        tokens = list(filter(None, tokens))\n",
    "\n",
    "        is_integer = lambda s: s.isdigit() or (s[0] == '-' and s[1:].isdigit())\n",
    "        no_integers = list(filter(is_integer, tokens))\n",
    "        tokens_no_ints = [x for x in tokens if x not in no_integers]\n",
    "\n",
    "        num_unique_tokens = len(set(tokens_no_ints))\n",
    "        return num_unique_tokens\n",
    "\n",
    "    def get_pc_unique_tokens_to_total_tokens(t):\n",
    "        tokens = t.split('_')\n",
    "        tokens = list(filter(None, tokens))\n",
    "\n",
    "        is_integer = lambda s: s.isdigit() or (s[0] == '-' and s[1:].isdigit())\n",
    "        no_integers = list(filter(is_integer, tokens))\n",
    "        tokens_no_ints = [x for x in tokens if x not in no_integers]\n",
    "\n",
    "        num_unique_tokens = len(set(tokens_no_ints))\n",
    "\n",
    "        try:\n",
    "            pc_unique_tokens_to_total_tokens = num_unique_tokens/len(set(tokens))\n",
    "        except ZeroDivisionError:\n",
    "            pc_unique_tokens_to_total_tokens = 0\n",
    "\n",
    "        return pc_unique_tokens_to_total_tokens\n",
    "\n",
    "    for col in addr_cols:\n",
    "        nut = col + '_num_unique_tokens'\n",
    "        pc = col + '_pc_unique_tokens_to_total_tokens'\n",
    "        df[nut] = df[col + '_tokens'].apply(get_num_unique_tokens)\n",
    "        df[pc] = df[col + '_tokens'].apply(get_pc_unique_tokens_to_total_tokens)\n",
    "\n",
    "    def unique_alphabets_count(address):\n",
    "        if type(address) == str:\n",
    "            return len(set(address))\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def unique_alphabets_count_pct(address):\n",
    "        if type(address) == str:\n",
    "            return (len(set(address))/len(address) if len(address)>0 else 0)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df['unique_alphabets_count'] = df.apply(lambda x: unique_alphabets_count(x['complete_address']),axis=1)\n",
    "    df['unique_alphabets_count_pct'] = df.apply(lambda x: unique_alphabets_count_pct(x['complete_address']),axis=1)\n",
    "\n",
    "    def comma_count(address):\n",
    "        if pd.isna(address):\n",
    "            return 0\n",
    "        x = re.findall(\"[,]\",address)\n",
    "        return len(x)\n",
    "\n",
    "\n",
    "    df['comma_count'] = df.apply(lambda x: comma_count(x['complete_address']),axis=1)\n",
    "\n",
    "    def vowel_count(address):\n",
    "        if pd.isna(address):\n",
    "            return 0\n",
    "        return len(re.findall(\"[aeiou]\",address))\n",
    "\n",
    "    def vowel_pct(address):\n",
    "        if pd.isna(address):\n",
    "            return 0\n",
    "        return (round(vowel_count(address)/len(address),2) if len(address)>0 else 0)\n",
    "\n",
    "\n",
    "\n",
    "    df['vowel_count'] = df.apply(lambda x: vowel_count(x['complete_address']),axis=1)\n",
    "    df['vowel_pct'] = df.apply(lambda x: vowel_pct(x['complete_address']),axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    def past_rto_count_mob_number(mob_no):\n",
    "        return df.loc[(df['consignee_mob_no']==mob_no)&(df['rto_or_not']==1),:].shape[0]\n",
    "\n",
    "    def past_rto_pct_mob_number(mob_no):\n",
    "        return past_rto_count_mob_number(mob_no)/df.loc[(df['consignee_mob_no']==mob_no),:].shape[0] if past_rto_count_mob_number(mob_no)>0 else 0\n",
    "\n",
    "    df['past_rto_count_mob_number'] = df.apply(lambda x: past_rto_count_mob_number(x['consignee_mob_no']),axis=1)\n",
    "    df['past_rto_pct_mob_number'] = df.apply(lambda x: past_rto_pct_mob_number(x['consignee_mob_no']),axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def special_character_count(address):\n",
    "        if pd.isna(address):\n",
    "            return 0\n",
    "        return len(re.findall(\"[@_!#$%^&*()<>?/|}{~]\",address))\n",
    "\n",
    "    def special_character_pct(address):\n",
    "        if pd.isna(address):\n",
    "            return 0\n",
    "        return len(re.findall(\"[@_!#$%^&*()<>?/|}{~]\",address))/len(address) if len(address)>0 else 0\n",
    "\n",
    "    df['special_character_count'] = df.apply(lambda x: special_character_count(x['complete_address']),axis=1)\n",
    "    df['special_character_pct'] = df.apply(lambda x: special_character_pct(x['complete_address']),axis=1)\n",
    "\n",
    "    def pin_check(pin):\n",
    "        pin = \"\".join([i for i in str(pin) if str(i).isnumeric()])\n",
    "    #     pin = str(pin).strip()\n",
    "        if str(pin).isnumeric()==False:\n",
    "            return 0\n",
    "        if len(str(pin))!=6:\n",
    "            return 0\n",
    "        if int(str(pin)[0])==0:\n",
    "            return 0\n",
    "        if int(str(pin)[0:2]) in [10,29,35,54,55,65,66,86,87,88,89]:\n",
    "            return 0\n",
    "        return 1\n",
    "            \n",
    "    df['pin_check'] = df.apply(lambda x: pin_check(x['consignee_pincode']),axis=1)\n",
    "\n",
    "    def email_check(email):\n",
    "        if pd.isna(email):\n",
    "            return 1\n",
    "        x = re.findall(\"[^@]+@[^@]+\\.[^@]+\",email)\n",
    "        if x:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df['email_check'] = df.apply(lambda x: email_check(x['consignee_email']),axis=1)\n",
    "\n",
    "    def name_check(name):\n",
    "        if name.isalpha() and len(name)>=3:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df['name_check'] = df.apply(lambda x: name_check(x['consignee_name']),axis=1)\n",
    "\n",
    "    import difflib\n",
    "\n",
    "    import fuzzywuzzy\n",
    "    from fuzzywuzzy import fuzz\n",
    "\n",
    "    def match_1(address_line_1,address_line_2):\n",
    "        if pd.isna(address_line_1) or pd.isna(address_line_2):\n",
    "            return 1\n",
    "        return difflib.SequenceMatcher(None,str(address_line_1),str(address_line_2)).ratio()\n",
    "\n",
    "    def match_2(address_line_1,address_line_2):\n",
    "        if pd.isna(address_line_1) or pd.isna(address_line_2):\n",
    "            return 1\n",
    "        return fuzz.partial_ratio(str(address_line_1),str(address_line_2))\n",
    "\n",
    "    df['match_1'] = df.apply(lambda x: match_1(x['address_line_1'],x['address_line_2']),axis=1)\n",
    "    df['match_2'] = df.apply(lambda x: match_2(x['address_line_1'],x['address_line_2']),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    def aplha_numeric(word):\n",
    "        x = re.findall(\"[a-z]\",word.lower())\n",
    "        y = re.findall(\"[0-9]\",word.lower())\n",
    "        if len(x)>=1 and len(y)>=1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def alpha_numeric_count(line):\n",
    "        if pd.isna(line):\n",
    "            return 0\n",
    "        total = 0 \n",
    "        for word in line.split(\" \"):\n",
    "            if aplha_numeric(word)==1:\n",
    "                total+=1\n",
    "        return total\n",
    "\n",
    "\n",
    "    df['alpha_numeric_count'] = df.apply(lambda x: alpha_numeric_count(x['complete_address']),axis=1)  \n",
    "\n",
    "    def alpha_numeric_pct(line):\n",
    "        if pd.isna(line):\n",
    "            return 0\n",
    "        return round(alpha_numeric_count(line)/len(line.split(\" \")),2) if len(line.split(\" \"))>0 else 0\n",
    "\n",
    "    df['alpha_numeric_count'] = df.apply(lambda x: alpha_numeric_count(x['complete_address']),axis=1) \n",
    "\n",
    "\n",
    "\n",
    "    all_tokens_list = df['complete_address_tokens'].to_list()\n",
    "    all_tokens = []\n",
    "    for li in all_tokens_list:\n",
    "        tos = remove_ints_from_tokens(li.split('_'))\n",
    "        for t in tos:\n",
    "            all_tokens.append(t.lower())\n",
    "    import collections\n",
    "    import math\n",
    "\n",
    "    def get_top_tokens(ds):\n",
    "        all_tokens_list = ds.to_list()\n",
    "        all_tokens = []\n",
    "        for li in all_tokens_list:\n",
    "            tos = remove_ints_from_tokens(li.split('_'))\n",
    "            for t in tos:\n",
    "                all_tokens.append(t.lower())\n",
    "\n",
    "        freq = collections.Counter(all_tokens)\n",
    "        freq = dict(freq)\n",
    "        sorted_freq = sorted(freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        top_tokens = sorted_freq[0 : math.floor(len(sorted_freq) * 0.1)]\n",
    "\n",
    "        return top_tokens\n",
    "    df_del = df.loc[df['current_status'] == 'DELIVERED']\n",
    "    df_rto = df.loc[df['current_status'].isin(rto_status_list)]\n",
    "    top_tokens_all = get_top_tokens(df['complete_address_tokens'])\n",
    "    top_tokens_del = get_top_tokens(df_del['complete_address_tokens'])\n",
    "    top_tokens_rto = get_top_tokens(df_rto['complete_address_tokens'])\n",
    "    def intersection(lst1, lst2):\n",
    "        return list(set(lst1) & set(lst2))\n",
    "\n",
    "    # l1 = []\n",
    "    # l2 = []\n",
    "    # for i in range(len(top_tokens_del)):\n",
    "    #     l1.append(top_tokens_del[i][0])\n",
    "\n",
    "    # for i in range(len(top_tokens_rto)):\n",
    "    #     l2.append(top_tokens_rto[i][0])\n",
    "\n",
    "    # print(len(intersection(l1, l2)))\n",
    "    # len(top_tokens_del), len(top_tokens_rto)\n",
    "    \n",
    "    def get_num_tokens(t):\n",
    "        t = t.split('_')\n",
    "        return len(t)\n",
    "\n",
    "    for col in addr_cols:\n",
    "        col_name = col + '_num_tokens'\n",
    "        df[col_name] = df[col + '_tokens'].apply(get_num_tokens)\n",
    "        \n",
    "    def get_num_common_tokens(t, l):\n",
    "        l1 = []\n",
    "        for i in range(len(l)):\n",
    "            l1.append(l[i][0])\n",
    "        t = remove_ints_from_tokens(t.split('_'))\n",
    "        c = 0\n",
    "        for i in range(len(t)):\n",
    "            if t[i] in l1: c +=1   \n",
    "        num_common_tokens = c\n",
    "        return num_common_tokens\n",
    "\n",
    "    def get_num_unique_common_tokens(t, l):\n",
    "        l1 = []\n",
    "        for i in range(len(l)):\n",
    "            l1.append(l[i][0])\n",
    "        t = remove_ints_from_tokens(t.split('_'))\n",
    "        num_unique_common_tokens = len(intersection(set(t), l1))\n",
    "        return num_unique_common_tokens\n",
    "\n",
    "    for col in addr_cols:\n",
    "        nct = col + '_num_common_tokens'\n",
    "        nuct = col + '_num_unique_common_tokens'\n",
    "        l = top_tokens_all\n",
    "        df[nct + '_all'] = df[col + '_tokens'].apply(lambda x: get_num_common_tokens(x, l))\n",
    "        df[nuct + '_all'] = df[col + '_tokens'].apply(lambda x: get_num_unique_common_tokens(x, l))\n",
    "        df[col + '_pc_common_tokens_to_total_tokens' + '_all'] = df[nct + '_all'] / df[col + '_num_tokens']\n",
    "        df[col + '_num_non_common_tokens' + '_all'] =  df[col + '_num_tokens'] - df[col + '_num_common_tokens' + '_all']\n",
    "\n",
    "        l = top_tokens_del\n",
    "        df[nct + '_del'] = df[col + '_tokens'].apply(lambda x: get_num_common_tokens(x, l))\n",
    "        df[nuct + '_del'] = df[col + '_tokens'].apply(lambda x: get_num_unique_common_tokens(x, l))\n",
    "        df[col + '_pc_common_tokens_to_total_tokens' + '_del'] = df[nct + '_del'] / df[col + '_num_tokens']\n",
    "        df[col + '_num_non_common_tokens' + '_del'] = df[col + '_num_tokens'] - df[col + '_num_common_tokens' + '_del'] \n",
    "\n",
    "        l = top_tokens_rto\n",
    "        df[nct + '_rto'] = df[col + '_tokens'].apply(lambda x: get_num_common_tokens(x, l))\n",
    "        df[nuct + '_rto'] = df[col + '_tokens'].apply(lambda x: get_num_unique_common_tokens(x, l))\n",
    "        df[col + '_pc_common_tokens_to_total_tokens' + '_rto'] = df[nct + '_rto'] / df[col + '_num_tokens']\n",
    "        df[col + '_num_non_common_tokens' + '_rto'] = df[col + '_num_tokens'] - df[col + '_num_common_tokens' + '_rto']\n",
    "\n",
    "\n",
    "\n",
    "    def get_most_popular_token_freq(t):\n",
    "        if pd.isna(t):\n",
    "            return 0\n",
    "        t = remove_ints_from_tokens(t.split('_'))\n",
    "        freq = collections.Counter(t)\n",
    "        freq = dict(freq)\n",
    "        sorted_freq = sorted(freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        try:\n",
    "            return sorted_freq[0][1]\n",
    "        except IndexError:\n",
    "            return 0\n",
    "    for col in addr_cols:\n",
    "        col_name = col + '_most_popular_token_freq'\n",
    "        df[col_name] = df[col].apply(get_most_popular_token_freq)\n",
    "        \n",
    "#     def latitude_exists_or_not(latitude):\n",
    "#         return 1 if not pd.isna(latitude) else 0\n",
    "#     df['latitude_exists_or_not'] = df.apply(lambda x: latitude_exists_or_not(x['consignee_latitude']),axis=1)\n",
    "    import datetime as dt\n",
    "    df['order_weekend_or_not'] = np.where((df['order_placed_date'].dt.dayofweek == 5)|(df['order_placed_date'].dt.dayofweek == 6),1,0)\n",
    "    \n",
    "    df['order_hour'] = df['order_placed_date'].dt.hour\n",
    "\n",
    "    import math\n",
    "    def time_bucket(hour):\n",
    "        if pd.isna(hour):\n",
    "            return \"missing\"\n",
    "        if 0<=hour<9:\n",
    "            return '0-9'\n",
    "        else:\n",
    "            return f'{math.floor(hour/3)*3}-{(math.floor(hour/3)+1)*3}'\n",
    "\n",
    "    df['order_time_bucket'] = df['order_hour'].apply(time_bucket)\n",
    "    \n",
    "    df['expected_delivery_weekend_or_not'] = np.where((df['expected_delivery_date'].dt.dayofweek == 5)|(df['expected_delivery_date'].dt.dayofweek == 6),1,0)\n",
    "#     df['hour'] = df['expected_delivery_date'].dt.hour\n",
    "#     df['expected_delivery_time_bucket'] = df['hour'].apply(time_bucket)\n",
    "#     del df['hour']  \n",
    "    \n",
    "    df['delivery_weekend_or_not'] = np.where((df['delivery_date'].dt.dayofweek == 5)|(df['delivery_date'].dt.dayofweek == 6),1,0)\n",
    "    df['delivery_hour'] = df['delivery_date'].dt.hour\n",
    "    df['delivery_time_bucket'] = df['delivery_hour'].apply(time_bucket)\n",
    " \n",
    "    \n",
    "    \n",
    "    df['expected_delivery-order'] = (df['expected_delivery_date'].dt.date - df['order_placed_date'].dt.date).dt.days\n",
    "    df['delivery-expected_delivery']=(df['delivery_date'].dt.date - df['expected_delivery_date'].dt.date).dt.days\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c7b3c",
   "metadata": {},
   "source": [
    "# pincode in city and state check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28895d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import ast\n",
    "from fuzzywuzzy import fuzz\n",
    "def pin_state_check(pin,state):\n",
    "    res = requests.get(f\"https://api.postalpincode.in/pincode/{pin}\")\n",
    "    if json.loads(res.text)[0]['Status']!='Success':\n",
    "        return 0\n",
    "    else:\n",
    "        if json.loads(res.text)[0]['PostOffice'][0]['State'].lower() == state.lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "def pin_city_check(pin,city):\n",
    "    res = requests.get(f\"https://api.postalpincode.in/pincode/{pin}\")\n",
    "    if json.loads(res.text)[0]['Status']!='Success':\n",
    "        return 0\n",
    "    else:\n",
    "        return fuzz.ratio((json.loads(res.text)[0]['PostOffice'][0]['District']).lower(),city.lower())\n",
    "# ast.literal_eval(json.loads(res.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82855433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pin_city_check(pin,city):\n",
    "    if pincode_city_state.loc[pincode_city_state['pincode']==int(pin),'city'].values[0].lower()==city.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# def pin_state_check(pin,state):\n",
    "#     if str(pin) in pincode_city_state.pincode:\n",
    "#         if pincode_city_state[str(pin)][1].lower()==state.lower():\n",
    "#             return 1\n",
    "#     else :\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36602cf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# city in state check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a7f35",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.countrystatecity.in/v1/countries/IN/states\"\n",
    "\n",
    "headers = {\n",
    "  'X-CSCAPI-KEY': 'SUNqZjVLa0xMSGdudEZHT0RRQVlOTXA5N01ETlZiMnFpRFMwUEhPUw=='\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "state_iso2 = pd.DataFrame(columns = ['state','iso2'])\n",
    "for i in range(0,len(json.loads(response.text))):\n",
    "    state_iso2 = state_iso2.append({'state':json.loads(response.text)[i]['name'],'iso2':json.loads(response.text)[i]['iso2']},ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# get city detials from the state\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def city_list_of_state(state):\n",
    "    url = f\"https://api.countrystatecity.in/v1/countries/IN/states/{state_iso2.loc[state_iso2['state'].str.lower()==state.lower(),'iso2'].values[0]}/cities\"\n",
    "\n",
    "    headers = {\n",
    "      'X-CSCAPI-KEY': 'SUNqZjVLa0xMSGdudEZHT0RRQVlOTXA5N01ETlZiMnFpRFMwUEhPUw=='\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    \n",
    "    city_list = []\n",
    "    for i in range(0,len(json.loads(response.text))):\n",
    "        city_list.append(json.loads(response.text)[i]['name'])\n",
    "    return city_list\n",
    "\n",
    "def city_check(city,state):\n",
    "    if city.title() in city_list_of_state(state):\n",
    "        return 1\n",
    "    else:\n",
    "        o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68154a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Gibberish Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d3af5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cleaned_city(city):\n",
    "    city = city.replace(\"*\",\"\")\n",
    "    city = city.replace(\".\",\" \")\n",
    "    city = city.replace(\"  \",\" \")\n",
    "    city = city.replace(\"   \",\" \")\n",
    "    city = city.strip()\n",
    "    a=city.lower()\n",
    "    b=city.lower()\n",
    "    c = city.lower()\n",
    "    if \"-\" in city:\n",
    "        a = city[:city.index(\"-\")].lower()\n",
    "    if \"(\" in city:\n",
    "        b = city[:city.index(\"(\")].lower()\n",
    "    if \"[\" in city:\n",
    "        c = city[:city.index(\"[\")].lower()\n",
    "        \n",
    "    if len(a)<=min(len(b),len(c)):\n",
    "        return a\n",
    "    if len(b)<=min(len(a),len(c)):\n",
    "        return b\n",
    "    if len(c)<=min(len(a),len(b)):\n",
    "        return c\n",
    "\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import brown\n",
    "from english_words import english_words_set\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "words_to_add_df = getDataFromSheets(\"words_to_add\",\"Sheet1\")\n",
    "words_to_add=set(words_to_add_df['clean_area'])\n",
    "\n",
    "english_words_set = english_words_set.union(words_to_add)\n",
    "\n",
    "def bigrams(word):\n",
    "    a = []\n",
    "    for i in range(len(word)-1):\n",
    "        a.append(word[i:i+2].lower())\n",
    "    return a  \n",
    "\n",
    "def bigrams_not_possible():\n",
    "\n",
    "\n",
    "    set_all = set()\n",
    "    for i in english_words_set:\n",
    "        set_all = set_all.union(set(bigrams(i)))    \n",
    "\n",
    "    all_bigrams_list = []\n",
    "    for i in set_all:\n",
    "        if i.isalpha()==False:\n",
    "            pass\n",
    "        else:\n",
    "            all_bigrams_list.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    all_combs = []\n",
    "    for i in string.ascii_lowercase:\n",
    "        for j in string.ascii_lowercase:\n",
    "            all_combs.append(i+j)\n",
    "\n",
    "    len(all_combs)\n",
    "\n",
    "    bigrams_not_possible_list = [i for i in all_combs if i not in all_bigrams_list]\n",
    "    return bigrams_not_possible_list\n",
    "\n",
    "bigrams_not_possible_list = bigrams_not_possible()\n",
    "\n",
    "\n",
    "def trigrams(word):\n",
    "    a = []\n",
    "    for i in range(len(word)-2):\n",
    "        a.append(word[i:i+3].lower())\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "def trigrams_not_possible():\n",
    "    def trigrams(word):\n",
    "        a = []\n",
    "        for i in range(len(word)-2):\n",
    "            a.append(word[i:i+3].lower())\n",
    "        return a\n",
    "\n",
    "    set_all = set()\n",
    "    for i in english_words_set:\n",
    "        set_all = set_all.union(set(trigrams(i)))    \n",
    "\n",
    "    all_bigrams_list = []\n",
    "    for i in set_all:\n",
    "        if i.isalpha()==False:\n",
    "            pass\n",
    "        else:\n",
    "            all_bigrams_list.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    all_combs = []\n",
    "    for i in string.ascii_lowercase:\n",
    "        for j in string.ascii_lowercase:\n",
    "            for k in string.ascii_lowercase:\n",
    "                all_combs.append(i+j+k)\n",
    "\n",
    "    len(all_combs)\n",
    "\n",
    "    bigrams_not_possible_list = [i for i in all_combs if i not in all_bigrams_list]\n",
    "    return bigrams_not_possible_list\n",
    "\n",
    "trigrams_not_possible_list = trigrams_not_possible()\n",
    "\n",
    "\n",
    "def quadgrams(word):\n",
    "    a = []\n",
    "    for i in range(len(word)-3):\n",
    "        a.append(word[i:i+4].lower())\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "# def quadgrams_not_possible():\n",
    "\n",
    "#     set_all = set()\n",
    "#     for i in english_words_set:\n",
    "#         set_all = set_all.union(set(quadgrams(i)))    \n",
    "\n",
    "#     all_bigrams_list = []\n",
    "#     for i in set_all:\n",
    "#         if i.isalpha()==False:\n",
    "#             pass\n",
    "#         else:\n",
    "#             all_bigrams_list.append(i)\n",
    "\n",
    "\n",
    "\n",
    "#     all_combs = []\n",
    "#     for i in string.ascii_lowercase:\n",
    "#         for j in string.ascii_lowercase:\n",
    "#             for k in string.ascii_lowercase:\n",
    "#                 for l in string.ascii_lowercase:\n",
    "#                     all_combs.append(i+j+k+l)\n",
    "\n",
    "#     len(all_combs)\n",
    "\n",
    "#     bigrams_not_possible_list = [i for i in all_combs if i not in all_bigrams_list]\n",
    "#     return bigrams_not_possible_list\n",
    "\n",
    "# quadgrams_not_possible_list = quadgrams_not_possible()\n",
    "\n",
    "def gibberish_or_not(word):\n",
    "    word = word.lower()\n",
    "    lst1 = bigrams(word)\n",
    "    lst2 = bigrams_not_possible_list\n",
    "    lst3 = trigrams(word)\n",
    "    lst4 = trigrams_not_possible_list\n",
    "#     lst5 = quadgrams(word)\n",
    "#     lst6 = quadgrams_not_possible_list\n",
    "    for i in lst1:\n",
    "        if i in lst2:\n",
    "            return \"gibberish\"\n",
    "    for i in lst3:\n",
    "        if i in lst4:\n",
    "            return \"gibberish\"\n",
    "#     for i in lst5:\n",
    "#         if i in lst6:\n",
    "#             return \"gibberish\"\n",
    "    return \"not_gibberish\"\n",
    "\n",
    "def gibberish_count(line):\n",
    "    count=0\n",
    "    if pd.isna(line):\n",
    "        return 0\n",
    "    for word in line.replace(\".\",\" \").replace(\",\",\" \").split(\" \"):\n",
    "        if (gibberish_or_not(word)==\"gibberish\") and word.isalpha():\n",
    "            count+=1\n",
    "    return count\n",
    "            \n",
    "            \n",
    "\n",
    "def gibberish_pct(line):\n",
    "    total = 0\n",
    "    if pd.isna(line):\n",
    "        return 0\n",
    "    for word in line.replace(\".\",\" \").replace(\",\",\" \").split(\" \"):\n",
    "        if word.isalpha():\n",
    "            total+=1     \n",
    "    return round(gibberish_count(line)/total,2) if total>0 else 0\n",
    "\n",
    "df['gibberish_count'] = df.apply(lambda x: gibberish_count(x['complete_address']),axis=1)\n",
    "df['gibberish_pct'] = df.apply(lambda x: gibberish_pct(x['complete_address']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1ce53",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdb9d782",
   "metadata": {},
   "source": [
    "# Feature Analysis for rule creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd2a8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:02:52.588186Z",
     "start_time": "2022-05-26T15:02:52.553577Z"
    }
   },
   "outputs": [],
   "source": [
    "def bins(feature,demand='lower',label = 'rto_or_not',df = df,method='percentile',total_count_threshold=3,rto_pct_threshold=0):\n",
    "    \n",
    "    def not_null_columns(df):\n",
    "        a=[]\n",
    "        for i in df.columns:\n",
    "            if df[i].isnull().sum()==0:\n",
    "                a.append(i)\n",
    "        return a\n",
    "\n",
    "\n",
    "\n",
    "    def link(feature=feature,label=label, df = df,total_count_threshold=total_count_threshold,rto_pct_threshold=rto_pct_threshold):\n",
    "        pivot=df.pivot_table(values=[i for i in not_null_columns(df) if i not in [feature,label]][0],index=feature,columns=label,aggfunc='count')\n",
    "        pivot['sum']=pivot.sum(axis=1)\n",
    "        pivot.fillna(0,inplace=True)\n",
    "        pivot['rto_pct']=(pivot[1])/(pivot['sum'])\n",
    "        return pivot.loc[(pivot['sum']>=total_count_threshold)&(pivot['rto_pct']>=rto_pct_threshold),:]\n",
    "    \n",
    "    if demand=='equal':\n",
    "        return link(feature)\n",
    "    \n",
    "    \n",
    "    if method == 'percentile':\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['percentile','value_less/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                total = len(df.loc[df[feature]<=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_less/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['percentile','value_more/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(0,100,5)]:\n",
    "                total = len(df.loc[df[feature]>=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_more/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    else:\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['value_less/equal_than','total','rto_pct'])\n",
    "            for i in range(1,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]<=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_less/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['value_more/equal_than','total','rto_pct'])\n",
    "            for i in range(0,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]>=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_more/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    table['feature'] = feature\n",
    "    \n",
    "\n",
    "    \n",
    "    if demand == 'lower':\n",
    "        return table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_less/equal_than','total','rto_pct']].drop_duplicates()\n",
    "    else:\n",
    "        return table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_more/equal_than','total','rto_pct']].drop_duplicates()        \n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b280ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_two(feature1,feature2,label = 'rto_or_not',df = df,demand1='lower',demand2='lower',method='percentile',count_threshold=0,pct_threshold=0):\n",
    "    table = pd.DataFrame(columns=['feature1','percentile1','value_less/equal_than1','value_more/equal_than1','feature2','percentile2','value_less/equal_than2','value_more/equal_than2','total','rto_pct'])\n",
    "    if method == 'percentile':\n",
    "        if (demand1 == 'lower')&(demand2 == 'lower'):\n",
    "            \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    total = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j)),:])\n",
    "                    rto_pct = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j))&(df[label]==1),:])/total if total>0 else 0\n",
    "                    table = table.append({'feature1':feature1,'percentile1':i,'value_less/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_less/equal_than2':df[feature2].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        elif (demand1 == 'upper')&(demand2 == 'upper'):\n",
    "    \n",
    "            for i in [x/100 for x in range(0,100,5)]:\n",
    "                for j in [x/100 for x in range(0,100,5)]:\n",
    "                    total = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)),:])\n",
    "                    rto_pct = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j))&(df[label]==1),:])/total if total>0 else 0\n",
    "                    table = table.append({'feature1':feature1,'percentile1':i,'value_more/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_more/equal_than2':df[feature2].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        \n",
    "        elif (demand1 == 'lower')&(demand2 == 'upper'):\n",
    "    \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(0,100,5)]:\n",
    "                    total = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)),:])\n",
    "                    rto_pct = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j))&(df[label]==1),:])/total if total>0 else 0\n",
    "                    table = table.append({'feature1':feature1,'percentile1':i,'value_less/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_more/equal_than2':df[feature2].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        elif (demand1 == 'upper')&(demand2 == 'lower'):\n",
    "    \n",
    "            for i in [x/100 for x in range(0,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    total = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j)),:])\n",
    "                    rto_pct = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j))&(df[label]==1),:])/total if total>0 else 0\n",
    "                    table = table.append({'feature1':feature1,'percentile1':i,'value_more/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_less/equal_than2':df[feature2].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)    \n",
    "    \n",
    "#     else:\n",
    "#         if demand == 'lower':\n",
    "            \n",
    "#             for i in range(1,df[feature].max()+1,1):\n",
    "#                 for j in range(1,df[feature].max()+1,1):\n",
    "#                     total = len(df.loc[(df[feature1]<i)&(df[feature2]<j),:])\n",
    "#                     rto_pct = len(df.loc[(df[feature1]<i)&(df[feature2]<j)&(df[label]==1),:])/total if total>0 else 0\n",
    "#                     table = table.append({'feature1':feature1,'value_less/equal_than1':i,'feature2':feature2,'value_less/equal_than2':j,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "#         else:\n",
    "            \n",
    "#             for i in range(1,df[feature].max()+1,1):\n",
    "#                 for j in range(1,df[feature].max()+1,1):\n",
    "#                     total = len(df.loc[(df[feature1]>i)&(df[feature2]>j),:])\n",
    "#                     rto_pct = len(df.loc[(df[feature1]>i)&(df[feature2]>j)&(df[label]==1),:])/total if total>0 else 0\n",
    "#                     table = table.append({'feature1':feature1,'value_less/equal_than1':i,'feature2':feature2,'value_less/equal_than2':j,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "#     print(table)\n",
    "    output = table.loc[(table['total']>count_threshold)&(table['rto_pct']>pct_threshold),:].sort_values(by=['rto_pct'],ascending=False).drop(columns=['percentile1','percentile2']).drop_duplicates()\n",
    "    return output\n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bddced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins_three(feature1,feature2,feature3,label = 'rto_or_not',df = df,demand1='lower',demand2='lower',demand3='lower',method='percentile',count_threshold=10,pct_threshold=0.1):\n",
    "    table = pd.DataFrame(columns=['feature1','percentile1','value_less/equal_than1','value_more/equal_than1','feature2','percentile2','value_less/equal_than2','value_more/equal_than2','feature3','percentile3','value_less/equal_than3','value_more/equal_than3','total','rto_pct'])\n",
    "    if method == 'percentile':\n",
    "        if (demand1 == 'lower')&(demand2 == 'lower')&(demand3 == 'lower'):\n",
    "            \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    for k in [x/100 for x in range(5,100,5)]:\n",
    "                        total = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j)) & (df[feature3]<=df[feature3].quantile(k)),:])\n",
    "                        rto_pct = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j)) & (df[feature3]<=df[feature3].quantile(k)) & (df[label]==1),:])/total if total>0 else 0\n",
    "                        table = table.append({'feature1':feature1,'percentile1':i,'value_less/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_less/equal_than2':df[feature2].quantile(j),'feature3':feature3,'percentile3':k,'value_less/equal_than3':df[feature3].quantile(k),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "\n",
    "        if (demand1 == 'lower')&(demand2 == 'lower')&(demand3 == 'upper'):\n",
    "            \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    for k in [x/100 for x in range(5,100,5)]:\n",
    "                        total = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j)) & (df[feature3]>=df[feature3].quantile(k)),:])\n",
    "                        rto_pct = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j)) & (df[feature3]>=df[feature3].quantile(k)) & (df[label]==1),:])/total if total>0 else 0\n",
    "                        table = table.append({'feature1':feature1,'percentile1':i,'value_less/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_less/equal_than2':df[feature2].quantile(j),'feature3':feature3,'percentile3':k,'value_more/equal_than3':df[feature3].quantile(k),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        \n",
    "        if (demand1 == 'lower')&(demand2 == 'upper')&(demand3 == 'upper'):\n",
    "            \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    for k in [x/100 for x in range(5,100,5)]:\n",
    "                        total = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)) & (df[feature3]>=df[feature3].quantile(k)),:])\n",
    "                        rto_pct = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)) & (df[feature3]>=df[feature3].quantile(k)) & (df[label]==1),:])/total if total>0 else 0\n",
    "                        table = table.append({'feature1':feature1,'percentile1':i,'value_less/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_more/equal_than2':df[feature2].quantile(j),'feature3':feature3,'percentile3':k,'value_more/equal_than3':df[feature3].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        \n",
    "        if (demand1 == 'upper')&(demand2 == 'upper')&(demand3 == 'upper'):\n",
    "            \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    for k in [x/100 for x in range(5,100,5)]:\n",
    "                        total = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)) & (df[feature3]>=df[feature3].quantile(k)),:])\n",
    "                        rto_pct = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)) & (df[feature3]>=df[feature3].quantile(k)) & (df[label]==1),:])/total if total>0 else 0\n",
    "                        table = table.append({'feature1':feature1,'percentile1':i,'value_more/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_more/equal_than2':df[feature2].quantile(j),'feature3':feature3,'percentile3':k,'value_more/equal_than3':df[feature3].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        \n",
    "        \n",
    "        elif (demand1 == 'upper')&(demand2 == 'upper'):\n",
    "    \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    total = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)),:])\n",
    "                    rto_pct = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j))&(df[label]==1),:])/total if total>0 else 0\n",
    "                    table = table.append({'feature1':feature1,'percentile1':i,'value_more/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_more/equal_than2':df[feature2].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        elif (demand1 == 'lower')&(demand2 == 'upper'):\n",
    "    \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    total = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)),:])\n",
    "                    rto_pct = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j))&(df[label]==1),:])/total if total>0 else 0\n",
    "                    table = table.append({'feature1':feature1,'percentile1':i,'value_less/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_more/equal_than2':df[feature2].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        elif (demand1 == 'upper')&(demand2 == 'lower'):\n",
    "    \n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                for j in [x/100 for x in range(5,100,5)]:\n",
    "                    total = len(df.loc[(df[feature1]>=df[feature1].quantile(i)) & (df[feature2]>=df[feature2].quantile(j)),:])\n",
    "                    rto_pct = len(df.loc[(df[feature1]<=df[feature1].quantile(i)) & (df[feature2]<=df[feature2].quantile(j))&(df[label]==1),:])/total if total>0 else 0\n",
    "                    table = table.append({'feature1':feature1,'percentile1':i,'value_more/equal_than1':df[feature1].quantile(i),'feature2':feature2,'percentile2':j,'value_less/equal_than2':df[feature2].quantile(j),'total':total,'rto_pct':rto_pct},ignore_index=True)    \n",
    "    \n",
    "#     else:\n",
    "#         if demand == 'lower':\n",
    "            \n",
    "#             for i in range(1,df[feature].max()+1,1):\n",
    "#                 for j in range(1,df[feature].max()+1,1):\n",
    "#                     total = len(df.loc[(df[feature1]<i)&(df[feature2]<j),:])\n",
    "#                     rto_pct = len(df.loc[(df[feature1]<i)&(df[feature2]<j)&(df[label]==1),:])/total if total>0 else 0\n",
    "#                     table = table.append({'feature1':feature1,'value_less/equal_than1':i,'feature2':feature2,'value_less/equal_than2':j,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "#         else:\n",
    "            \n",
    "#             for i in range(1,df[feature].max()+1,1):\n",
    "#                 for j in range(1,df[feature].max()+1,1):\n",
    "#                     total = len(df.loc[(df[feature1]>i)&(df[feature2]>j),:])\n",
    "#                     rto_pct = len(df.loc[(df[feature1]>i)&(df[feature2]>j)&(df[label]==1),:])/total if total>0 else 0\n",
    "#                     table = table.append({'feature1':feature1,'value_less/equal_than1':i,'feature2':feature2,'value_less/equal_than2':j,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    output = table.loc[(table['total']>count_threshold)&(table['rto_pct']>pct_threshold),:].dropna(axis=1,how='all').sort_values(by=['rto_pct'],ascending=False).drop(columns=['percentile1','percentile2']).drop_duplicates()\n",
    "    return output\n",
    "            \n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929567e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6bee2d9",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdfe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_analysis(feature,label = 'rto_or_not',data=df):\n",
    "    if data[feature].dtype in [np.float64,np.int64]: #numerical feature\n",
    "        f = plt.figure(1)\n",
    "        sns.catplot(data=data,x=label,y=feature,kind='violin')\n",
    "        f.show()\n",
    "        g = plt.figure(1)\n",
    "        sns.distplot(data[data[label] == 'rto'][feature][0:] , label = \"1\", color = 'red')\n",
    "        sns.distplot(data[data[label] == 'others'][feature][0:] , label = \"0\", color = 'blue')\n",
    "        g.show()\n",
    "    else: # categorical feature\n",
    "        pivot=data.pivot_table(values=[i for i in not_null_columns(df) if i not in [feature,label]][0],index=feature,columns=label,aggfunc='count')\n",
    "        pivot['sum']=pivot.sum(axis=1)\n",
    "        pivot.fillna(0,inplace=True)\n",
    "        pivot['rto_pct']=(pivot[1])/(pivot['sum'])\n",
    "        sns.catplot(data=data,x=feature,kind='count',hue=label)\n",
    "        print(pivot.reset_index())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20fb13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in list(df.columns[13:48])+list(df.columns[51:]):\n",
    "#     feature_analysis(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cff6f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9960fae",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2be09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08cf7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr().to_excel('corr.xlsx')\n",
    "def drop_high_correlated_columns(df,threshold = 0.8):\n",
    "    corr = df.corr()\n",
    "    correlated_columns=[]\n",
    "    for i in range(0,corr.shape[0]):\n",
    "        for j in range(i,corr.shape[1]):\n",
    "            if corr.iloc[i,j]>=threshold and corr.index[i]!=corr.columns[j]:\n",
    "#                 print(corr.index[i],corr.columns[j])\n",
    "                correlated_columns.append(corr.columns[j])\n",
    "    return df.drop(columns=correlated_columns).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb1a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_high_correlated_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f07652",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f4636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[:,df.columns[list(df.columns).index('customer_address_len'):]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test(data,label_column,validation_size=0.25,test_size=0.2):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X=data.drop(columns=label_column)\n",
    "    y=data[label_column]\n",
    "    # train_feature,train_label,test_feature,test_label --> use this for variable\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=test_size, random_state=42)\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "train_feature,train_label,test_feature,test_label = train_validation_test(df1,'rto_or_not')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be8f1b8",
   "metadata": {},
   "source": [
    "### random forest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbdee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score\n",
    "for i in [6,9,12]:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model_RandomForestClassifier = RandomForestClassifier(max_depth=i,n_estimators=50,random_state=0)\n",
    "    model_RandomForestClassifier.fit(train_feature,train_label)\n",
    "    predict_RandomForestClassifier = model_RandomForestClassifier.predict(test_feature)\n",
    "    predict_RandomForestClassifier_train = model_RandomForestClassifier.predict(train_feature)\n",
    "    accuracy_RandomForestClassifier= accuracy_score(y_true=test_label,y_pred=predict_RandomForestClassifier)\n",
    "    confusion_matrix_RandomForestClassifier = pd.DataFrame(confusion_matrix(y_true=test_label,y_pred=predict_RandomForestClassifier))\n",
    "    f1_score_value = f1_score(y_true=test_label,y_pred=predict_RandomForestClassifier)\n",
    "    f1_score_train = f1_score(y_true=train_label,y_pred=predict_RandomForestClassifier_train)\n",
    "    print(f\"RandomForestClassifier-> accuracy:{accuracy_RandomForestClassifier}, confusion_matrix:{confusion_matrix_RandomForestClassifier}, f1_score:{f1_score_value}, f1_score_train:{f1_score_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_set_features,train_set_labels)\n",
    "predict = model_DecisionTreeClassifier.predict(test_set_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_RandomForestClassifier = RandomForestClassifier(max_depth=9,n_estimators=50,random_state=0)\n",
    "model_RandomForestClassifier.fit(train_feature,train_label)\n",
    "predict_RandomForestClassifier = model_RandomForestClassifier.predict(test_feature)\n",
    "predict_RandomForestClassifier_train = model_RandomForestClassifier.predict(train_feature)\n",
    "accuracy_RandomForestClassifier= accuracy_score(y_true=test_label,y_pred=predict_RandomForestClassifier)\n",
    "confusion_matrix_RandomForestClassifier = pd.DataFrame(confusion_matrix(y_true=test_label,y_pred=predict_RandomForestClassifier))\n",
    "f1_score_value = f1_score(y_true=test_label,y_pred=predict_RandomForestClassifier)\n",
    "f1_score_train = f1_score(y_true=train_label,y_pred=predict_RandomForestClassifier_train)\n",
    "print(f\"RandomForestClassifier-> accuracy:{accuracy_RandomForestClassifier}, confusion_matrix:{confusion_matrix_RandomForestClassifier}, f1_score:{f1_score_value}, f1_score_train:{f1_score_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fa9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model_RandomForestClassifier.feature_importances_\n",
    "\n",
    "feature_importance = pd.DataFrame({'feature':list(train_feature.columns),'importance':importance}).sort_values(by=['importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876df6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60986d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.to_excel('feature importance random forest 2.0.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab00b2",
   "metadata": {},
   "source": [
    "### logistic regression feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba28e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_LogisticRegression = LogisticRegression()\n",
    "model_LogisticRegression.fit(train_feature,train_label)\n",
    "predict_LogisticRegression = model_LogisticRegression.predict(test_feature)\n",
    "predict_RandomForestClassifier_train = model_RandomForestClassifier.predict(train_feature)\n",
    "accuracy_LogisticRegression= accuracy_score(y_true=test_label,y_pred=predict_LogisticRegression)\n",
    "confusion_matrix_LogisticRegression = pd.DataFrame(confusion_matrix(y_true=test_label,y_pred=predict_LogisticRegression))\n",
    "f1_score_value = f1_score(y_true=test_label,y_pred=predict_RandomForestClassifier)\n",
    "f1_score_train = f1_score(y_true=train_label,y_pred=predict_RandomForestClassifier_train)\n",
    "print(f\"LogisticRegression-> accuracy:{accuracy_LogisticRegression}, confusion_matrix:{confusion_matrix_LogisticRegression}, f1_score:{f1_score_value}, f1_score_train:{f1_score_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model_LogisticRegression.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0192ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature':list(train_feature.columns),'importance':importance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03487998",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance['abs_importance'] = feature_importance['importance'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8fc3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance.sort_values(by=['abs_importance'],ascending=False).to_excel('feature_importance_logistic_regression 2.0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ad114",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/shubham_mantri/Downloads/mappls_sample_scored.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa058a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import pdb\n",
    "\n",
    "def geocode_score(dic):\n",
    "#     pdb.set_trace()\n",
    "    dic = ast.literal_eval(dic)\n",
    "    \n",
    "    if len(dic.keys())==0:\n",
    "        return 0\n",
    "    score = 0\n",
    "    for key in geocode_weights.keys():\n",
    "        value = 1 if dic[key]!='' else 0\n",
    "        score+=geocode_weights[key]*value\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f067791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_weights = {'city' : 0.1,\n",
    "                 'district' : 0.1,\n",
    "                 'houseName' : 1,\n",
    "                 'houseNumber' : 1,\n",
    "#                  'landmark' : 0.9,\n",
    "                 'locality' : 0.8,\n",
    "                 'pincode' : 0.2,\n",
    "                 'poi' : 0.8,\n",
    "                 'state' : 0.01,\n",
    "                 'street' : 0.8,\n",
    "                 'subDistrict' : 0.4,\n",
    "                 'subLocality' : 0.85,\n",
    "                 'subSubLocality' : 0.9,\n",
    "                 'village' : 0.85}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7efe256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['geocode_score'] = df.apply(lambda x: geocode_score(x['meta']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44828551",
   "metadata": {},
   "outputs": [],
   "source": [
    "shopify = {\"data\": {\"cod\": False, \"email\": \"vamsi.glory@gmail.com\", \"state\": \"Telangana\", \"address\": \"4-204, My Home Vihanga, Gachibowli Financial district\", \"pincode\": \"500032\", \"lastName\": \"Innamuri\", \"firstName\": \"Vamsi\", \"created_at\": \"2022-04-15T14:08:33+05:30\", \"phoneNumber\": \"90081 84868\"}, \"order\": {\"id\": 4734201495800, \"name\": \"#2245\", \"note\": None, \"tags\": \"\", \"test\": False, \"email\": \"vamsi.glory@gmail.com\", \"phone\": None, \"token\": \"e4562c3205ff10ca220a62fba526bf2f\", \"app_id\": 580111, \"number\": 1245, \"gateway\": \"razorpay_cards_upi_netbanking_wallets_\", \"refunds\": [], \"user_id\": None, \"currency\": \"INR\", \"customer\": {\"id\": 6406339526904, \"note\": None, \"tags\": \"\", \"email\": \"vamsi.glory@gmail.com\", \"phone\": None, \"state\": \"disabled\", \"currency\": \"INR\", \"last_name\": \"Innamuri\", \"created_at\": \"2022-04-15T14:06:17+05:30\", \"first_name\": \"Vamsi\", \"tax_exempt\": False, \"updated_at\": \"2022-04-15T14:08:33+05:30\", \"total_spent\": \"2519.10\", \"orders_count\": 1, \"last_order_id\": 4734201495800, \"tax_exemptions\": [], \"verified_email\": True, \"default_address\": {\"id\": 7782329811192, \"zip\": \"500032\", \"city\": \"Hyderabad\", \"name\": \"Vamsi Innamuri\", \"phone\": \"90081 84868\", \"company\": None, \"country\": \"\", \"default\": True, \"address1\": \"4-204, My Home Vihanga, Gachibowli\", \"address2\": \"Financial district\", \"province\": \"Telangana\", \"last_name\": \"Innamuri\", \"first_name\": \"Vamsi\", \"customer_id\": 6406339526904, \"country_code\": \"IN\", \"country_name\": \"India\", \"province_code\": \"TS\"}, \"last_order_name\": \"#2245\", \"accepts_marketing\": True, \"admin_graphql_api_id\": \"gid://shopify/Customer/6406339526904\", \"multipass_identifier\": None, \"marketing_opt_in_level\": \"single_opt_in\", \"accepts_marketing_updated_at\": \"2022-04-15T14:06:17+05:30\"}, \"closed_at\": None, \"confirmed\": True, \"device_id\": None, \"reference\": None, \"tax_lines\": [{\"rate\": 0.18, \"price\": \"384.27\", \"title\": \"IGST\", \"price_set\": {\"shop_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}}, \"channel_liable\": False}], \"total_tax\": \"384.27\", \"browser_ip\": \"122.175.106.40\", \"cart_token\": None, \"created_at\": \"2022-04-15T14:08:33+05:30\", \"line_items\": [{\"id\": 12079910420728, \"sku\": \"TCC-PUL-BAR-1\", \"name\": \"pull-up bar - 90 cms - 115 cms\", \"grams\": 2500, \"price\": \"2799.00\", \"title\": \"pull-up bar\", \"duties\": [], \"vendor\": \"The Cube Club\", \"taxable\": True, \"quantity\": 1, \"gift_card\": False, \"price_set\": {\"shop_money\": {\"amount\": \"2799.00\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"2799.00\", \"currency_code\": \"INR\"}}, \"tax_lines\": [{\"rate\": 0.18, \"price\": \"384.27\", \"title\": \"IGST\", \"price_set\": {\"shop_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}}, \"channel_liable\": False}], \"product_id\": 7117183123607, \"properties\": [], \"variant_id\": 40952216813719, \"variant_title\": \"90 cms - 115 cms\", \"product_exists\": True, \"total_discount\": \"0.00\", \"origin_location\": {\"id\": 3027176751255, \"zip\": \"400021\", \"city\": \"Mumbai\", \"name\": \"thecubeclub\", \"address1\": \"1105 B wing, Dalamal Tower, Nariman Point,\", \"address2\": \"1105 B wing,\", \"country_code\": \"IN\", \"province_code\": \"MH\"}, \"requires_shipping\": True, \"fulfillment_status\": None, \"total_discount_set\": {\"shop_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}}, \"fulfillment_service\": \"manual\", \"admin_graphql_api_id\": \"gid://shopify/LineItem/12079910420728\", \"discount_allocations\": [{\"amount\": \"279.90\", \"amount_set\": {\"shop_money\": {\"amount\": \"279.90\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"279.90\", \"currency_code\": \"INR\"}}, \"discount_application_index\": 0}], \"fulfillable_quantity\": 1, \"variant_inventory_management\": \"shopify\"}], \"source_url\": None, \"updated_at\": \"2022-04-15T14:08:35+05:30\", \"checkout_id\": 32585804677368, \"location_id\": None, \"source_name\": \"web\", \"total_price\": \"2519.10\", \"cancelled_at\": None, \"fulfillments\": [], \"landing_site\": \"/wallets/checkouts.json\", \"order_number\": 2245, \"processed_at\": \"2022-04-15T14:08:33+05:30\", \"total_weight\": 2500, \"cancel_reason\": None, \"contact_email\": \"vamsi.glory@gmail.com\", \"total_tax_set\": {\"shop_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}}, \"checkout_token\": \"b68882e25dc3b95ed307c8a06c1fa1ef\", \"client_details\": {\"browser_ip\": \"122.175.106.40\", \"user_agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.88 Safari/537.36\", \"session_hash\": None, \"browser_width\": 1317, \"browser_height\": 738, \"accept_language\": \"en-US,en;q=0.9\"}, \"discount_codes\": [{\"code\": \"unlockxthecube\", \"type\": \"percentage\", \"amount\": \"279.90\"}], \"referring_site\": \"https://thecubeclub.com/products/pull-up-bar?variant=40952216813719\", \"shipping_lines\": [{\"id\": 3923313688824, \"code\": \"Standard\", \"phone\": None, \"price\": \"0.00\", \"title\": \"Standard\", \"source\": \"shopify\", \"price_set\": {\"shop_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}}, \"tax_lines\": [], \"discounted_price\": \"0.00\", \"delivery_category\": None, \"carrier_identifier\": None, \"discount_allocations\": [], \"discounted_price_set\": {\"shop_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}}, \"requested_fulfillment_service_id\": None}], \"subtotal_price\": \"2519.10\", \"taxes_included\": True, \"billing_address\": {\"zip\": \"500032\", \"city\": \"Hyderabad\", \"name\": \"Vamsi Innamuri\", \"phone\": \"90081 84868\", \"company\": None, \"country\": \"India\", \"address1\": \"4-204, My Home Vihanga, Gachibowli\", \"address2\": \"Financial district\", \"latitude\": 17.4338826, \"province\": \"Telangana\", \"last_name\": \"Innamuri\", \"longitude\": 78.33194859999999, \"first_name\": \"Vamsi\", \"country_code\": \"IN\", \"province_code\": \"TS\"}, \"customer_locale\": \"en\", \"estimated_taxes\": False, \"note_attributes\": [], \"total_discounts\": \"279.90\", \"total_price_set\": {\"shop_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}}, \"total_price_usd\": \"33.09\", \"financial_status\": \"paid\", \"landing_site_ref\": None, \"order_status_url\": \"https://thecubeclub.com/57946210455/orders/e4562c3205ff10ca220a62fba526bf2f/authenticate?key=00ecd60ae8cd552a4d78002938a76d1d\", \"shipping_address\": {\"zip\": \"500032\", \"city\": \"Hyderabad\", \"name\": \"Vamsi Innamuri\", \"phone\": \"90081 84868\", \"company\": None, \"country\": \"India\", \"address1\": \"4-204, My Home Vihanga, Gachibowli\", \"address2\": \"Financial district\", \"latitude\": 17.4338826, \"province\": \"Telangana\", \"last_name\": \"Innamuri\", \"longitude\": 78.33194859999999, \"first_name\": \"Vamsi\", \"country_code\": \"IN\", \"province_code\": \"TS\"}, \"current_total_tax\": \"384.27\", \"processing_method\": \"offsite\", \"source_identifier\": None, \"total_outstanding\": \"0.00\", \"fulfillment_status\": None, \"subtotal_price_set\": {\"shop_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}}, \"total_tip_received\": \"0.00\", \"current_total_price\": \"2519.10\", \"total_discounts_set\": {\"shop_money\": {\"amount\": \"279.90\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"279.90\", \"currency_code\": \"INR\"}}, \"admin_graphql_api_id\": \"gid://shopify/Order/4734201495800\", \"presentment_currency\": \"INR\", \"current_total_tax_set\": {\"shop_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"384.27\", \"currency_code\": \"INR\"}}, \"discount_applications\": [{\"code\": \"unlockxthecube\", \"type\": \"discount_code\", \"value\": \"10.0\", \"value_type\": \"percentage\", \"target_type\": \"line_item\", \"target_selection\": \"all\", \"allocation_method\": \"across\"}], \"payment_gateway_names\": [\"razorpay_cards_upi_netbanking_wallets_\"], \"current_subtotal_price\": \"2519.10\", \"total_line_items_price\": \"2799.00\", \"buyer_accepts_marketing\": False, \"current_total_discounts\": \"279.90\", \"current_total_price_set\": {\"shop_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}}, \"current_total_duties_set\": None, \"total_shipping_price_set\": {\"shop_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"0.00\", \"currency_code\": \"INR\"}}, \"original_total_duties_set\": None, \"current_subtotal_price_set\": {\"shop_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"2519.10\", \"currency_code\": \"INR\"}}, \"total_line_items_price_set\": {\"shop_money\": {\"amount\": \"2799.00\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"2799.00\", \"currency_code\": \"INR\"}}, \"current_total_discounts_set\": {\"shop_money\": {\"amount\": \"279.90\", \"currency_code\": \"INR\"}, \"presentment_money\": {\"amount\": \"279.90\", \"currency_code\": \"INR\"}}}, \"amount\": 2519.1, \"source\": \"thecubeclub.myshopify.com\", \"status\": \"paid\", \"billing\": {\"city\": \"Hyderabad\", \"state\": \"Telangana\", \"address\": \"4-204, My Home Vihanga, Gachibowli\", \"company\": \"\", \"country\": \"India\", \"pinCode\": \"500032\", \"address1\": \"Financial district\", \"customer\": {\"email\": \"vamsi.glory@gmail.com\", \"fName\": \"Vamsi\", \"lName\": \"Innamuri\", \"phone\": \"\"}}, \"orderId\": \"4734201495800\", \"shipping\": {\"city\": \"Hyderabad\", \"state\": \"Telangana\", \"address\": \"4-204, My Home Vihanga, Gachibowli\", \"company\": \"\", \"country\": \"India\", \"pinCode\": \"500032\", \"address1\": \"Financial district\", \"customer\": {\"email\": \"vamsi.glory@gmail.com\", \"fName\": \"Vamsi\", \"lName\": \"Innamuri\", \"phone\": \"\"}}, \"created_at\": \"2022-04-15T14:08:33+05:30\", \"workflowId\": \"f2fab6e9-556a-4f9c-9fe9-e81a072b1310\", \"paymentMethod\": \"prepaid\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a536aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(shopify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343181c7",
   "metadata": {},
   "source": [
    "# correct spelling of the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71890e64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T10:56:15.074903Z",
     "start_time": "2022-05-27T10:56:10.045387Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df3 = getDataFromSheets(\"City-State-Population\",\"Sheet1\")\n",
    "\n",
    "# df3.replace({'Jammu and Kashmir':'Jammu & Kashmir','Dadra and Nagar Haveli':'Dadra & Nagar Haveli and Daman & Diu','Andaman and Nicobar Islands':'Andaman & Nicobar Islands'},inplace=True)\n",
    "# df = df.replace({'Jammu & Kashmir':'Jammu and Kashmir','Daman & Diu':'Daman and Diu','Andaman & Nicobar Islands':'Andaman and Nicobar Islands','Chattisgarh':'Chhattisgarh'})\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "\n",
    "\n",
    "\n",
    "def correct_state_spelling(state,threshold_spelling = 70,threshold_phonetics = 80):\n",
    "#     print(type(state))\n",
    "#     return 1\n",
    "    if type(state)!=str:\n",
    "        return \"gibberish_state\"\n",
    "    check_list = list(df3['State/UT'].str.lower())\n",
    "    def match_pct_spelling(word):\n",
    "        return fuzz.ratio(word.lower(),state.lower())\n",
    "\n",
    "    def match_pct_phonetics(word):\n",
    "        return fuzz.ratio(jellyfish.soundex(word.lower()),jellyfish.soundex(state.lower()))\n",
    "\n",
    "    lst_spelling = list(map(match_pct_spelling,np.array(check_list)))\n",
    "    lst_phonetics = list(map(match_pct_phonetics,np.array(check_list)))\n",
    "    if max(lst_phonetics)>=threshold_phonetics:\n",
    "#         print('phonetics -',max(lst_phonetics))\n",
    "        return check_list[np.argmax(lst_phonetics)]\n",
    "    if max(lst_spelling)>=threshold_spelling:\n",
    "#         print('spelling -',max(lst_spelling))\n",
    "        return check_list[np.argmax(lst_spelling)]\n",
    "    else:\n",
    "        return \"gibberish_state\"\n",
    "\n",
    "\n",
    "    \n",
    "def correct_city_spelling(city,state,threshold_spelling = 70,threshold_phonetics = 80):\n",
    "    if state == \"gibberish_state\":\n",
    "        return \"gibberish_state\"\n",
    "#     print(city,\" \",state)\n",
    "    check_list = list(df3.loc[df3['State/UT'].str.lower()==state.lower(),'City'])\n",
    "    def match_pct_spelling(word):\n",
    "        return fuzz.partial_ratio(word.lower(),city.lower())\n",
    "\n",
    "    def match_pct_phonetics(word):\n",
    "        return fuzz.ratio(jellyfish.soundex(word.lower()),jellyfish.soundex(city.lower()))\n",
    "    \n",
    "    print(match_pct_spelling('kochi'))\n",
    "\n",
    "    lst_spelling = list(map(match_pct_spelling,np.array(check_list)))\n",
    "#     print(check_list)\n",
    "    lst_phonetics = list(map(match_pct_phonetics,np.array(check_list)))\n",
    "    if max(lst_phonetics)>=threshold_phonetics:\n",
    "#         print('phonetics -',max(lst_phonetics))\n",
    "        return check_list[np.argmax(lst_phonetics)]\n",
    "    if max(lst_spelling)>=threshold_spelling:\n",
    "#         print('spelling -',max(lst_spelling))\n",
    "        return check_list[np.argmax(lst_spelling)]\n",
    "    else:\n",
    "        return \"gibberish_city\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8905e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T10:56:15.206559Z",
     "start_time": "2022-05-27T10:56:15.075934Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_city_spelling('Cochi','Kerala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce9f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T10:53:12.355316Z",
     "start_time": "2022-05-27T10:53:12.348453Z"
    }
   },
   "outputs": [],
   "source": [
    "state = 'Kerela'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de40b87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T10:53:12.790485Z",
     "start_time": "2022-05-27T10:53:12.716302Z"
    }
   },
   "outputs": [],
   "source": [
    "list(df3.loc[df3['State/UT'].str.lower()==state.lower(),'City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a266a35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T10:46:29.691934Z",
     "start_time": "2022-05-27T10:46:29.682821Z"
    }
   },
   "outputs": [],
   "source": [
    "fuzz.partial_ratio('kochi','cochi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e6562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-27T10:56:49.765943Z",
     "start_time": "2022-05-27T10:56:49.757996Z"
    }
   },
   "outputs": [],
   "source": [
    "fuzz.ratio(jellyfish.soundex('cochi'),jellyfish.soundex('kochi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dff3a5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# loading pincode city state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10e3236",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "pincode_city_state = json.load(open(\"/Users/shubham_mantri/Downloads/pincode city state.rtf\"))\n",
    "\n",
    "pincode_city_state_df = pd.DataFrame(pincode_city_state).T.reset_index().rename(columns={'index':'pincode',0:'city',1:'state'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d29b3",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# pincode city and state check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedf4b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pin_city_check(pin,city):\n",
    "    if str(pin) in pincode_city_state.keys():\n",
    "        if pincode_city_state[str(pin)][0].lower()==city.lower():\n",
    "            return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "def pin_state_check(pin,state):\n",
    "    if str(pin) in pincode_city_state.keys():\n",
    "        if pincode_city_state[str(pin)][1].lower()==state.lower():\n",
    "            return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa88e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_url = (\n",
    "    \"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data\"\n",
    ")\n",
    "us_states_url = f\"{data_url}/us-states.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f94be",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "us_states_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60bd865",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data/us-states.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa424940",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c6484",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GeoJson of Indian States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514f8b3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "m = folium.Map([35, 80], zoom_start=4)\n",
    "\n",
    "folium.GeoJson(\"https://raw.githubusercontent.com/Subhash9325/GeoJson-Data-of-Indian-States/master/Indian_States\").add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639fcb8",
   "metadata": {},
   "source": [
    "# Google maps API (Geocoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754562bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T16:50:37.441774Z",
     "start_time": "2022-06-08T16:50:37.007345Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "GOOGLE_API_KEY = 'AIzaSyBm8OiGWcbaBuR2oz-8aBmLLeoG0yxarY4' \n",
    "\n",
    "result_list = {}\n",
    "\n",
    "def extract_lat_long_via_address(address_or_zipcode):\n",
    "#     print(address_or_zipcode)\n",
    "    lat, lng = None, None\n",
    "    api_key = GOOGLE_API_KEY\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    endpoint = f\"{base_url}?address={address_or_zipcode}&key={api_key}\"\n",
    "#     time.sleep(0.5)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(endpoint,timeout=10.0)\n",
    "        if r.status_code not in range(200, 299):\n",
    "            result_list[address_or_zipcode]=\"wrong address\"\n",
    "            return \"wrong address\"\n",
    "        result_list[address_or_zipcode]=r.json()\n",
    "        return r.json()\n",
    "#         results = r.json()['results'][0]\n",
    "#         lat = results['geometry']['location']['lat']\n",
    "#         lng = results['geometry']['location']['lng']\n",
    "    except:\n",
    "        result_list[address_or_zipcode]=\"timeout error\"\n",
    "        return \"timeout error\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e394bf2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T16:50:53.226416Z",
     "start_time": "2022-06-08T16:50:52.905587Z"
    }
   },
   "outputs": [],
   "source": [
    "test = extract_lat_long_via_address(\"Allied Trade Centre #20/A EV Lane Dodpete Nagarathpete Gottigere, Near Saptagiri Homes Bengaluru Karnataka 560002 India\")\n",
    "\n",
    "\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ed275",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:37:47.968949Z",
     "start_time": "2022-05-24T10:37:47.958438Z"
    }
   },
   "outputs": [],
   "source": [
    "test['results'][0]['postcode_localities']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940eeff",
   "metadata": {},
   "source": [
    "## city and state extraction from pincode using google maps api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14159dad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:54:12.618386Z",
     "start_time": "2022-05-24T10:54:12.609895Z"
    }
   },
   "outputs": [],
   "source": [
    "def city_town_list_for_pincode(pin):\n",
    "    test = extract_lat_long_via_address(str(pin)+' ,India')\n",
    "    if len(test['results'][0]['address_components'])==1:\n",
    "        return \"wrong_pincode\"\n",
    "    lst = []\n",
    "    for i in test['results'][0]['address_components']:\n",
    "        lst.append(i['long_name'])\n",
    "    if 'postcode_localities' in test['results'][0].keys():   \n",
    "        final_lst = lst + test['results'][0]['postcode_localities']\n",
    "    return final_lst\n",
    "\n",
    "def state_extract_from_pincode(pin):\n",
    "    test = extract_lat_long_via_address(str(pin)+' ,India')\n",
    "    if len(test['results'][0]['address_components'])==1:\n",
    "        return \"wrong_pincode\"\n",
    "    for j in test['results'][0]['address_components']:\n",
    "        if \"administrative_area_level_1\" in j['types']:\n",
    "            return j['long_name']\n",
    "    else:\n",
    "        return \"wrong_pincode\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6ff1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:55:46.085371Z",
     "start_time": "2022-05-24T10:55:46.077582Z"
    }
   },
   "outputs": [],
   "source": [
    "'postcode_localities' in test['results'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365713b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:43:01.810591Z",
     "start_time": "2022-05-24T10:43:01.803233Z"
    }
   },
   "outputs": [],
   "source": [
    "pin = 302019\n",
    "str(pin)+' ,India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee88d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T14:00:48.664461Z",
     "start_time": "2022-05-24T14:00:48.271171Z"
    }
   },
   "outputs": [],
   "source": [
    "city_town_list_for_pincode(209206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8b99c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T13:51:12.892756Z",
     "start_time": "2022-05-24T13:51:12.883623Z"
    }
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671e708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:40:01.630567Z",
     "start_time": "2022-05-24T10:40:01.620265Z"
    }
   },
   "outputs": [],
   "source": [
    "final_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1784899",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:53:00.897235Z",
     "start_time": "2022-05-24T10:53:00.481798Z"
    }
   },
   "outputs": [],
   "source": [
    "a = extract_lat_long_via_address(\"206142, India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d8745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T10:53:26.296791Z",
     "start_time": "2022-05-24T10:53:26.287813Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044c5f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T11:34:25.963544Z",
     "start_time": "2022-05-23T11:34:25.614029Z"
    }
   },
   "outputs": [],
   "source": [
    "api_result = extract_lat_long_via_address('28,Vinayaka Layout 1St Cross  near greendale apartment 560016 Bengaluru')\n",
    "\n",
    "\n",
    "# test_googleapi_result['results'][0]['types']\n",
    "\n",
    "api_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b91e11d",
   "metadata": {},
   "source": [
    "## feature extraction from google maps api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25edf8f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T12:42:00.676404Z",
     "start_time": "2022-05-09T12:42:00.669779Z"
    }
   },
   "outputs": [],
   "source": [
    "api_result['results'][0]['geometry']['location_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e1208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T21:40:23.211382Z",
     "start_time": "2022-05-12T21:40:17.270598Z"
    }
   },
   "outputs": [],
   "source": [
    "hierarchy = getDataFromSheets(\"Google Maps Geocoding API response type hierarchy\",\"Sheet1\")\n",
    "\n",
    "def googlemaps_mapping(typ):\n",
    "    hierarchy = getDataFromSheets(\n",
    "        \"Google Maps Geocoding API response type hierarchy\", \"Sheet1\")\n",
    "    return hierarchy.loc[hierarchy['Entity Type'] == typ, 'Rank'].values[0]\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "GOOGLE_API_KEY = 'AIzaSyBm8OiGWcbaBuR2oz-8aBmLLeoG0yxarY4' \n",
    "\n",
    "result_list = {}\n",
    "\n",
    "def extract_lat_long_via_address(address_or_zipcode):\n",
    "#     print(address_or_zipcode)\n",
    "    lat, lng = None, None\n",
    "    api_key = GOOGLE_API_KEY\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    endpoint = f\"{base_url}?address={address_or_zipcode}&key={api_key}\"\n",
    "#     time.sleep(0.5)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(endpoint,timeout=10.0)\n",
    "        if r.status_code not in range(200, 299):\n",
    "            result_list[address_or_zipcode]=\"wrong address\"\n",
    "            return \"wrong address\"\n",
    "        result_list[address_or_zipcode]=r.json()\n",
    "        return r.json()\n",
    "#         results = r.json()['results'][0]\n",
    "#         lat = results['geometry']['location']['lat']\n",
    "#         lng = results['geometry']['location']['lng']\n",
    "    except:\n",
    "        result_list[address_or_zipcode]=\"timeout error\"\n",
    "        return \"timeout error\"\n",
    "    \n",
    "\n",
    "def lowest_type_googlemaps(api_result):\n",
    "    if api_result==\"timeout error\":\n",
    "        return None\n",
    "    if len(api_result['results']) == 1:\n",
    "        return max(\n",
    "            list(\n",
    "                map(googlemaps_mapping,\n",
    "                    api_result['results'][0]['types'])))\n",
    "    else:\n",
    "        def match(i):\n",
    "            return fuzz.partial_ratio(api_result['results'][i]['formatted_address'],address)\n",
    "        partial_ratio_list = list(map(match,range(len(api_result['results']))))\n",
    "        highest_match_index = partial_ratio_list.index(max(partial_ratio_list))\n",
    "        return max(\n",
    "            list(\n",
    "                map(googlemaps_mapping,\n",
    "                    api_result['results'][highest_match_index]['types'])))\n",
    "    \n",
    "def results_count(api_result):\n",
    "    if api_result==\"timeout error\":\n",
    "        return None\n",
    "    return len(api_result['results'])\n",
    "\n",
    "def match_address_original_vs_formatted(address,api_result):\n",
    "    if api_result==\"timeout error\":\n",
    "        return None\n",
    "    if len(api_result['results']) == 1:\n",
    "        return fuzz.ratio(api_result['results'][0]['formatted_address'],address)\n",
    "    else:\n",
    "        def match(i):\n",
    "            return fuzz.partial_ratio(api_result['results'][i]['formatted_address'],address)\n",
    "        partial_ratio_list = list(map(match,range(len(api_result['results']))))\n",
    "        highest_match_index = partial_ratio_list.index(max(partial_ratio_list))\n",
    "        return fuzz.ratio(api_result['results'][highest_match_index]['formatted_address'],address)\n",
    "    \n",
    "    \n",
    "def lat_long_extraction(api_result):\n",
    "    if api_result==\"timeout error\":\n",
    "        return None\n",
    "    if len(api_result['results']) == 1:\n",
    "        lat = api_result['results'][0]['geometry']['location']['lat']\n",
    "        lng = api_result['results'][0]['geometry']['location']['lng']\n",
    "        return lat,lng\n",
    "    else:\n",
    "        def match(i):\n",
    "            return fuzz.partial_ratio(api_result['results'][i]['formatted_address'],address)\n",
    "        partial_ratio_list = list(map(match,range(len(api_result['results']))))\n",
    "        highest_match_index = partial_ratio_list.index(max(partial_ratio_list))\n",
    "        lat = api_result['results'][highest_match_index]['geometry']['location']['lat']\n",
    "        lng = api_result['results'][highest_match_index]['geometry']['location']['lng']\n",
    "        return lat,lng\n",
    "    \n",
    "def location_type(api_result):\n",
    "    if api_result==\"timeout error\":\n",
    "        return None\n",
    "    if len(api_result['results']) == 1:\n",
    "        return api_result['results'][0]['geometry']['location_type']\n",
    "    else:\n",
    "        def match(i):\n",
    "            return fuzz.partial_ratio(api_result['results'][i]['formatted_address'],address)\n",
    "        partial_ratio_list = list(map(match,range(len(api_result['results']))))\n",
    "        highest_match_index = partial_ratio_list.index(max(partial_ratio_list))\n",
    "        return api_result['results'][highest_match_index]['geometry']['location_type']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b7210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T21:41:04.321106Z",
     "start_time": "2022-05-12T21:41:03.864414Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_lat_long_via_address(\"323 shyam nagar jaipur 302020 rajasthan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35051f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cc004ef",
   "metadata": {},
   "source": [
    "# map my india vs google maps api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1705e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T07:18:56.722460Z",
     "start_time": "2022-05-09T07:18:48.099148Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "address_list = ['No, Patna City, Patna, Bihar - 800008','Veliparambil House, , Ernakulam, Kerala - 682040','25, Gura Nanak Nagar St No 1, Faridkot, Punjab - 151203','No.50 , 4Th Street, Vaatimanai, Ambur, Tamil Nadu - 635802','1-4-22/5/A, Rajendra Nagar, Mahabub Nagar, Telangana - 509001','Nr Petrol Pump, House No.7, Simdega, Simdega, Jharkhand - 835223','Kaliganj Gash Agency, Nilambazar Subdistrict, , Assam - 788720','Kwakta Bazar\\nPo Moirang\\nDist.Bishnupur, , Tiddim Road, Manipur - 795133','Tallital Bazar Bhimtal, , Nainital, Uttarakhand - 263136','342, Jaingara Kirawali, Agra District, Uttar Pradesh - 283122']\n",
    "lst = []\n",
    "for address in address_list:\n",
    "    lst.append(extract_lat_long_via_address(address))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d73062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T07:52:15.282911Z",
     "start_time": "2022-05-09T07:52:15.266345Z"
    }
   },
   "outputs": [],
   "source": [
    "i=10\n",
    "\n",
    "print(address_list[i])\n",
    "lst[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7d367e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b822b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pincode_city_state_df['complete']=pincode_city_state_df['pincode']+', '+pincode_city_state_df['cleaned_city'].str.title()+', '+ pincode_city_state_df['state']+', '+'India'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4009cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pincode_city_state_df=pincode_city_state_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9bfa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pincode_city_state_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pincode_city_state_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pincode_city_state_df['google_api_result']=pincode_city_state_df.progress_apply(lambda x: extract_lat_long_via_address(x['complete']),axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfab042",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long=getDataFromSheets(\"pincode_googlemaps_api\",\"Sheet1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a0444",
   "metadata": {},
   "source": [
    "# latitude longitude extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614bfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "lat_long['google_api_result'] = lat_long['google_api_result'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86863c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T12:28:34.726940Z",
     "start_time": "2022-05-09T12:28:34.720640Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lat_long_extraction(api_result):\n",
    "    lat = api_result['results'][0]['geometry']['location']['lat']\n",
    "    lng = api_result['results'][0]['geometry']['location']['lng']\n",
    "    return lat,lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ead380",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long[['latitude','longitude']] = lat_long.apply(lambda x: lat_long_extraction(x['api_result']),axis=1,result_type='expand')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d01f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertDataIntoSheets(lat_long,\"pincode_googlemaps_api\",\"Sheet2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8d8fbe",
   "metadata": {},
   "source": [
    "# lat long distance calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da7a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "def lat_long_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93264ba",
   "metadata": {},
   "source": [
    "# Adding more cities from groceries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ae5aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T06:57:11.650798Z",
     "start_time": "2022-05-04T06:57:11.640344Z"
    }
   },
   "outputs": [],
   "source": [
    "def import_groceries_data():\n",
    "    df = pd.DataFrame()\n",
    "    for i in list(range(54,69))+[113,114]:\n",
    "        df_temp = pd.read_csv(f'/Users/shubham_mantri/Downloads/Grocery_/a6491a3a3422b7e8050570588f282f20_h3_{i}.csv',header=None)\n",
    "        df_temp.columns = ['order_external_id', 'account_id', 'status', 'gmv', 'listing_tier', 'product_id', 'units', 'order_status', 'order_created_by', 'order_user_agent', 'order_sales_channel', 'order_date_time', 'return_completed_date_time', 'new_customer_flag', 'deliver_date_time', 'flow_type', 'order_billing_amount', 'brand', 'courier_name', 'product_title', 'pincode', 'analytic_business_unit', 'analytic_super_category', 'analytic_category', 'analytic_sub_category', 'analytic_vertical', 'contact_creation_date_time', 'contact_user_name', 'contact_first_name', 'contact_last_name', 'address_line1', 'address_line2', 'address_city', 'address_landmark', 'address_state', 'communication_phone', 'communication_email']\n",
    "        df = df.append(df_temp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ec0ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T06:57:38.584956Z",
     "start_time": "2022-05-04T06:57:24.254518Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = import_groceries_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88087bf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:03:43.773601Z",
     "start_time": "2022-05-04T07:03:43.424558Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1[['address_city','address_state']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37903f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:04:04.831966Z",
     "start_time": "2022-05-04T07:04:04.761275Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.to_csv('random2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f54dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T07:04:33.210985Z",
     "start_time": "2022-05-04T07:04:33.205157Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d89106",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:22:59.657996Z",
     "start_time": "2022-05-04T11:22:55.898779Z"
    }
   },
   "outputs": [],
   "source": [
    "df = getDataFromSheets('City-State-Population','Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b973eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T09:46:19.439752Z",
     "start_time": "2022-05-04T09:44:32.517728Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "import jellyfish\n",
    "\n",
    "matching = {}\n",
    "\n",
    "for state in df['State/UT'].str.lower().unique():\n",
    "    for city in df.loc[df['State/UT'].str.lower()==state,'City'].unique():\n",
    "        print(state,city)\n",
    "        def match_pct_spelling(word):\n",
    "            return fuzz.ratio(word.lower(),city.lower())\n",
    "\n",
    "        def match_pct_phonetics(word):\n",
    "            return fuzz.ratio(jellyfish.soundex(word.lower()),jellyfish.soundex(city.lower()))\n",
    "        \n",
    "        def extract_above_threshold(lst1,lst2,threshold=92):\n",
    "            extracted_list = []\n",
    "            for i in lst1:\n",
    "                if i>=threshold:\n",
    "                    extracted_list.append(lst2[lst1.index(i)])\n",
    "            return extracted_list\n",
    "                    \n",
    "    \n",
    "        lst_spelling = list(map(match_pct_spelling,np.array(df.loc[df['State/UT'].str.lower()==state,'City'].unique())))\n",
    "        lst_phonetics = list(map(match_pct_phonetics,np.array(df.loc[df['State/UT'].str.lower()==state,'City'].unique())))\n",
    "        lst_matching = extract_above_threshold(lst_phonetics,df.loc[df['State/UT'].str.lower()==state,'City'].unique())\n",
    "        matching[city] = lst_matching\n",
    "#         if max(lst_phonetics)>=70:\n",
    "#     #         print('phonetics -',max(lst_phonetics))\n",
    "# #             return df.loc[df['State/UT'].str.lower()==state,'City'].unique()[np.argmax(lst_phonetics)]\n",
    "#             matching[city]=df.loc[df['State/UT'].str.lower()==state,'City'].unique()[np.argmax(lst_phonetics)]\n",
    "#         if max(lst_spelling)>=70:\n",
    "#     #         print('spelling -',max(lst_spelling))\n",
    "# #             return check_list[np.argmax(lst_spelling)]\n",
    "#             matching[city]=df.loc[df['State/UT'].str.lower()==state,'City'].unique()[np.argmax(lst_spelling)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11959496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T09:46:19.590499Z",
     "start_time": "2022-05-04T09:46:19.440768Z"
    }
   },
   "outputs": [],
   "source": [
    "matching1 = pd.DataFrame.from_dict(matching, orient='index')\n",
    "matching1 = matching1.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c3e21c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T09:46:19.651902Z",
     "start_time": "2022-05-04T09:46:19.591358Z"
    }
   },
   "outputs": [],
   "source": [
    "matching1.to_csv('random4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca24fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:05:15.700086Z",
     "start_time": "2022-05-04T10:05:15.678729Z"
    }
   },
   "outputs": [],
   "source": [
    "df=matching1.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd3ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:06:10.916318Z",
     "start_time": "2022-05-04T10:06:06.444098Z"
    }
   },
   "outputs": [],
   "source": [
    "# def distinct_more_than_one(df):\n",
    "df['distinct_more_than_one']=None\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    print(set(list(df.iloc[i,:])))\n",
    "    df.iloc[i,25]=len(set(list(df.iloc[i,:])))\n",
    "#     if i==20:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb318dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:51:30.300317Z",
     "start_time": "2022-05-04T10:51:17.795604Z"
    }
   },
   "outputs": [],
   "source": [
    "insertDataIntoSheets(df.loc[df['distinct_more_than_one']>=3,:].fillna(\"\"),\"City-State-Population\",'Sheet5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ee20a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T10:07:58.974766Z",
     "start_time": "2022-05-04T10:07:58.963516Z"
    }
   },
   "outputs": [],
   "source": [
    "df['distinct_more_than_one'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8fed7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:34:52.661730Z",
     "start_time": "2022-05-04T08:34:52.646530Z"
    }
   },
   "outputs": [],
   "source": [
    " def cleaned_city(city):\n",
    "    city = city.replace(\"*\",\"\")\n",
    "    city = city.replace(\".\",\" \")\n",
    "    city = city.replace(\"  \",\" \")\n",
    "    city = city.replace(\"   \",\" \")\n",
    "    city = city.strip()\n",
    "    a=city.lower()\n",
    "    b=city.lower()\n",
    "    c = city.lower()\n",
    "    if \"-\" in city:\n",
    "        a = city[:city.index(\"-\")].lower()\n",
    "    if \"(\" in city:\n",
    "        b = city[:city.index(\"(\")].lower()\n",
    "    if \"[\" in city:\n",
    "        c = city[:city.index(\"[\")].lower()\n",
    "        \n",
    "    if len(a)<=min(len(b),len(c)):\n",
    "        return a\n",
    "    if len(b)<=min(len(a),len(c)):\n",
    "        return b\n",
    "    if len(c)<=min(len(a),len(b)):\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2fff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:23:45.961826Z",
     "start_time": "2022-05-04T11:23:45.952751Z"
    }
   },
   "outputs": [],
   "source": [
    "type(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494114b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:22:17.786126Z",
     "start_time": "2022-05-04T11:22:17.605922Z"
    }
   },
   "outputs": [],
   "source": [
    "dic = {'pratapgarh district':'pratapgarh','allahabad district':'allahabad','varanasi district':'varanasi','balrampur':'balrampur district','gorakhpur district':'gorakhpur','azamgarh district':'azamgarh','nizamabad':'nizamabad district','mirzapur cum vindhyachal':'mirzapur','mahrajganj mahrajganj district':'mahrajganj district','baghpat':'baghpat district','chandauli':'chandauli district','jansath':'jhansi district','ghaziabad district':'ghaziabad','saharanpur':'saharanpur district','gautam buddha nagar':'gautam buddh nagar','mughalsarai':'machhlishahr','moradabad':'moradabad district','mainpuri district':'mainpuri','bulandshahr district':'bulandshahr','farrukhabad district':'farrukhabad','barwar':'bharwari','mirzapur district':'mirzapur','rampur karkhana':'rampur district','jaunpur':'jaunpur district','gautam buddha nagar district':'gautam buddh nagar','banda':'bhind','rampur maniharan':'rampur district','kaushambi':'kachhauna patseni','bhimnagar district':'bangarmau','pilibhit district':'pilibhit','sikandra allahabad district':'sikanderpur','firozabad':'farrukhabad','maharajganj':'mirganj','rae bareli district':'rae bareli','saidpur ghazipur district':'sitapur district','mau':'mhow','lalitpur':'lalitpur district','bijnor':'bijnor district','barabanki':'bara banki district','shahjahanpur district':'shahjahanpur','firozabad district':'farrukhabad','budhana':'badaun','fatehpur fatehpur district':'fatehpur district','faizabad':'faizabad mahendragarh district','kewalpur':'kulpahar','kanpur nagar':'kanpur','etawah':'etah','ghazipur':'ghazipur district','sikandarabad industrial area':'sikanderpur','etah district':'etawah district','akbarpur kanpur dehat district':'akbarpur','mursan':'mahrajganj district','ghatampur':'gautam buddh nagar','raebareli':'rae bareli','beswan':'bhogaon','sahatwar':'shahdara','sikandrabad':'sikanderpur','bijnore':'bijnor district','lakhimpur':'lakhimpur district','jiyanpur':'jaunpur district','kaushambi district':'kachhauna patseni','hamirpur':'hamirpur district','muzaffarnagar district':'muzaffarnagar','ranipur':'rampur baghelan','sikanderpur kannauj district':'sikanderpur','karwi':'kheri','manikpur sarhat':'mankapur','nawabganj unnao district':'nawabganj bareilly district','kheri district':'kurthi jafarpur','haidergarh':'hathras','barabanki industrial area':'bara banki district','kanpur nagar district':'kanpur','bela pratapgarh':'bhulepur','kannauj':'konch','bara gaon':'bhargain','sidhpura':'sitapur district','kushinagar':'kushinagar district','fatehpur chaurasi':'fatehpur district','suriyawan':'soron','mohammadabad':'maunath bhanjan','kanpur dehat district':'kanpur','mahmudabad':'maunath bhanjan','fatehganj purvi':'fatehganj pashchimi','atraulia':'atrauli','kharkhoda':'kurukshetra','bhadohi':'behat','jalalabad shahjahanpur district':'jalalpur','rampura':'rampur baghelan','kithaur':'khutar','sikandra rao':'sikanderpur','budaun':'badaun','raibareli':'rae bareli','khairabad sitapur district':'khairabad mau district','gosainganj faizabad district':'gosainganj lucknow district','chitrakoot district':'chitrakoot uttar pradesh','biswan':'bhogaon','amila':'aonla','kotwali':'khatauli','shrawasti district':'sherkot','pipri':'pipariya','powayan':'pihani','kathaura':'khutar','barsana':'bhargain','bachhrawan':'bachhraon','mau aima':'mawana','mahimapur':'mainpuri','kasganj':'kushinagar district','pachperwa':'pakbara','un':'unnao','barabanki district':'bara banki district','ambedkar nagar':'ambedkar nagar district','saurikh':'sirsi','bikapur':'bijpur','tirwaganj':'trishundi industrial area','saraon':'soron','bhinga':'bansi','maigal ganj':'machhlishahr','bidhuna':'badaun','pratapgarh city':'pratapgarh district','reoti':'rath','bahuwa':'bah','gangapur':'gangapur city','bighapur':'bijpur','suar':'sewarhi','ambedkarnagar':'ambedkar nagar district','jainpur industrial area':'jaunpur district','mohammadabad ghazipur district':'maunath bhanjan','tundla':'tundla kham','gorakhpur air force area township':'gorakhpur','bilaspur gautam buddha nagar district':'bilaspur rampur district','bewar':'baheri','bajna':'bhogaon','samthar':'sant ravidas nagar bhadohi district','kanpur dehat':'kanpur','siddharth nagar':'siddharthnagar district','mundera bazar':'mandawar','kotra':'khutar','bilari':'bilhaur','ashrafpur kichhauchha':'agro park karkhiyon','karari':'kurara','dibai':'debai','gaziabad':'ghaziabad','rudouli':'rudauli','mahrajganj':'mahrajganj district','mallawan':'mailani','koraon':'kairana','dhaurahara':'dhaurehra','sikanderpur ballia district':'sikanderpur','sahawar':'sewarhi','mahrajganj azamgarh district':'mahrajganj district','nawabganj gonda district':'nawabganj bareilly district','faizganj':'fazi nagar','kachhwa':'khaga','chandpur':'chandapur','jalalabad muzaffarnagar district':'jalalpur','miranpur':'mauranipur','banguwan kalan':'bansgaon','jahangirpur':'jahangirabad','kannuj':'konch','bhojpur dharampur':'bijpur','sikandarabad':'sikanderpur','siddhaur':'shahdara','jaithara':'jatari','gosainganj lucknow':'gosainganj lucknow district','awagarh':'agra','bhadarsa':'bahadurganj','adari':'atarra','seohara':'sewarhi','shahabad rampur district':'shahabad hardoi district','sarai mir':'saraimeer','bisharatganj':'bhokarhedi','sonbhadra':'sonbhadra district','birbhanpur':'bara banki district','khair':'kheri','palpur':'phulpur allahabad district','shahabad':'shahbad','kemri':'khamaria','katra gonda district':'katra shahjahanpur district','farah':'fariha','musafirkhana':'muzaffarnagar','noida 49':'noida','basta':'buguda','gausganj':'gosainganj lucknow district','raibareilly':'rae bareli','baksar':'bakewar','maudaha':'moth','bharichi':'bahraich','kuraoli':'karhal','siddharthnagar':'siddharthnagar district','phulpur azamgarh district':'phulpur allahabad district','kheragarh':'kursi road industrial area','sant kabir nagar':'sant kabir nagar district','satrikh':'saiyad raja','sirauli':'sarila','kakod':'khekada','atrauliya':'atrauli','kauria ganj':'kauriaganj','sumerpur':'sumerpur industrial area','kora jahanabad':'kauriaganj','lakhna':'lucknow','badaun district':'budaun district','jalalabad bijnor district':'jalalpur','gorkhpur':'gorakhpur','kheta sarai':'katghar lalganj','garhi pukhta':'gauri bazar','baragaon':'birsinghpur','shrawasti':'sherkot','khetasarai':'katghar lalganj','santkabir nagar':'sant kabir nagar district','mohenpur':'mainpuri','santkabirnagar':'sant kabir nagar district','bara banki':'bara banki district','amethi':'antu','bakiabad':'baghpat district','kiraoli':'karhal','shahbad hardoi':'shahabad hardoi district','mohan':'mawana','amethi sultanpur':'amethi sultanpur district','ghughli':'ghughuli','saidpur':'sitapur district','saidpur budaun district':'sitapur district','mhrajgnj':'mahrajganj district','siddhaarth nagar':'siddharthnagar district','sonebhadra':'sonbhadra district','gida, gorakhpur':'gida gorakhpur','beniganj':'bansgaon','nakur':'naugarh','kushinager':'kushinagar district','sikandra':'sikanderpur','fatehpur sikri':'fatehpur district','siddhrth nagar':'siddharthnagar district','gohand':'gonda','banat':'banda','sasni':'sahaswan','mohammadabad farrukhabad district':'maunath bhanjan','maina maujpur':'mahamaya nagar district','garauri':'ghiraur','mahroni':'maurawan','nawabganj':'nawabganj bareilly district','khariya':'kheri','korwa':'kheri','mussoorie gulawathi road industrial area':'misrikh cum neemsar','etwah':'etah','sarsawa':'sirsi','bulandshahar':'bulandshahr','fatehpur bara banki district':'fatehpur district','district sitapur':'district behraich','kishunpur':'kachhauna patseni','koeripur':'koiripur','sultanpuru':'sultanpur district','mugra badshahpur':'mogra badshahpur','district fatehapur':'district behraich','singahi bhiraura':'shamsabad farrukhabad district','gorakhpur sadar':'gorakhpur','district sultanpur':'district behraich','jaonpur':'jaunpur district','district auraiya':'district behraich','parsakhera industrial area':'purquazi','pepeeganj':'pipiganj','faridpur':'faridpur bareilly district','anurudhpur purab patti':'amraudha','gabhana':'gopamau','machhali shahar':'machhlishahr','khanupur':'kanpur','tundla rly colony':'tundla kham','varansi':'varanasi','shahjahan pur':'shahjahanpur','baghpat industrial area':'baghpat district','kharela':'karhal','runkata':'renukoot','parikshitgarh':'parsadepur','dhanoura':'dhanaura','district ballia':'district behraich','thiriya nizamat khan':'tronica city','nodia':'noida','madiya':'moth','ghazipur city':'ghazipur district','saraimir':'saraimeer','kataghar lalganj':'katghar lalganj','muhammadabad':'mamidipalle','kakari':'kakori','ram kola':'ramkola','lawar':'lar','usawan':'ujhani','kadaura':'khutar','district basti':'district behraich','sonkh':'saunkh','district jaunpur':'district behraich','district kannauj':'district behraich','sandila industrial area':'sandila','gorakhpur city':'gorakhpur','saranath':'sarnath','ambehta':'ambedkar nagar district','barielly':'bareilly','behsuma':'bhogaon','shikarpur':'shikaripura','anoopshahr':'anupshahr','narora':'naraura','junpuer':'jaunpur district','dhaurahra':'dhaurehra','nawabganj gonda':'nawabganj bareilly district','district unnao':'district behraich','lakhimpur kheri':'lakhimpur','kanpurdehat':'kanpur','jalalabad shahjahanpur':'jalalpur','sikindra':'sikanderpur','sadar':'shahdara','reabreli':'rae bareli','shaswan':'sahaswan','mohammdi':'mohammadi','allahganj':'aliganj','rai bareli':'rae bareli','mohanpur':'mainpuri','barhaj':'bahraich','phulpur azamgarh':'phulpur allahabad district','amilo':'aonla','tindwari':'tanda rampur district','kithore':'khutar','parichha':'parasi','junpur':'jaunpur district','shahabad hardoi':'shahabad hardoi district','gopiganj':'gopi ganj','bachhraun':'bachhraon','maharajganj district':'mahrajganj district','chandoli':'chandauli district','bilaspur':'bilaspur district','goverdhan':'govardhan','farukhabad':'farrukhabad','paliya kalan':'palia kalan','maharajganj industrial area':'mahrajganj district','mendu':'mohammadi','unno':'unnao','sant ravidas nagar bhadohi':'sant ravidas nagar bhadohi district','chitrkoot':'chitrakoot uttar pradesh','sahjanwa':'sahaswan','ntpc tanda colony':'ntpc dadri','subeha':'sahpau','mureet':'meerut','gorkhapur':'gorakhpur','shamsabad agra district':'shamsabad farrukhabad district','north east delhi':'north west delhi','bishunpur':'bishunipur','faizabad industrial area 1':'faizabad district','barahaj':'bahraich','muhammadabad district':'maunath bhanjan','siddhartha nagar':'siddharthnagar district','jainpur industiral area':'jaunpur district','district gonda':'district behraich','bihka':'bahjoi','anpra':'anpara','bhuragarh industrial area':'barkhera','dhaura tand':'dhaura tanda','ghughali':'ghughuli','pilkhana':'pilkhani','kachnar':'kusmara','raebarelli':'rae bareli','ambedkernagar':'ambedkar nagar district','reabareli':'rae bareli','barelliy':'bareilly','baharaech':'bahraich','banjarepur':'bangarmau','mohammadabad yusufpur':'maunath bhanjan','prayag raj':'prayagraj','machhalishaher':'machhlishahr','prayagraj district':'prayagraj','muzaffaranagar':'muzaffarnagar','firozabad upsidc':'farrukhabad','muhammdabad':'maunath bhanjan','gokul':'ghughuli','shahajahanpur':'shahjahanpur','bhagwant nagar':'bisanda buzurg','ghazibad':'ghaziabad','sakhanu':'sahaswan','jaunpur city':'jaunpur district','bahaduragnj':'bahadurganj','sant ravidas nagar':'sant ravidas nagar bhadohi district','district ghazipur':'district behraich','khatuali':'khatauli','mughal sarai':'machhlishahr','ibrahim pur':'ibrahimpur','madhaugarh':'madhogarh','dildarnagar':'dildarnagar fatehpur bazar','kumarganj':'kunwargaon','phulpur':'phulpur allahabad district','rajepur':'rajapur','shahabad, hardoi':'shahabad hardoi district','shahabad, rampur':'shahabad hardoi district','shamsabad, agra':'shamsabad farrukhabad district','shamsabad, farrukhabad':'shamsabad farrukhabad district','shikarpur, bulandshahr':'shikarpur','anupshahar':'anupshahr','billari':'bilhaur','siyana':'siana','rasulabad':'rasulabad kanpur dehat district','ambuj nagar':'anupshahr','jalalabadup':'jalalpur','bacchawaran':'bachhraon','miyanganj':'manjhanpur','mauup':'mahoba','soraon':'soron','manda':'mohammadi','nariwari':'naraura','karchhana':'kauriaganj','phoolpur':'phulpur allahabad district','lal gopalganj':'lal gopalganj nindaura','saidabad':'sadabad','madhuban':'madhubani district','sikandarpur':'sikanderpur','mungra badshahpur':'mehnagar','martinganj':'muradnagar','kurebhar':'koiripur','gosainganj':'gosainganj lucknow district','haidargarh':'hathras','lalganj ajhara':'lalganj','marihan':'maurawan','chunnar':'chunar','dhanapur':'dhampur','gahmar':'gunnaur','dildar nagar':'dildarnagar fatehpur bazar','mishrikh':'misrikh cum neemsar','jyotiba phule nagar':'jyotiba phule nagar district','gajrola':'gajraula','kanth':'kunda','gulawati':'gulaothi','afjalgarh':'afzalgarh','thanabhawan':'thana bhawan','bailaha':'ballia','rudhauli':'rudauli','brijmanganj':'bhargain','dullahapur':'dulhipur','r s':'richha','bariya':'baheri','kirauli':'karhal','talbahat':'talbehat','mahrauni':'maurawan','jagatsinghapur district':'jagatsinghapur','talcher thermal power station township':'talcher','sambalpur':'sambalpur district','bhadrak':'bhadrak district','anugul':'anugul district','nabarangapur':'nabarangapur district','angul':'anugul district','kandhamal':'kandhamal district','kendujhar':'kendujhar district','sundargarh':'sundargarh district','nabarangpur':'nabarangapur district','ramgarh':'ramgarh sikar district','jharsuguda district':'jharsuguda','rengali dam project township':'rengali','bargarh':'bargarh district','byasanagar':'bhushan steel plant jharsuguda township','dhenkanal':'dhenkanal district','baleshwar':'baleshwar district','bhushan steel plant meramandali township':'bhushan steel plant jharsuguda township','bolangir':'balangir district','balangir':'balangir district','kendrapara':'kendrapara district','jajapur':'jajapur district','jeypur':'jeypore','malkangiri':'malkangiri district','brajrajnagar':'bargarh district','barapali':'barbil','jajpur district':'jajapur district','koraput':'koraput district','bishama katak':'bhushan steel plant jharsuguda township','bhuabneswar':'bhubaneswar','titilagarh':'titlagarh','kalahandi':'kalahandi district','binika':'banki','damanjodi':'dhamanagar','kantabanji':'khandapada','balasore':'baleshwar district','kalyanasingpur':'kalinga nagar industrial area','bhuban':'bhuban,','basudevpur':'basudebpur','debagarh':'debagarh district','malkan giri district':'malkangiri district','badagada':'badakodanda','jashipur':'jajapur district','brajarajnagar':'bargarh district','bhubaneshwar':'bhubaneswar','chatrapur':'chhatrapur','jagatsinghpur':'jagatsinghapur','jajpur road':'jajapur district','bhubaneswar751011':'bhubaneswar','jajpur':'jajapur district','brahmabarada':'berhampur','kuchinda':'kochinda','boudh district':'baudh district','ganjam':'ganjam district','jagatasinghpur':'jagatsinghapur','balakati':'baliguda','baripara':'birapratappur','balagoda':'baliguda','dungamal':'dhenkanal district','paradeep':'paradip','mayurbhanj':'mayurbhanj district','bangomunda':'bhanjanagar','bellaguntha':'balugaon','baudh':'boudh','jatni':'jatani','gajapati':'gajapati district','brahampur':'berhampur','angul district':'anugul district','madanpur ramp ur':'madanpur rampur','kashinagara':'kesinga','khordh':'khordha','phulbani':'phulabani','berahampur':'berhampur','bhubaneswer':'bhubaneswar','kansbahal':'kunjabangarh','lakhanpur':'lakhnapur','rajagangapur':'rajasunakhala','birmitrapur':'biramitrapur','kashinagar':'kesinga','umerkote':'umarkote','phula bani':'phulabani','pathar':'pathara','jagatsinghpur district':'jagatsinghapur','bhanja nagar':'bhanjanagar','saydpur':'sayadpur','narasinghpur':'narsingarh','banpur':'banapur','angula district':'anugul district','cuttck district':'cuttack district','jeleswar':'jaleswar','sayedpur':'sayadpur','ranpurgada':'ranapurgada','debagarh,':'debagarh district','khurda':'khordha','bissma cuttack':'bhushan steel plant jharsuguda township','cuttack city':'cuttcak','paralakhemundi':'parlakhemundi','kabisurjya nagar':'kavisurjyanagar','rajsunakhala':'rajgangpur','raurkela':'rourkela','nayagrh':'nayagarh','sundergarh':'sundargarh district','bolani':'balani','bhubneswer':'bhubaneswar','bhanjanagara':'bhanjanagar','ghatgon':'ghatagaon','barpali':'barbil','athagada':'athagad','damonjodi':'dhamanagar','balesore':'baleshwar district','kendujhara':'kendujhar district','mayorbhanj':'mayurbhanj district','puri 2':'puri','padamapur':'padmapur','deogrh':'deogarh','sambolpur':'sambalpur district','blasore':'baleshwar district','bhadarak':'bhadrak district','chandbali':'chandapur','nuahota':'nuahata','konrak':'konark','balngire district':'balangir district','pardeep':'paradip','kordha':'khordha','jajapura district':'jajapur district','dhankanal':'dhenkanal district','digapahndi':'digapahandi','khorda':'khordha','gopalapur':'gopalpur','khurdha':'khordha','chandikhole':'chandikhol','balikuda':'baliguda','rajnagar or':'rajgangpur','chandipur':'chandpur south twenty four parganas district','jajpur town':'jajapur district','binjharpur':'bonaigarh','baleswar':'baleshwar district','bonth':'bundia','dhamara':'danara','baisinga':'bhushan steel plant jharsuguda township','bangriposi':'bonaigarh','dukura':'deogarh','ghatgaon':'ghatagaon','kamakhyanagar':'kamakshyanagar','kamakhyanagar orrissa':'kamakshyanagar','chhendipada':'chandapur','kantamal':'kandhamal district','balliguda':'baliguda','borigumma':'boriguma','pappadahandi':'papadahandi','tikiri':'tusura','raygada':'rayagada','sinapali':'sambalpur district','binka':'banki','loisingha':'loisinga','melchhamunda':'malkangiri district','rairakhol':'rourkela','ballinga':'balangir district','sagar':'sausar','bangalore':'bengaluru','bengaluru rural district':'bengaluru','kotturu':'kadiri','bijapur district':'bijapur','yadgir district':'yadgir','heroor':'harihar','bangalore rural district':'bengaluru','tumakuru':'tumkur district','vijayapura':'vijapura','hubli':'hubballi','bengalore':'bengaluru','belgaum':'belgaum district','tumkur':'tumkur district','gulbarga district':'gulbarga','mangalore':'mangaluru','chikkamagaluru':'chikmagalur district','davanagere district':'davanagere','honnavar':'honavar','chikballapur industrial area':'chikkaballapur district','krishnarajanagara':'krishnarajpet','davangere':'davanagere','bagalkot district':'bagalkot','chamarajanagar':'chamarajanagar district','madikeri':'mudigere','solapur':'solapur district','ramanagara district':'ramanagara','bilgi':'bhalki','yellapur':'yelbarga','alur':'ayyalur','bengalur':'bengaluru','belthangady':'beltangadi','chikkaballapura district':'chikkaballapur district','chikmagalur':'chikmagalur district','dakshina kannada':'dakshina kannada district','bengaluru rural':'bengaluru','sidco industrial estate badanguppe kellambali':'sidco industrial estate jakkasandra','mysore':'mysuru','chik ballapur':'chikkaballapur district','doddaballapur industrial area':'dod ballapur','siddapur':'saidapur','chitradurga':'chitradurga district','chikamaglur':'chikmagalur district','hiriyur':'harihar','kadur':'kotturu','narasimharajapura':'nargund','mangluru':'mangaluru','doddaballapura apparel park':'dod ballapur','ballar':'ballari','bellary':'ballari','kirshnarajanagara':'krishnarajpet','bangarpet':'bangarapet','tirthahalli':'terdal','kushalnagar':'kushalanagara','mhalingpur':'mahalingpur','somvarpet':'sambra','karkala':'karkal','mallar':'malur','bangalore rural':'bengaluru','shahapur':'shahpur','chamaraja nagar':'chamarajanagar district','hutti':'hatti','nanjungud':'nanjangud','mandy district':'mandya district','kudur':'kotturu','hospet':'hosapete','shirahatti':'shirhatti','belgum district':'belgaum district','banglore':'bengaluru','sindhanur':'sindhnur','ballary district':'bellary district','harohalli industrial area':'hirehally industrial area','gangavathi':'gonikoppal','moodbidri':'mudbidri','srirampura':'srirangapatna','nelmangala':'nelamangala','chiknayakanhalli':'chikmagalur district','bengaluru 86':'bengaluru','huvinahadagali district':'hoovina hadagalli','soraba':'sorab','humnabad industrial area':'homnabad','kodagu':'kudchi','krishnaraja sagara':'krishnarajpet','honaga industrial area':'hungund','sadalgi':'sidlaghatta','kamatgi':'kundgol','bangalore district':'bengaluru','narikombu':'nargund','sidco industrial estate gowribidanur':'sidco industrial estate jakkasandra','talikoti':'talikota','hunsur,':'hunsur','moodbidire':'mudbidri','bailhongal':'bail hongal','holenarasipura':'hole narsipur','bengluru':'bengaluru','saligrama':'saligram','kalaburagi':'kalaburgi','vijayapur':'vijapura','bnagalore':'bengaluru','bellari':'ballari','chamrajnagar':'chamarajanagar district','challekere':'challakere','saragur':'sargur','madhugiri':'mudigere','humnabad':'homnabad','kerur':'karwar','yadgiri':'yadgir','dodballapur':'dod ballapur','jevaragi':'jevargi','sidco industrial estate kittur belagavi':'sidco industrial estate jakkasandra','chikkaballapur':'chikkaballapur district','bengalurua':'bengaluru','saundatti':'saundatti yellamma','bangalure':'bengaluru','solebhavi':'sulebhavi','belgium':'belgaum district','basavkalyan':'basavakalyan','molkalmuru':'molakalmuru','saundattiyellamma':'saundatti yellamma','kollur':'kolar','chikkaballapura':'chikkaballapur district','bilagi':'bhalki','sindhnuor':'sindhnur','virajpet':'virajpete','gundlupete':'gundlupet','mangolur':'mangaluru','gundelpet':'gundlupet','ramanagar':'ramanagara','rachura':'raichur','kudar':'kotturu','chitaradurga':'chitradurga district','mulur':'malur','hosadurga':'hosdurga','yadagir':'yadgir','manjanady':'manjunath township basavkalyan','kustagi':'kushtagi','sidco industrial estte kittur belagavi':'sidco industrial estate jakkasandra','gulbraga':'gulbarga','h d kote':'hd kote','ranebennru':'ranebennur','chikmagalure':'chikmagalur district','kundapur':'kundapura','bangalore u':'bengaluru','sattur':'seithur','kushalnagara':'kushalanagara','belagaum':'belgaum district','ballri':'ballari','mysure':'mysuru','uttara kannada':'uttara kannada district','humnbad':'homnabad','gajendragarh':'gajendragad','davanagereo':'davanagere','kunigal industrial area':'kunigal','k r nagara':'kairangala','ranibennur':'ranebennur','nandikur industrial area':'nandagad','gajendrgad':'gajendragad','ballary':'ballari','bengalure':'bengaluru','bangalur':'bengaluru','gadag betigieri':'gadag betigeri','bangarpet industrial area':'bangarapet','bangaluru':'bengaluru','manglore':'mangaluru','kollegala':'kollegal','mangalor':'mangaluru','yelburga':'yelbarga','chamarajnagar':'chamarajanagar district','hoovina hadagali':'hoovina hadagalli','banagalore':'bengaluru','sullia':'sulya','huvvinahadagalli':'hoovina hadagalli','kamatagi':'kundgol','dhrawad':'dharwad','bengaloore city':'bengaluru','davangre':'davanagere','hospate':'hosapete','riachur':'raichur','belgaum 1':'belgaum district','sidco industrial estate vemagal':'sidco industrial estate jakkasandra','bantaval':'bantval','talikote':'talikota','mutaga':'mutga','piriyapatna':'periyapatna','mahalingapur':'mahalingpur','holenarasipur':'hole narsipur','bengaluru city':'bengaluru','bydagi':'byadgi','sakleshpur 9741244556':'sakleshpur','chamarajanagara':'chamarajanagar district','chikamagalur district':'chikmagalur district','chikballapur':'chikkaballapur district','hoskute':'hoskote','banglure':'bengaluru','gowribidanur':'gauribidanur','mahalingapura':'mahalingpur','mudalagi':'mudalgi','mudabidri':'mudbidri','ramanagaram':'ramanagara','sagara':'sagar','sakaleshapura':'sakleshpur','sindagi':'sindgi','sanduru':'sandur','sankeshwara':'sankeshwar','shikaripur':'shikaripura','surapura':'shorapur','shrirangapattana':'srirangapatna','sindhagi':'sindgi','doddaballapura':'dod ballapur','dabaspete':'dobaspet industrial area','myntra':'mundargi','shanivarasanthe':'sambra','krishnarajngr':'krishnarajpet','chikkanayakanahalli':'chikmagalur district','turuvukere':'turuvekere','chikkamagalur':'chikmagalur district','moodabidri':'mudbidri','vitla':'vittal','chickmagalur':'chikmagalur district','thirthahalli':'terdal','bhadravathi':'bhadravati','hosanagar':'hosanagara','shiralakoppa':'siralkoppa','jagaluru':'jagalur','ajjampur':'agumbe','byadagi':'byadgi','holalu':'haliyal','rona':'ron','kalaghatgi':'kalghatgi','kittur':'kotturu','laxmeshwar':'lakshmeshwar','gangava':'gonikoppal','harpanahalli':'harapanahalli','toranagallu':'tirumakudaluns','lingasugur':'lingsugur','chittapur':'chitapur','gulbarg':'gulbarga','mannaekhelli':'mangaluru','kolhar':'kolar','basavana bagewadi':'basavana bagevadi','munuvalli':'manipal','raibag':'raybag','hukkeri':'hukeri','sahibganj':'sahibganj district','phusro':'pakaur','hazaribagh':'hazaribagh district','gomoh':'gumia','kodarma':'kodarma district','jhumri telaiya':'jhumri tilaiya','sindri':'sinduria','ramgarh district':'ramgarh cantonment civil township','barhi':'baihar','lohardaga district':'lohardaga','dhanbad district':'dhanbad','bokaro thermal township':'bokaro district','meru':'muri','barki saraiya':'barkakana','ara':'arrah','koderma':'kodarma district','sahnidih':'saunda','jamtara district':'jamtara','simdega district':'simdega','pakur':'pakaur','purbi singhbhum':'purbi singhbhum district','gidi':'godda','mahagma':'mihijam','hazaribag':'hazaribagh district','tati':'toto','grahwa':'garhwa','majhion':'mihijam','saraikela kharswan':'saraikela kharsawan district','bachra':'bokaro','sonda':'saunda','paschimi singhbhum':'pashchimi singhbhum district','mahagama':'mihijam','mera':'muri','tinpahar':'tin pahar','pathardih':'patratu','jhumari telaya':'jhumri tilaiya','giridh':'giridih','kharkharee':'kharkhari','khalari':'khelari','jaridihbazar':'jaridih bazar','sarka':'sirka','koderma district':'kodarma district','chouparan':'chauparan','rajganj':'raiganj','churi':'charhi','chiria':'charhi','chandaur':'chandrapura','seraikela':'saraikela kharsawan district','palamau district':'palamu district','mahagam':'mihijam','mandu':'mundi','sarauni':'saram','bishungarh':'bishnugarh','dhnbad':'dhanbad','bhagatdih':'bhojudih','behragora':'baharagora','barkatha':'barughutu','bagoar':'bokaro','husainabad':'hussainabad','borio':'bhowrah','mahag ma':'mihijam','gimla':'gumla','chakardharpur':'chakradharpur','saraikela':'saraikela kharsawan district','gidi a':'godda','bhurkunda':'barajamda','barkagaon':'barkakana','ghatsila':'ghatshila','danguwapasi':'dangoaposi','barora':'barharwa','palamau':'palamu','barhait bazaar':'berhait bazar','bardubhi':'berhait bazar','bokara':'bokaro','purulia':'puruliya','gomia':'gumia','boarijore':'baharagora','behraghora':'baharagora','poriyahat':'paratdih','tisri':'tisra','chhatarpur':'chhatarpur district','bisrampur':'bishrampur','ranka':'ranchi','barki saria':'barkakana','petarbar':'peterbar','seraikella':'saraikela kharsawan district','bero':'bhowrah','purba medinipur':'purba medinipur district','koch bihar district':'koch bihar','dakshin odlabari':'dakshin dinajpur district','bankura':'bankura district','baruipur':'birpara','paschim medinipur':'paschim medinipur district','birbhum':'birbhum district','kolaghat':'kolkata','coochbhar':'coochbehar','bardhaman':'burdwan','cooch behar':'coochbehar','garh kamalpur':'garshyamnagar','sehara':'suri','murshidabad':'murshidabad district','parasia':'porsa','jalpaiguri':'jalpaiguri district','kalna':'kalyani','uttarpara kotrung':'uttar bagdogra','darjeeling':'darjiling district','konnagar':'kanchrapara','bhangar raghunathpur':'bankura district','banshra':'bankura district','nadia':'naihati','midnapore':'medinipur','barrackpur cantonment civil township':'barrackpore','krishnagar':'krishnanagar','raghunathpur hugli district':'raghunathpur puruliya district','chaspara':'coochbehar','burdwan district':'burdwan','purbamedinipur district':'purba medinipur district','bira':'bora','paschim bardhaman district':'paschim bardhaman','barjora':'bahirgram','sainthia':'simhat','alipurduar':'alipurduar district','kendua':'kandi','siligurii':'siliguri','kalimpong district':'kalimpong','birpara tea garden':'birpara','bara':'barh','alipurduar rly jnc':'alipurduar district','bahula':'bally','kaliaganj':'kalas north','andul':'andal','mugkalyan':'maslandapur','purbo bardhaman':'purba bardhaman district','patuli':'patulia','north 24 parganas':'north barrackpur','begampur':'bishnupur bankura','sonada khasmahal':'sonatikiri','uttar kamakhyaguri':'uttar satali','sankrail':'singur','amtala':'andal','kurseong':'krishnanagar','alipore':'alipurduar district','bilpahari':'bolpur','bishnupur bankura district':'bishnupur bankura','masat south twenty four parganas district':'masat hugli district','cooch biher district':'coochbehar','maldah':'malda','jaigaon':'jaygaon','borai':'bora','bishnupur industrial growth centre':'bishnupur bankura','simlapal':'shimulpur','chopra':'chapari','jagadish pur':'jagadishpur','bankra':'bankura district','basantapur':'basanti','santoshpur':'sonatikiri','fatepur':'fatehpur','kshidirpur':'khidirpur','uttar dinajpur':'uttar dinajpur district','pandua':'panihati','bara suzapur':'bora gagangohalia','oodlabari':'odlabari','binnaguri':'bankura district','barda':'birodhi','chandonnagor':'chandannagar','dakshin dinajpur':'dakshin dinajpur district','parangarpar':'piarinagar','basudebpur murshidabad district':'basudebpur purba medinipur district','labhpur':'lapara','punchghara':'panskura','darjiling':'darjiling district','barrackpur':'barrackpore','haora':'howrah','baidyabati,':'baidyabati','krishnapur maldah district':'krishnanagar','rajpur bazar':'rajpur sonarpur','uttar kusum':'uttar satali','sonatala':'santaldih','purba bardhaman':'purba bardhaman district','baruipara':'birpara','dakshin khagrabari':'dakshin jhapardaha','hooghly':'hijuli','ramjibanpur':'rangabhita','shyamnagar':'singur','mira':'mahoor','panchghara':'panskura','balarampota':'balarampur puruliya district','jaynagar':'jaynagar mazilpur','kesabpur':'koch bihar','mahadeb nagar':'mathabhanga','nabgram':'nabagram colony','bhasa':'baska','deulia':'deuli','purbba narayanpur':'purba medinipur district','bongaon':'bangaon','jirat':'jhorhat','durgapur 13':'durgapur','rongmook ceder tea garden':'raniganj','dakshin dinaj pur':'dakshin dinajpur district','krishnapur hugli district':'krishnanagar','mahiari':'mira','barrackpure':'barrackpore','dakshin dnajpur':'dakshin dinajpur district','brasat':'barasat','coochbehar district':'coochbehar','nalahati':'nalhati','bowali':'bally','kalra':'kalara','perba medinipur district':'purba medinipur district','gangni':'gangnapur','samuktala':'samuktola','jemari':'jamuria','uttar mahammadpur':'uttar madarihat','baneswar':'bankura district','kenda':'kandi','bandi pur':'bandipur','uttar bishnupur':'uttar bagdogra','balarambati':'balarampur puruliya district','ramchandrapur':'raniganj','bishnupur birbhum district':'bishnupur bankura','district darjeeling':'district purbamedinipur','harirampur district':'harirampur','cooch bihar district':'coochbehar','bongan':'bangaon','dakhin rampur':'dakshin rajyadharpur','domjur':'dhanyakuria','dhuliyan':'dhulian','khardha':'khardaha','jujarsaha':'jujer saha','dhuilya':'deuli','gobardnga':'gobardanga','gangaram pur':'gangarampur','chakapara':'coochbehar','mal bazar':'malbazar','alipurdour':'alipurduar district','kendra khottamdi':'khantora','patihal':'patulia','hogli':'hijuli','uttar pirpur':'uttar bagdogra','arambagh':'arambag','chandipur maldah district':'chandpur south twenty four parganas district','bayarsing':'bara jumla','khardah':'khardaha','farakka pts township':'farakka barrage township','kolkata 150':'kolkata','khandra':'khantora','barrackpor':'barrackpore','arjun pur':'arjunpur','barua gopalpur':'barrackpore','kanaipur':'khanpur hugli district','north twenty four parganas':'north twenty four parganas district','khalor':'kalara','makardaha':'magra hat','balarampur south twenty four parganas district':'balarampur puruliya district','dakshin chatra':'dakshin jhapardaha','krishna sali':'krishnanagar','dhamua':'dhania','barddhaman district':'burdwan','cooch bihar':'coochbehar','chincheuria':'chinsurah','manbazer':'manbazar','purba bishnupur':'purba bardhaman district','paschim punropara':'paschim bardhaman','dakshin santoshpur':'dakshin jhapardaha','ranagaht':'ranaghat','coochbihar':'coochbehar','haldi bari':'haldibari','manushpur':'manikpur','south twenty four parganas':'south twenty four parganas district','paschim midnapore,':'paschim medinipur district','khalia':'kulia','chuk alampur':'chak alampur','shyampur haora district':'shyampur south twenty four parganas district','champahati':'champdani','aranghata':'aurangabad','asonsol':'asansol','mald':'malda','barddhaman':'burdwan','utter dinajpur':'uttar dinajpur district','kalaria':'kalara','kankinara':'kanganbaria','berachampa':'bara jumla','dakshin raypur':'dakshin rajyadharpur','purb medinipur district':'purba medinipur district','budge budgeooo':'budge budge','cooch behar district':'coochbehar','purbba tajpur':'par patiram','burdwen district':'burdwan','uttar jhapardaha':'uttar satali','utturdinajpur district':'uttar dinajpur district','paschim bainan':'paschim bardhaman','arangabad':'aurangabad','kolora':'kalara','poali':'phulia','paschim panchla':'paschim bardhaman','maynaguri':'mainaguri','uttarpara kotrang':'uttar bagdogra','kanganberia':'kanganbaria','murshidaabad':'murshidabad district','khargram':'kharsarai','jaykrishnapur hugli district':'jujer saha','paniara':'panuria','mandarboni':'mandarbani','chandpala anantapathpur':'chandpur south twenty four parganas district','chakdah':'chakdaha','kolkata 700023':'kolkata','baniban jagadishpur':'baniban','natibpur':'notibpur','howrah district':'haora district','santiniketan':'shyamdhan','nabagram':'nabagram colony','paschim midnapur':'paschim medinipur district','khajutti':'kakdihi','maldha':'malda','nalahat':'nalhati','uttardinajpur district':'uttar dinajpur district','samali':'simla','bardwan':'burdwan','alipur':'alipurduar district','kaliyaganj':'kalas north','chak baria':'coochbehar','mal':'mahal','jafarpur':'jafrabad','guskhara':'guskara','maldaha':'malda','chanddandaha':'chandannagar','joynagar':'jaynagar mazilpur','district purba bardhaman':'district purbamedinipur','north barrackpore':'north barrackpur','bhangarraghunathpur':'bankura district','kumardihi':'konardihi','jhantipahari':'jhanti pahari','coch bihar district':'coochbehar','barrackpoore':'barrackpore','hawrha':'howrah','baghmudni':'basanti','tarkeswar':'tarakeswar','bankul':'bangalpur','eksara':'egra','barrack pure':'barrackpore','howrha':'howrah','uttardinajpur':'uttar dinajpur district','poschim mednapur':'paschim medinipur district','jhargram district':'jhargram','kolaght':'kolkata','horipur':'haripur','bandel':'bandhail','nandakumar':'nandigram','basantia':'basanti','bhanderkhali':'bhandar gachha','kolkata105':'kolkata','baru pur':'birpara','dihimandalghat':'diamond harbour','amta 2':'amta','coochbahar':'coochbehar','digha nadia district':'dakshin dinajpur district','anantabati':'anantapur','alipurduer':'alipurduar district','pathar beria':'patharberia','chandpur north twenty four parganas district':'chandpur south twenty four parganas district','darjeeling district':'darjiling district','hugli':'hijuli','raichak':'raigachhi','karidhya':'khardaha','uttarpara kotrng':'uttar bagdogra','puraba medinipur':'purba medinipur district','dainhat':'dinhata','mangarjung tea garden':'mainaguri','new barrackpore':'new barrackpur','kolkata 39':'kolkata','purba midnapur':'purba medinipur district','bora,':'bora','bargachhia haora district':'bora gagangohalia','kolkata700019':'kolkata','sainthiya':'simhat','kolkata district':'kolkata','tarakeswer':'tarakeswar','kriparampur':'kharibari','baneshwarpur':'bankura district','rai pur bazar':'raipur bazar','naiti':'naihati','jhargaram':'jhargram','manbazar 2':'manbazar','coochbeher':'coochbehar','jagtaj':'jagadishpur','mosat hugli district':'masat hugli district','dhunki':'danga','ulubaria':'uluberia','kokapur':'koch bihar','alipur duar':'alipurduar district','habra 2':'habra','kolkata 700057':'kolkata','nawapara':'nibra','kolkatta':'kolkata','kanchrapar':'kanchrapara','makardaha 2':'magra hat','uttarpara':'uttar bagdogra','raghunathganj':'raghunathpur puruliya district','ahmedpur':'ahmadpur','barunda':'brindabanpur','chhekati':'chakdaha','kolkata700006':'kolkata','south dumdum':'south twenty four parganas district','kamarhati':'konardihi','north dumdum':'north twenty four parganas district','baranagar':'birnagar','chandpara':'chandpur south twenty four parganas district','jaynagar majilpur':'jaynagar mazilpur','tarkeshwar':'tarakeswar','panagarh':'panskura','chandrakona road':'chandrakona','belda':'baluhati','bajkul':'bagula','ramnagarwb':'ramkrishnapur','ama dubi':'ahmadpur','hura':'howrah','balarampur':'balarampur puruliya district','bhaddi':'buita','baghmundi':'bagnan','barobisha':'barabazar','labpur':'lapara','bamangola':'bamangram','north dinajpur':'north twenty four parganas district','bhagabati':'bhagabatipur','lodhan':'lutunia','bijanbari':'bishnupur bankura','sonada':'simhat','mungpoo':'manikpur','gourbathan':'garbeta','mekhliganj':'mekliganj','kalchini':'kalas north','pundibari':'pandaveswar wb','hanskhali':'hingalganj','haringhata':'haringhata farm','nowda':'naihati','baharampur':'berhampore','lohapur':'lapara','ghanashyampur':'gangnapur','dakshin barasat':'dakshin baguan','batanagar':'bidhannagar','gangasagar':'gangajalghati','rajarhat':'rajarhat gopalpur','kishanganj':'kishanganj district','visakhapatnam district':'visakhapatnam','srikakulam district':'srikakulam','vijayawada':'vijayawada 1','guntur':'guntur district','kurnool district':'kurnool','west godavari':'west godavari district','anantapur district':'anantapur','vizianagaram':'vizianagaram district','vizinagaram district':'vizianagaram district','tadepalligudem':'tadepalli','anantapuram':'anantapur','krishna':'krishna district','atmakur sri potti sriramulu':'atmakur','chebrole khandrika':'chebrolu','tedeplle':'tadepalli','narsipatnam':'narasapur','prakasam':'prakasam district','vishakhapatnam':'visakhapatnam','tadapalli':'tadepalli','amaravati':'amravati','puttaparthi':'peddapuram','mydukur':'muttukuru','pamur':'ponnur','koikuntla':'kakinada','bethamcherla':'betamcharla','jangareddygudem':'jangareddigudem','madanapalli':'madanapalle','palakol':'palacole','warangal':'warangal rural district','parvathipuram':'paravada industrial area','sullurupet':'sullurupeta','anakapalli':'anakapalle','banaganapalli':'banaganapalle','pithapuram':'peddapuram','tadipatri':'tadpatri','amaravathi':'amaravati','giddaluru':'giddalur','dwarakatirumala':'dwaraka tirumala','salur':'sulluru','gundugolanu':'guntakal','paderu':'puttur','vissannapeta':'vissannapet','tiruchanur 517503':'tiruchanur','piler':'pileru','jaggayyapet':'jaggaiahpet','anaparthy':'annavaram','anantapalli':'anantapur','industrial growth centre thimmanapalem':'industrial park naidupet','adonio':'adoni','mummidivaram':'mandapeta','sulluru peta':'sullurupeta','sattenapalli':'sattenapalle','kadiri io':'kadiri','sullurpeta':'sullurupeta','rajahmundry rural':'rajahmundry','mylvaram':'mylavaram','vijayawada 520012':'vijayawada 1','srisailam':'srikalahasti','proddutur':'proddatur','punganuru':'punganur','guntur2':'guntur district','industrial park gollapuram':'industrial park naidupet','india cement factory chilamakuru':'industrial park naidupet','narasapuram':'narasapur','narasaraopeta':'narasaraopet','gajpathinagaram':'gajapathinagaram','pedapudi':'pathapatnam','chittor':'chittoor','kondapalli':'kondapalle','chintapalli':'chintapalle','east godvari':'east godavari district','wast godavari district':'west godavari district','nidadavolu':'nidadavole','vizianagram':'vizianagaram district','kotabammali':'kotabammal','macherlau':'macherla','nakkapalli':'nakkapalle','visakh apatnam district':'visakhapatnam','srungavarapu kota':'srungavarapukota','gudivada visakhapatnam district':'gudivada krishna district','vizainagaram':'vizianagaram district','rayachoty':'rayachoti','ponduru':'pondura','kovveru':'kovvur','tadepalligudem 2':'tadepalli','porumaimilla':'porumamilla','vizag':'vizage','kurnool city':'kurnool','payakarao peta':'payakaraopeta','kotabommali':'kotabammal','cheepurupalli':'chipurupalle','pithapuram rural':'peddapuram','kantabamsuguda':'kondapalle','sullurpete':'sullurupeta','narsaraopet':'narasaraopet','sullur pata':'sullurupeta','visakhapatnem':'visakhapatnam','hydrabad':'hyderabad','ankapalli':'anakapalle','managalagiri':'mangalagiri','sullurupeata':'sullurupeta','sullurpet':'sullurupeta','westgodavari':'west godavari district','jangareddy gudem':'jangareddigudem','peda boddepalle':'pathapatnam','vijayanagaram':'vizianagaram district','gudivada':'gudivada krishna district','attili':'attilli','naidupet':'nayudupeta','renigunta':'ramachandrapuram','penukonda':'punganur','urvakonda':'uravakonda','rayadurgam':'rayadurg','koduru':'kadiri','rompicharla':'rampachodavaram','chowdepalli':'chitvel','venkatagirikota':'venkatagiri','koilakuntla':'koilkuntla','betamcherla':'betamcharla','nandikotkur':'nandigama','kodumuru':'kodumur','kaikaluru':'kaikalur','pamarru':'ponnur','pedapadu':'pathapatnam','dachepalli':'dachepalle','martur':'maruteru','parchoor':'perecherla','addanki':'atmakur','kondapi':'kondapalle','tripuranthakam':'tiruvuru','yerragonda palem':'yerraguntla','cumbumap':'cumbum','naidupeta':'nayudupeta','vinjamur':'vinukonda','alluru':'allur','yellamanchili':'yelamanchili','ichapuram':'ichchapuram','narsipuram':'narasapur','godavari':'gowthavaram','rajahmundary':'rajahmundry','kothapalli':'kothavalasa','penugonda':'punganur','palakollu':'palacole','chintalapudi':'chintalavalasa','chintalpudi':'chintalavalasa','pendurthi':'pondura','bhogapuram':'bogappuram','padmanabham':'pedanandipadu','gajapatinagaram':'gajapathinagaram','aurangabad district':'aurangabad','palghar':'palghar district','sindi':'sindewahi','jalgaon jamod':'jalgaon district','rajur ahmadnagar district':'rajgurunagar khed','yavatmal district':'yavatmal','ratnagiri district':'ratnagiri','jalgaon':'jalgaon district','ahmed nagar':'ahmadnagar','ahmadnagar district':'ahmadnagar','nanded district':'nanded waghala','nagpur district':'nagpur','sangole':'sangli district','beed':'bid','chikhala':'chikhli','amravati district':'amravati','nanded':'nanded waghala','nandura':'nandurbar','beed district':'bid district','warud':'wardha','kolhapur':'kolhapur district','nandurbar district':'nandurbar','buldana district':'buldana','chandur amravati district':'chandrapur district','sangli miraj kupwad':'sangli district','karjat raigarh district':'kurkheda','vaijapur':'vasai virar','pen':'pune','bhandara midc':'bhandara','sholapur':'solapur district','umarkhed':'umarga','bhandara district':'bhandara','vita':'vada','pone':'pune','osmanabad':'osmanabad district','chandur chandrapur district':'chandrapur district','akkalkuwa':'akluj','aurngabad':'aurangabad district','parbhani district':'parbhani','ahmednagar':'ahmadnagar','khandala satara':'kondhali','ghatanji':'gadhinglaj','ashta':'akodia','yawal':'yeola','dombivali':'dombivli','bhokar':'boisar','hingoli district':'hingoli','ahmednagar district':'ahmadnagar','koregaon':'kurkumbh midc','gadchiroli':'gadchiroli district','dindori':'dindori district','sangameshwar':'sangamner','talegaon midc':'talegaon dabhade','kalyan e':'kalyan','balapur hingoli district':'balapur','darwha':'deori','pandharkaoda':'pandharpur','tarapur textile park':'tarapur','rajura':'raigarh','sangola':'sangli district','shivaji nagar':'shevgaon','pauni':'pune','kannad':'kinwat','shirol':'shirala','sawantwadi':'sindhudurg district','hingoli midc':'hingoli','mahad midc':'mohadi midc','manmad':'mantha','puna':'pune','kudal':'katol','kherdi':'karad','mombai':'mumbai','ambepur':'aamby valley','ambejogai':'ambajogai','sengaon':'sangamner','saoner':'sinnar','sangli':'sangli district','tiror':'tirora','ambernath':'ambarnath','karjat ahmadnagar district':'kurkheda','akkalkot':'akluj','kalwan bk':'kalamb','mahad':'mauda','thana':'thane','nandgaonpeth midc':'nandgaon','kallam':'kalyan','krushnoor midc':'kurkumbh midc','chicholi':'chichli','pandare midc':'pandharpur','mhaswad':'mukhed','mowad':'mauda','mokhada':'mukhed','mangrulpir':'manchar','manjlegaon':'mangalvedha','sailu':'selu','ahemadnagar':'ahmadnagar','phaltan sez midc':'phaltan','khandala midc':'kondhali','panvel':'pimpalner','pathri':'patur','vinchur':'vengurla','chandurbazar':'chandrapur district','deoni':'dahanu','shirwal':'shirala','pimpalgaon baswant':'pimpalner','basmat midc':'basmath','manora':'manor','rajgurunagar, khed':'rajgurunagar khed','mul':'mohol','hingna':'hinganghat','madha':'mauda','sawangi megh':'sangamner','sindkheda':'sindkhed raja','miraj':'morshi','shendra midc':'samudrapur','shirur anantpal':'shrirampur','pulgoan':'pulgaon','murud janjira':'murtajapur','degloor':'deglur','umerkhed':'umarga','malegaon jahangir':'malegaon','raigad':'risod','butibori midc':'butibori','roha midc':'ramtek','mirabaheyndar':'mira bhayandar','malkapur kolhapur district':'malkapur buldana district','kalwan':'kalyan','mehker':'mehkar','murbad midc':'murbad','jamner':'junnar','ahemdnagar district':'ahmadnagar','dandi':'daund','goregaon gondiya district':'goregaon','deola':'dhule','nagothane':'nagothana','kadegaon midc':'kadegaon','shrivardhan':'shirpur','roha':'raha','hadgaon':'hatkanangle','khandala':'kondhali','pampalner':'pimpalner','vasai virar city':'vasai virar','mouda':'mauda','lonavla':'lonavala','tasgoan':'tasgaon','kundalwadi':'kondhali','kamptee cantt civil township':'kamptee','nasik':'nashik','parola':'parli','navimumbai':'navi mumbai','nira':'ner','warthi':'wardha','nandgaon khandeshwar':'nandgaon','umarga midc':'umarga','jalgoan':'jalgaon district','osmanabad city':'osmanabad district','jalana':'jalna','shendurjana':'samudrapur','kalyan dombivali':'kalyan dombivli','himayatnagar':'hindnagar','kandahr':'kandhar','kalmeshwar':'kalameshwar midc','dondaicha warwadee':'dondaicha warwade','sindewahi midc':'shinde midc','chandur chndrapur district':'chandrapur district','mahadula':'motala','radhanagari':'ratnagiri','singnapur kopargaon':'sangamner','sinner':'sinnar','padgha':'padagha','ahemadpur':'ahmadpur','malkapur,buldana':'malkapur buldana district','mum2bai':'mumbai','korochi':'korchi','chandrpur':'chandrapur district','nimbhore budruk':'nampur','chandrapur cggc':'chandrapur district','gondia':'gondiya','manwath':'mantha','kamthi':'kinwat','dehuroad':'dehu road','bhoom':'bhum','nandgaon pode':'nandgaon','kalameshwar':'kalameshwar midc','amgaon':'anjangaon','hatkanangale':'hatkanangle','koradi':'karad','sawali':'selu','malegaon midc':'malegaon','surgana':'shrigonda','malkapur midc':'malkapur buldana district','kelapur':'kolhapur district','bhanadara':'bhandara','budhgaon':'bhadgaon','muktainager':'muktainagar','pombhurna':'pimpri chinchwad','honad industrial area':'hindnagar','naishik':'nashik','partur midc':'partur','jiwati':'jath','mumbaii':'mumbai','kalamb yavatmal district':'kalamb','baramat':'baramati','kandri mines':'kandhar','amgaon bk':'anjangaon','indapur midc':'indapur','jalagaon':'jalgaon district','shani shingnapur':'sangamner','koregaon bhima':'kurkumbh midc','aurangabad industrial city':'aurangabad district','ambarnath e':'ambarnath','hinganghat 442203':'hinganghat','bramhapuri':'brahmapuri','mumbai suberban':'mumbai suburban','mumbi':'mumbai','ganeshpur':'gangapur','chandrapur midc':'chandrapur district','asangaon industrial area':'asangaon','mumbai400002':'mumbai','mahur':'marowa','tumsar road':'tumsar','jawahar nagar':'jawharnagar','kandri nagpur':'kandhar','ahamdnagar':'ahmadnagar','district osmanabad':'district buldana','ettapalli':'etapalli','hadagaon':'hatkanangle','jintur midc':'jintur','maharashtra industrial development corporation':'murgud','murtijapur':'murtajapur','hinganghat midc':'hinganghat','mohopada alias wasambe':'mohpada alias wasambe','dabhol':'dapoli','mangalwedha':'mangalvedha','kundal':'kondhali','mohadi':'mauda','shirpur warwade':'shirpur','pune262804':'pune','district palghar':'district buldana','saoner midc':'sinnar midc','raiged':'risod','kolhapure':'kolhapur district','sindhudurg':'sindhudurg district','pimprichinchwad':'pimpri chinchwad','hatkanagale':'hatkanangle','medha':'mauda','ahemdpur':'ahmadpur','kandari':'kandhar','pimpri':'pimpri chinchwad','karjat':'kurkheda','malkapur':'malkapur buldana district','mangalvedhe':'mangalvedha','shahade':'shahada','soyagaon':'shegaon','talode':'taloda','vadgaon kasba':'vadgaon','wadgaon road':'wadgaon','mira bhayander':'mira bhayandar','lonere':'lonar','banda mh':'bhiwandi nizampur','saidapura satara':'saidapur','ambegaon':'ambajogai','rajgurunagar':'rajgurunagar khed','pargaon mh':'parshioni','dhayari':'deori','talegaon':'talegaon dabhade','ranjangaon':'ranjangaon midc','mandrup':'maindargi','temburni':'tembhurni midc','sonari mh':'sinnar midc','walchandnagar':'waluj midc','malashiras':'malshiras','jeur':'jawhar','mahisgaon':'mahagaon','malsiras':'malshiras','atpadi':'atapadi','shirur anantapal':'shrirampur','kallamb':'kalamb','ashti':'akot','kada':'khed','patan mh':'pathan midc','mayani':'mihan','gadhingalaj':'gadhinglaj','mudal':'motala','mudhal':'motala','veeta':'vada','asangijath':'asangaon','halkarni':'halkarni midc','talere':'telhara','wada mh':'wadwani','saikheda':'saswad','dindori mh':'dindori','ojhar':'ozar','nifad':'niphad','akole':'akola','talegaon dhige':'talegaon dabhade','shindkheda':'sindkhed raja','akkalkuva':'akluj','borad':'birwadi','majalgaon':'musalgaon midc','vasmat':'vashind','kingaon':'khamgaon','gangakher':'gangakhed','sarkhani':'shrigonda','aundha nagnath':'ahmadnagar','kurkhude':'kurkheda','saoli':'selu','gondpipari':'gondpipri','arjunimorgaon':'arjunwad','arjuni morgaon':'arjunwad','talegaon sp':'talegaon dabhade','allapali':'allapalli','deaulgaon raja':'deulgaon raja','murtizapur':'murtajapur','dahihanda':'daund','amdapur':'ahmadpur','manglurpir':'mangalvedha','mangrul pir':'manchar','daryapur':'daryapur banosa','chandur railway':'chandrapur district','paratwadda':'paratwada','akola bazar':'achalpur','darwah':'deori','pandharkawada':'pandharpur','shahadra':'shahdara','south west delhi':'south east delhi','north east':'north west delhi','north district':'north delhi','north west district':'north west delhi','south west district':'south west delhi','new delhi8':'new delhi','new delh':'new delhi','central district':'central delhi','north east district':'north west delhi','newdelhi':'new delhi','south east delhi district':'south west delhi','central':'central delhi','patna':'patan','bhagalpur':'bhagalpur district','muzaffarpur district':'muzaffarpur','gopalganj':'gopalganj district','darbhanga':'darbhanga district','begusarai district':'begusarai','sitamarhi district':'sitamarhi','madhubani':'madhubani district','lakhisarai district':'lakhisarai','samastipur':'samastipur district','munger':'munger district','madhepura district':'madhepura','buxar':'bakhri','purbi champaran district':'purba champaran district','sheikhpura':'sheikhpura district','motipur':'madhepura','jehanabad district':'jehanabad','teghra':'tikari','purbi champaran':'purba champaran district','nalanda':'nalanda district','bikram':'bikramganj','barauni 1':'barauni','jhanjharpur':'jainagar','rosera':'rajgir','puraini':'purnia','bhabua':'bhabhua','baruni':'barauni','jahanabad':'jehanabad','manihari':'maner','jogbani':'jogabani','bihar sharif':'biharsharif','paria':'piro','mansur chak':'munger district','sonpur':'sonepur','sherghati':'saharsa district','bihat begusarai district':'bihta begusarai district','pashchim champaran':'pashchim champaran district','bihiya':'behea','barahiya':'barh','saraiya':'sheohar','muzffarpur':'muzaffarpur','kesaria':'khagaria','mirganj,':'mirganj','bakhtiyarpur':'bakhtiarpur','betia':'bettiah','barauni ioc town ship':'barauni ioc township','behia':'behea','hazipur':'hajipur','kumarbagh':'kaimur bhabua district','patna800014':'patna','darbhang':'darbhanga district','bauxar':'bakhri','kaimur bhabua':'kaimur bhabua district','samstipur':'samastipur district','koath':'kataiya','darbhangaa':'darbhanga district','mahnar':'maner','purvi champaran':'purba champaran district','purba champaran':'purba champaran district','patnaa district':'patna district','district vaishali':'district saharsa','begusari':'begusarai','pareo':'piro','tekari':'tikari','nalnda':'nalanda district','purbichamparn':'purba champaran district','purbai champaran district':'purba champaran district','bhojpur':'bhojpur district','amarpur,':'amarpur','bihat':'bettiah','bagusarai':'begusarai','patna city':'patna sadar','chenari':'chanari','madhupra district':'madhepura','purbaichamparan district':'purba champaran district','purnea':'purnia','purbichamparan district':'purba champaran district','district rohtas':'district saharsa','bhagirathpur':'buxar district','bagaha 2':'bagaha','bhadurganj':'bahadurganj','district sitamarhi':'district saharsa','piru':'piro','sheoahr':'sheohar','district saran':'district saharsa','district patna':'district saharsa','district araria':'district saharsa','shekhpura':'sheikhpura district','district nalanda':'district saharsa','bhaglapur':'bhagalpur district','bagha':'bagaha','khalgaon':'kahalgaon','raxaul':'rajauli','banmankhi bazaar':'banmankhi bazar','purbichamparan':'purba champaran district','warisali ganj':'warisaliganj','baruani':'barauni','begusrai':'begusarai','khagria':'khagaria','drabhanga':'darbhanga district','behiya':'behea','district begusarai':'district saharsa','forbisganj':'forbesganj','kargahia purab':'kharagpur','district buxar':'district saharsa','bnaka':'banka','gopalgunj':'gopalganj district','buxer':'bakhri','district darbhanga':'district saharsa','sherghatio':'saharsa district','bxer':'bakhri','district muzaffarpur':'district saharsa','sahars':'saharsa','fatuha':'fatwah','bihta':'bettiah','sandesh':'siwan district','sheonar':'sanrha','mokama':'mokameh','nawadha':'nawada','brahmpur bh':'brahmapur','chakai':'chakia','katoriya':'katihar','kudra':'katihar','naugachia':'naugachhia','goh':'gaya','barachatti':'barasat','hajipur town':'hajipur','marhowarah':'marhaura','baniapur':'benipur','mojharia':'masaurhi','aurai':'arrah','sarai':'sheohar','sonbarsa':'sonepur','champaran':'chainpur','rusera':'rajgir','simri bakthiyarpur':'simrahi bazar','bhawanipur rajdham':'benipur','baisi':'bagaha','kulgam district':'kulgam','anantnag district':'anantnag','budgam':'badgam','baramula':'baramula district','badgam district':'badgam','ganderbal district':'ganderbal','udhampur district':'udhampur','rajauri':'rajouri','ranbirsinghpura':'ranbirsinghpora','vijay pur':'vijay pore','gurha salathian':'gorah salathian','baramulla':'baramula district','ananatnag':'anantnag','bishnai':'bishna','ranbir singh pura':'ranbirsinghpora','birpurjk':'bari brahmana epip industrial estate','hira nagar':'hiranagar','thrippunithura':'thiruvananthapuram','thiruvananthapuram district':'thiruvananthapuram','thrissur district':'thrissur','palakkad district':'palakkad','vakkom':'vaikom','kozhikode district':'kozhikode','edavilangu':'edappal','malappuram':'malappuram district','alappuzha district':'alappuzha','ernakulam':'ernakulam district','sreekantapuram':'sreekandapuram','kasaragod':'kasaragod district','chengannur':'changanacherry','idukki township':'idukki district','anakkayam':'angamaly','thrikkadavoor':'thrikkodithanam','kothamangalam':'kattanam','kuttippuram':'kattipparuthi','munnar':'maniyur','kadalundi':'koottilangadi','kasargode':'kasaragod district','kanjikode industrial area':'kanjikkuzhi','vadakkumkara':'vadakkumthala','alamcode':'alangad','mananthavady':'manantheri','pathanamthitta':'pathanamthitta district','palai':'pala','kanjirappally':'kanjiramkulam','kunnamkulam':'kanhangad','kottuvally':'kadavallur','kunnathunad':'kandanassery','azhoor':'azhiyur','pattambi':'puthenvelikkara','trivandrum':'thiruvananthapuram','mavelikkara':'mavelikara','kasargod':'kasaragod district','ayanivelikulangara':'amballur thrissur district','kedamangalam':'kattanam','perumanna malappuram district':'perumanna','kannamangalam alappuzha district':'kunnamangalam','vayalar':'veiloor','cherthala':'cherthalai','kottamkara':'kodungallur','kuthuparamba':'kattipparuthi','meenad':'mayyanad','puranattukara':'perinthalmanna','perinad':'perinthalmanna','kadungalloor':'kodungallur','perumbaikad':'perumbavoor','moonniyur':'maniyur','panmana':'ponnani','payyannur':'punnayur','veluthur':'vylathur','mannar':'maniyur','koduvally':'kadavallur','poolacode':'palakkad','iringal':'irinjalakuda','padiyam':'pattiom','chengalam south':'chengala','thuneri':'thanoor','peramangalam':'perumanna','talikkulam':'thalakkulathur','chengamanad':'changanacherry','chiramanangad':'cheriyamundam','kuttikkattoor':'kadikkad','kalady malappuram district':'kulathummal','puthuppally alappuzha district':'paduvilayi','pinarayi':'punnayur','peringandoor':'perinjanam','eranholi':'eramalloor','koduvayur':'kattipparuthi','kizhuppillikkara':'kizhuvalam koonthalloor','eranakulam':'ernakulam district','puthuppally':'paduvilayi','thiruvankulam':'thiruvananthapuram','peringathur':'perinjanam','pallippuram thiruvananthapuram district':'pallippuram alappuzha district','meppayyur':'mavoor','koothuparamba':'kattipparuthi','kunhimangalam':'kunnamangalam','kadamakkudy':'kodungallur','iroopara':'iriveri','meppayyour':'mavoor','erankulam':'ernakulam district','thrikkaruva':'thrissur','karamuck':'karunagappally','ayancheri':'anjur','calicut':'chalakudy','thikkody':'thaikkad','chingoli':'chengala','kakkanadu':'kakkanad','tanur':'thanoor','peermade':'perinthalmanna','parappur':'paravoor','panoor':'punnayur','mayilappuram':'malappuram district','pallikkal':'pallichal','vaniyamkulam ii':'vaniyamkulam','maniyoor':'maniyur','puthunagaram':'puthencruz','tiruvalla':'thiruvalla','panayam':'ponnani','eramala':'eramalloor','earamala':'eramalloor','kalliasseri':'kola cherry','peruvallur':'peruvayal','thrssur':'thrissur','kanhiroade':'kannur district','villiappally':'vilappil','pookode':'puzhathi','trikkur':'thrissur','thrissure district':'thrissur','thurayur':'tirur','kozhkode':'kakkodi','arookutty':'areacod','pilicode':'palakkad','poomangalam':'panangad thrissur district','nedumbassery':'nedumpana','madayikonam':'moothakunnam','puthur':'pathiyoor','channithala':'choondal','kudlu':'koodali','valanchery':'valancherry','kolacherry':'kola cherry','alamcode thiruvananthapuram district':'alangad','vadakkekad':'vadakkekara','parappanangadi':'piravam','chalakudi':'chalakudy','changanassery':'changanacherry','palakkadu':'palakkad','karikkad':'kureekkad','karthikappally':'kurattissery','velur':'vellore','cheru thazham':'cheruthazham','karunagapplly':'karunagappally','thrissur,':'thrissur','kainoor':'kannur','perumbaikadu':'perumbavoor','vatakara':'vadakara','vadakkummuri':'vadakkumthala','alleppey':'aluva','ancharakandy':'anjur','mannarkad i':'mannarkad','ongallur ii':'ongallur','thalasery':'thalassery','koch':'kochi','chennithala':'choondal','guruvayoor':'guruvayur','kallettumkara':'kulathummal','kottayam malabar':'kattanam','taliparamb':'taliparamba','kizhakkummuri':'kizhakkumbhagom','kattur':'kodur','nedumangadu':'nedumangad','nedumpura':'nedumpana','ambalapuzha':'amballur thrissur district','azhikode north':'azhikode','thaliparamba':'taliparamba','paravur':'paravoor','payyoli':'pala','ernakulm':'ernakulam district','kanhirode':'kannur district','kaniyarkode':'kumarakom','amballur':'amballur thrissur district','perumanna malappuram':'perumanna','thaliparambu':'taliparamba','iringaprom':'irinjalakuda','malapuram':'malappuram district','azhikode south':'azhikode','kandamkunnu':'kandanassery','kasargoad':'kasaragod district','kumly':'kumily','thirivananthapuram':'thiruvananthapuram','eranellur':'eramalloor','kozhikode, district':'kozhikode','kuruvattoor':'kuruvattur','kuttanad':'kottayam district','pallippuram':'pallippuram alappuzha district','kattoor':'kodur','kasaragode':'kasaragod district','kalady,, malappuram district':'kulathummal','kodamthuruth':'kottayam district','kozhencherry':'kozhenchery','minalur':'manalur','kottappally':'kadavallur','kasaragode district':'kasaragod district','kokkothamangalam':'keezhattingal','tripunithura':'thiruvananthapuram','kozhikod':'kozhikode','piravom':'piravam','ariyallur,':'ariyallur','pathnamthitta district':'pathanamthitta district','kozhikide':'kozhikode','maramapilly':'marampilly','maniyat':'mayyanad','pirayri':'pirayiri','koothali':'koodali','edathirinji':'edathiruthy','kasargod district':'kasaragod district','dharmadam':'dharmadom','chengannuer':'changanacherry','vadakkumbhagom':'vadakkumthala','kottayaam district':'kottayam district','chelembra':'chelambra','marampally':'marampilly','nanmanda13':'nanmanda','manakkody':'mangattidam','palghat':'palakkad','kottarakkra':'kottarakkara','minalor':'manalur','tellicherry':'thalassery','kallettumkara,':'kulathummal','panangad':'panangad thrissur district','pathanapuram':'puthenvelikkara','changanachery':'changanacherry','koothuparamb':'kattipparuthi','angamalay':'angamaly','keerikkad':'kureekkad','north paravoor':'north paravur','kuthu pramba':'kattipparuthi','nilamboor':'nilambur','kolavalloor':'kolavelloor','kottappuram':'kattipparuthi','kottarakkara ,':'kottarakkara','porkulam':'parassala','panamattom':'ponmundam','koyilandy':'kollam district','payyanur':'punnayur','kiliyanthara':'kollam district','mananthavadi':'manantheri','peravoor':'paravoor','chervathur':'cheruvathur','kuttikol':'kottakal','nochad':'nuchiyad','perambra':'perumbavoor','ayanchery':'anjur','sultan bathery':'sulthan bathery','areacode':'areacod','manjery':'manjeri','kottakkal':'kottakal','vadakkenchery':'vadakkumthala','anjumoorthy':'angamaly','karimba':'kurumpilavu','ottapalam':'ottappalam','trichur':'thrissur','trisshur':'thrissur','elamakkara':'elamkunnapuzha','kuruppampadi':'karuvanthuruthy','angamally':'angamaly','nedumkandam':'neyyattinkara','kuthumkal':'kodungallur','iddukki':'idukki','kottiyam':'kottayam','karukachal':'kurichikkara','tiruvella':'thiruvalla','kothanalloor':'kadayanallur','kaduthuruthy':'kuttiattoor','allapey':'aluva','manthuka':'mundakayam','mavelikera':'mavelikara','kalanjoor':'kalamassery','karunagapalli':'karunagappally','parippally':'peruvayal','kottarakarra':'kottarakkara','thiruvantapuram':'thiruvananthapuram','kazhakkoottam':'kozhikode','technopark campus':'thekkumbhagom','venjaramoodu':'vengara','udham singh nagar':'udham singh nagar district','hardwar district':'haridwar','dehradun district':'dehradun','almora':'almora district','rudraprayag':'rudrapur','pithoragarh district':'pithoragarh','nainital':'nainital district','gauchar':'gochar','bhimtaal':'bhimtal','haridwar district':'haridwar','bhagwanpur':'begumpur','sringar':'srinagar','udhamsingh nagar':'udham singh nagar district','dheradoon':'dehradun','bageshwar district':'bageshwar','rudraprayag district':'rudrapur','sidicul haridwar':'sidcul haridwar','karan prayag':'karnaprayag','rudrpur':'rudrapur','uttarkashi district':'uttarkashi','kotdwar':'kotdwara','rudrapur district':'rudrapur','nandprayag':'nand prayag','pant nagar':'pantnagar','ramngar':'ramnagar','bajpur':'bazpur','champawat':'champawat district','nandaprayag':'nand prayag','narendranagar':'narendra nagar','srinagar, uttarakhand':'srinagar','srinagar garhwal':'srinagar','charkhi dadri district':'charkhi dadri','karnal district':'karnal','gurgaon district':'gurgaon','mahendragarh':'mandhar industrial area','fatehabad district':'fatehabad','yamunanagar district':'yamunanagar','kundli':'kundli industrial area','mahendragarh district':'mahendragarh','ambala district':'ambala','sonipat district':'sonipat','kurukshetra district':'kurukshetra','sonepat':'sonipat','buria':'beri','panipat district':'panipat','yamuna nagar':'yamunanagar','chandimandir':'chandi mandir','faridabad district':'faridabad','ambala city':'ambala','mahender garh':'mahendragarh','panchkula district':'panchkula','sirsaaa':'sirsa','bhondsi':'bhiwani district','sohna':'siwani','sahibzada ajit singh nagar':'sahibzada ajit singh nagar district','mahendergarh':'mahendragarh','meham':'maham','gurgoan':'gurgaon','punhana':'punahana','tauru':'taoru','sonapat':'sonipat','fatehbaad':'fatehabad','jakhal mandi':'jakhalmandi','pinjor':'pinjore','firozpur jhirka':'ferozepur jhirka','panipat refinery township':'panipat','mahindergarh':'mahendragarh','baghola':'bhakali','naranual':'narnaul','pingwan':'pinagwan','bahadur garh':'bahadurgarh','fathebad':'fatehabad','gurugaon':'gurgaon','district jhajjar':'district sirsa','sarsod':'sirsa district','daruhera':'dharuhera','gurgaon rto cards':'gurgaon','gurgaon pataudi':'gurgaon','hissar':'hisar','bhuna':'bhiwani','bahal':'bawal','gannaur':'ganaur','ambala cantt':'ambala','sadhaura':'sadaura','gurgaon cpc':'gurgaon','mandi adampur':'mandi dabwali','ratlam district':'ratlam','singrauli district':'shamgarh','tikamgarh district':'tikamgarh','singrauli':'shamgarh','balaghat district':'balaghat','anuppur district':'anuppur','ashoknagar district':'ashoknagar','indergarh':'indore','patharia':'pithora','hoshangabad district':'hoshangabad','kanad':'khandwa','sihora':'sehore','chhindwara district':'chhindwara','burhanpur district':'burhanpur','mandsaur':'mandsaur district','khargone west nimar district':'khargone','mandla':'mandla district','kannod':'khandwa','jabalpur district':'jabalpur','narsimhapur district':'narsingarh','sheopur':'shivpuri','beohari':'baihar','shajapur district':'sohagpur','ashok nagar':'ashoknagar','khor':'khurai','alirajpur':'alirajpur district','indore district':'indore','rajgarh district':'rajgarh dhar district','budni':'badoni','sendhwa':'sanawad','majhauli':'majholi','narshinghpur':'narsingarh','rau':'rewa','gurh':'ghuwara','nagda':'nagod','suthaliya':'shahdol','shajapur':'sohagpur','sanwer':'semaria','bijawar':'bijuri','mungaoli':'mangalya','pichhore shivpuri district':'pichhore gwalior district','narsinghgarh':'narsingarh','keolari':'kelhauri','khaniyadhana':'kundam','biaora':'baihar','katni':'kotma','seondha':'sanawad','tendukheda narsimhapur district':'tendukheda damoh district','jaithari':'jaitwara','sheopur district':'shivpuri district','barela':'bareli','pithampur industrial hub':'pithampur','mangliya':'mangalya','mauganj':'meghnagar','narsimhapur':'narsingarh','rampur naikin':'rampur baghelan','joura':'jaora','sitamau':'satna','damua':'damoh','bargi':'berasia','jatara':'jaitwara','majhgawan':'mehgaon','betma':'badoni','sailana':'silwani','sironj':'sarangpur','indor':'indore','dongar parasia':'dungariya chhapara','chanderi':'chhindwara','pachmarhi cantt':'pachmarhi','shahpura dindori district':'shivpuri district','kasrawad':'khacharod','barwaha':'baihar','nasrullganj':'nasrullaganj','bhikangaon':'begamganj','nanpur':'nainpur','siya industrial area':'seoni district','amlai':'amla','bhourasa':'berasia','kakarhati':'khacharod','bichhiya':'buxwaha','katangi balaghat district':'katangi','bamor, morena':'bamor morena','boda':'badi','mandala':'mandla district','bina etawa':'bhind','kurwai':'khurai','hat piplia':'hatpiplia','ranapur':'rampur baghelan','gohad62':'gohad','diken':'dighawani','nagri':'nai garhi','dhana':'damoh','shahpur burhanpur district':'shahpur betul district','katangi jabalpur district':'katangi','borgaon':'birsinghpur','piplya mandi':'piplanarayanwar','khand':'khandwa','gandhi sagar haidel':'guna district','sawer':'sehore','murena':'morena','shahgarh':'sausar','jawar':'jaora','sirmaur':'sirmaur district','goraiya':'ghuwara','mandleshwar':'mandla district','suwasara':'sausar','district chhindwara':'district shivpuri','khachrod':'khacharod','khetia':'kothi','mandsour district':'mandsaur district','vindhya nagar':'vindhya nagar ntpc township','bhonrasa':'bamor shivpuri district','barwah':'baihar','garra':'ghuwara','obaidullaganj':'obaidullganj','shahpur sagar district':'shahpura jabalpur district','mohgaon':'mehgaon','badoda':'badod','satai':'sidhi','narsinghpur':'narsingarh','ladhaura':'lateri','begumganj':'begamganj','seehore':'sehore','badawada':'badod','singruli':'shamgarh','bhabhra':'bhavra','deohara':'dhar','jablpur':'jabalpur','polay kalan':'polaykalan','amanganj chhatarpur district':'amanganj panna district','singrouli':'shamgarh','bagh':'buxwaha','singrauli colliery':'shamgarh','mandasur':'mandsaur district','devendra nagar':'devendranagar','bansatar kheda':'bhainsdehi','lodhikheda':'lodhikheda,','ghansore':'ghansaur','ashokanagar':'ashoknagar','pindrai':'pandhurna','district dindori':'district shivpuri','mhow cantonment':'majhgawan township','mhowgaon':'mehgaon','wara seoni':'waraseoni','bediya':'badi','khragone':'khargone','chapda':'chhapiheda','chapada':'chhapiheda','alote':'alot','shahpur bhoura':'shahpur betul district','hoshang':'hoshangabad','budhni':'badoni','kesali':'kesli','tendukheda':'tendukheda damoh district','chatarpur':'chhatarpur district','binaganj':'bangawan','datiya':'datia','chand':'chandia','parasiya':'porsa','lamta':'laundi','barela mp':'bareli mp','shahpura ser':'shahpura jabalpur district','bichiya':'buxwaha','garha':'ghuwara','bhitoni':'badoni','rajendragram':'raisen district','majhgawa':'maksi','birshinghpur':'birsinghpur','garh':'ghuwara','semariya':'semaria','bargawan':'birsinghpur','jabalpu':'jabalpur','amanganj':'amanganj panna district','surendranagar':'surendranagar district','vadodara district':'vadodara','ahmadabad district':'ahmedabad','jamnagar':'jamnagar district','bhavnagar district':'bhavnagar','ankleshwer':'ankleshwar','jamjodhpur':'junagadh','veraval rajkot district':'veraval','valsad':'valsad district','anand district':'anand','navsari':'navsari district','sabar kantha district':'savarkundla','dharampur':'dharampur industrial estate','gandhinagar district':'gandhinagar','kheda':'kadi','gir somnath':'gir somnath district','junagadh district':'junagadh','unai':'una','bhachau':'bhuj','dahod':'dohad','paddhari':'padra','porbandar district':'porbandar','bareja':'bharuch','ahmadabad':'ahmedabad','jamnager':'jamnagar district','borsad':'bharuch district','amreli':'amreli district','veraval rajkot':'veraval','salaya':'shil','dhoraji':'dwarka','visnagar':'vijaynagar','shihori':'sihor','mehsana':'mahesana','vadodar':'vadodara','bhabhar':'babra','mehmedabad':'mandvi kachchh district','sanand':'sanand gidc','morvi':'morbi','baliyasan':'balasinor','himatnagar':'himmatnagar','gandhinagr':'gandhinagar','bhilad':'bhiloda','chhatral':'chhatral ina','mahemdabad':'mandvi kachchh district','anklav':'ankleshwar','jhagadiya industrial area':'jasdan','bayad':'bhatiya','bedi':'bhatiya','shehera':'sihor','the dangs':'the dangs district','simar ser':'simar sir','chhota udaipur':'chhota udaipur district','godhara':'godhra','virpur':'virpur rajkot district','ahmdabad':'ahmedabad','mandvi surat district':'mandvi kachchh district','kadodra':'kadodara','himmat nagar':'himmatnagar','ahmedbad':'ahmedabad','mahemadabad':'mandvi kachchh district','khapat':'kevadiya','bhanvad district':'bhanvad','navi bhildi':'nava bhildi','jetpur':'jetpur navagadh','morbi 1':'morbi','narmada':'narmada district','panchmahal':'panch mahals district','dhasa vishi':'digvijaygram','gidc por':'gidc panoli','sagbara':'sukhpar','devbhumi dwarka':'devbhoomi dwarka district','chikhali':'chikhli','palaj':'palej','chhota udepur district':'chhota udaipur district','songadh bhavnagar district':'songadh tapi district','parntij':'prantij','surendra nagar':'surendranagar district','kosmba':'kosamba','ahemdabad':'ahmedabad','sabarkantha district':'savarkundla','kachchh':'kuchchh','ankaleshwar':'ankleshwar','panch mahals':'panch mahals district','vadodra':'vadodara','mandvi gidc':'mandvi kachchh district','santrampure':'santrampur','dhansura':'damnagar','sabarkantha':'savarkundla','sabarkatha':'savarkundla','bhavanagar':'bhavnagar','surendranagar dudhrej':'surendranagar district','mandvi':'mandvi kachchh district','songadh':'songadh tapi district','unagj':'unjha','vishavadar':'visavadar','madhavpur':'mithapur','mendarda':'mundra','veeraval':'veraval','dharangathra':'dhrangadhra','limdi':'lunawada','dhasa':'deesa','gathda':'gadhda','nakhatrana':'nakhatrana gidc','gandhi nagar':'gandhinagar','sami':'sayan','mahemdavad':'mandvi kachchh district','matar':'modhera','vatadara':'vadodara','khambat':'khambhat','katodara':'kadodara','hazira':'hajira','tiruppur':'tiruppur district','chengalpattu district':'chengalpattu','coimbatore district':'coimbatore','tirupur':'tiruppur district','thiruvarur district':'tiruppur district','thiruvallur district':'tiruvallur','virudhunagar':'virudhunagar district','kancheepuram':'kanchipuram','viluppuram district':'villupuram','namakkal district':'namakkal','dindigul district':'dindigul','thiruvallur':'tiruvallur','cuddalore':'cuddalore district','muthur':'madurai','pudukkottai':'pattukkottai','arani tiruvannamalai district':'arani thiruvallur district','comibator':'coimbatore','nagapattinam district':'nagapattinam','punjaipuliampatti':'punjaipugalur','thanjavur':'thanjavur district','thiruvarur':'tiruppur district','tenkasi district':'tenkasi','thiruporur':'tiruppur district','ariyalur':'ariyalur district','pudukkottai district':'pattukkottai','sipcot industrial park sriprumbudur':'sipcot perundurai','thoothukkudi':'thoothukkudi district','avanashi':'avinashi','kanniyakumari':'kanniyakumari district','karumathampatti':'karamadai','tirunelveli':'tirunelveli district','ramanathapuram':'ramanathapuram district','ranipet':'ranipet district','sivaganga':'sivaganga district','kancheepuram district':'kanchipuram','chinnasalem':'chengalpattu','tiruchirappalli district':'tiruchirappalli','verkilambi':'veerakkalpudur','perumandi':'pernampattu','konganapuram':'kanniyakumari district','tiruchendur':'tiruchengode','keelakarai':'kallakkurichi district','krishnagiri':'krishnagiri district','thirumangalam':'tharamangalam','musiri':'mecheri','rajapalayam':'rajapalayam virudhunagar district','gudalur coimbatore district':'gudalur theni district','poolankinar':'puliankudi','mettur':'madurai','kuthanallur':'kadayanallur','ranipettai':'ranipet district','kelambakkam':'kalambur','markayankottai':'marakkanam','parangipettai':'periya negamam','aravakurichi':'aruppukkottai','perambalur':'perambalur district','paramakudi':'periya negamam','tiruvannamalai':'tiruvannamalai district','chatrapatti':'chettiarpatti','arakkonam':'arakonam','valparai':'villupuram','kondur':'kunnathur','tirpur':'tiruppur district','vaniyambadi':'vaniyanbadi','thiruparankundram':'tiruppur district','periyanaickenpalayam':'periya negamam','kallakkurichi':'kallakkurichi district','thiruvithancode':'tirupathur district','kilvaithinankuppam':'kayalpattinam','thiruvennainallur':'tiruvannamalai district','thiruverumbur':'tiruppur district','veeravanallur':'veerappanchatiram','thiruparappu':'tiruppur district','madukkur':'madukkarai','periyamanali':'pernampattu','aranthangi':'arani thiruvallur district','udangudi':'uthangarai','perambakkam':'perambalur district','kangayam':'kanniyakumari district','tirupathur vellore district':'tirupathur district','sankarnagar':'sankarankoil','puduvayal':'pudupalayam','sipcot thervoy kandigal':'sipcot perundurai','sipcot thoothukudi':'sipcot perundurai','komarapalayam':'kumarapalayam','renipet':'ranipet district','veerapandi coimbatore district':'veerappanchatiram','jolarpetai':'jolarpet','alangudi':'alangulam virudhunagar district','ayakudi':'aygudi','veerapandianpattinam':'veerappanchatiram','kangeyam':'kanniyakumari district','sankari':'sankarankoil','pj cholapuram':'pazhugal','thiruthangal':'tiruttani','kariapatti':'keeripatti','acharapakkam':'asaripallam','gangavalli':'ganguvarpatti','nangavaram':'nangavalli','vadakarai keezhpadugai':'vaitheeswarankoil','chengam':'chinnakkampalayam','pallapalayam coimbatore district':'pallipalayam','andipalayam':'andipatti jakkampatti','mallur':'melur','ayyampettai thanjavur district':'ammapettai erode district','tirukalukundram':'tirukkoyilur','dharamapuri':'dharmapuri district','kambainallur':'kambam','srimushnam':'sirumugai','kadambathur':'kadambur','kaveripattinam':'kaveripakkam','keelamanjakudi':'kelamangalam','kanchipuram district':'kanchipuram','tittakudi':'thoothukkudi district','pudupattinam':'pudupatti','vellalore':'vellalur','palayapettai':'pallapatti karur district','karugampattur':'krishnagiri district','mallasamudram':'mulagumudu','walajapet':'walajabad','sankarapuram':'sankarankoil','palldam':'palladam','gudalur the nilgiris district':'gudalur theni district','pernambut':'pernampattu','pallipattu':'pallapatti karur district','kaniyambadi':'kannampalayam','changalpattu district':'chengalpattu','karungal':'kurinjipadi','vadakkanandal':'vedasandur','alwarthirunagiri':'alwarthirunagari','manappari':'manapparai','thottiam':'thottiyam','rs mangalam':'r s mangalam','melpattampakkam':'mullipattu','manimutharu':'manamadurai','paramathi':'perundurai','thiruvenkadam':'tiruvannamalai district','tiruchitrambalam':'thirukkattupalli','tittacheri':'tuticorin','valangaiman':'velankanni','pandamangalam':'pennadam','tirupathur':'tirupathur district','udumalpet':'udumalaipettai','veppathur':'v pudur','panamarathupatti':'ponnamaravathi','samathur':'sundarapandiam','kolappalur':'kilvelur','perumanallur':'pernampattu','narasimhanaickenpalayam':'narasingapuram vellore district','sidco industrial estate velathur':'sidco industrial estate pollupalli','kangayampalayam':'kanniyakumari district','kollancode':'kollencode','koothanallur':'kadayanallur','sidco industrial estate vinnamangalam':'sidco industrial estate pollupalli','kilpennathur':'kalappanaickenpatti','sriperumbdur':'sriperumbudur','annamalai nagar':'anaimalai','vilavur':'villupuram','thirukarungudi':'tiruchirappalli','pattanam':'padmanabhapuram','padaiveedu':'pudupatti','sivagiri tirunelveli district':'sivagiri erode district','killiyoor':'kuhalur','thoothukudi':'thoothukkudi district','mathur':'madurai','pudupalayam agraharam':'pudupalayam','sentharapatti':'sundarapandiam','ayikudi':'aygudi','thiruvidaimarudur':'tirupathur district','vettaikaranpudur':'vaitheeswarankoil','ammapettai thanjavur district':'ammapettai erode district','thiruvaiyaru':'tiruppur district','chennai600077':'chennai','ammoor':'annur','alangulam tirunelveli district':'alangulam virudhunagar district','ammavarikuppam':'ambur','vaddakkankulam':'vedasandur','palayam':'palani','alangayam':'alangulam virudhunagar district','srikalikapuram':'sirkali','thirupuvanam thanjavur district':'thirupuvanam sivaganga district','viluppuram':'villupuram','ethapur':'ettayapuram','mangalampet':'mangalam','adirampattinam':'adiramapattinam','dharumapuri':'dharmapuri district','neyveli 2':'neyveli','ayyampettai kancheepuram district':'ammapettai erode district','karunguzhi':'kurinjipadi','genguvarpatti':'ganguvarpatti','tirupathur sivaganga district':'tirupathur district','thiruppanandal':'tiruvannamalai district','kalakkad':'kallakudi','tiruvethipuram':'tirupathur district','bhuvanagiri':'bibinagar','kottampatti':'kadambur','narasingapuram salem district':'narasingapuram vellore district','kanyakumari':'kanniyakumari district','kanakkampalayam':'kanniyakumari district','thorapadi':'tirupathur district','palappallam':'pallipalayam','thirunageswaram':'tharangambadi','anupuram dae township':'ambur','kallukoottam':'kallakudi','kalakad':'kallakudi','kariamangalam':'keeramangalam','kamayagoundanpatti':'kanniyakumari district','mettupalayam':'mettupalayam coimbatore district','pallipat':'pallapatti karur district','dindugal':'dindigul','kattathurai':'kadathur','othakadai':'odugathur','pullampadi':'poolampatti','punjai pugalur':'punjaipugalur','gandipuram':'gummidipoondi','vadugapatti theni district':'vadakkuvalliyur','thiruvattar':'tirupathur district','kalkurichi':'kallakkurichi district','the nilgiris':'the nilgiris district','thathankuttai':'thathaiyangarpet','periyampatti':'perambalur district','madurai 17':'madurai','keeranur pudukkottai district':'keeranur dindigul district','puliyur':'polur','kottur':'kayatharu','puthukkadai':'pattukkottai','kottaiyur':'kayatharu','sipcot cheyyar':'sipcot perundurai','krishnarayapuram':'krishnagiri district','mettupaalayam, coimbatore':'mettupalayam coimbatore district','sipcot industrial complex pillaipakkam':'sipcot perundurai','kanchiparam':'kanchipuram','tirumalaigiri':'tirunelveli district','sidco industrial estate asnoor':'sidco industrial estate pollupalli','perumagalur':'periya negamam','gangaikondan tirunelveli district':'gangaikondan','panagudi':'punjai thottakurichi','cuddalore 1':'cuddalore district','kolachel':'kolachal','kothanallur':'kadayanallur','kila ambur':'kalambur','kailasagiri':'kulasekaram','mulagumoodu':'mulagumudu','poolambadi':'poolampatti','kaniyur coimbatore district':'kumaragiri','lakshmi puram':'lakkampatti','sathiyamangalam':'sathyamangalam','manjalumoodu':'mangalam','eriodu':'erode','pallanthurai':'palamedu','therur':'thuraiyur','sidco industrial estate gudimangalam':'sidco industrial estate pollupalli','gobichettipalyam':'gobichettipalayam','muruganpalayam':'marakkanam','kooraikundu':'krishnagiri district','sundarapandianpattinam':'sundarapandiam','thiruvermbur':'tiruppur district','oragdam':'oragadam industrial area','tittagudi':'thoothukkudi district','salm':'salem','puliyankudi':'puliankudi','chennai 600039':'chennai','annavasal':'ambasamudram','moolakaraipatti':'melagaram','porayar':'peraiyur','mettupalayam tiruchirappalli district':'mettupalayam coimbatore district','kadayampatti':'kadambur','new tirupur':'new tirpur','kaniyur tiruppur':'kaniyur tiruppur district','arumbavur':'arumbanur','kannivadi tiruppur district':'kannivadi dindigul district','sidco industrial estate venmaniathur':'sidco industrial estate pollupalli','pannaikadu':'punjai thottakurichi','kurumbalur':'karambakkudi','trippur':'tiruppur district','erodu':'erode','perungulam':'periya negamam','chennai 41':'chennai','palaganangudy':'pallikonda','arakandanallur':'arakonam','kalugumalai':'kilkunda','alanganallur':'alangulam virudhunagar district','mathigiri':'madukkarai','mohamed bundur':'mandapam','athipatti':'ayothiapattinam','neelagiri':'nilgiris','koil palayam':'kilvelur','shencottah':'shenkottai','tirippur':'tiruppur district','ammapattinam':'ammapettai erode district','kanadukathan':'kinathukadavu','methukummal':'methukummel','punjai puliampatti':'punjaipugalur','selam':'salem','eranapuram':'erumaipatti','nerinjipettai':'nerunjipettai','singampuneri':'singampunari','maraimalai nagar':'maraimalainagar','kannanoor tiruchirappalli district':'kannanoor','tovarankurichi':'thevaram','mallankinaru':'malumichampatti','sankar nagar':'sankarankoil','tirupathur sivagangai district':'tirupathur district','peranamallur':'pernampattu','aval poondurai':'avalpoondurai','maduraii':'madurai','aavinashi':'avinashi','vilavancode':'valavanur','panaimarathupatti':'ponnamaravathi','tiruppattur':'tirupathur district','chennai 39':'chennai','sriperumpudur':'sriperumbudur','kallakurichi':'kallakkurichi district','amathur':'anthiyur','chennai600075':'chennai','vallam kancheepuram district':'velankanni','kulathur':'kolathur','kanakammachathram':'kanniyakumari district','new tripur':'new tirpur','tiruchirappalli ,':'tiruchirappalli','thiruppalai':'tiruvallur','ramanatha puram district':'ramanathapuram district','salam':'salem','puduchatram':'pattukkottai','tirumangalam':'tharamangalam','chenna':'chennai','madharpakkam':'madaharpakkam','ilanji':'ilayangudi','karimangalam':'keeramangalam','aliyar':'ayyalur','vembadithalam':'vaniputhur','thimmaiyanpettai':'thammampatti','avinshi':'avinashi','colachal':'colachel','thriuvermbur':'tiruppur district','oragadam':'oragadam industrial area','kaveripattinm':'kaveripakkam','mettamalai':'mudumalai','mathicode':'muthukadu','annanji':'ammainaickanur','perambalure district':'perambalur district','karaikudi':'karaikkudi','thanjavoor':'thanjavur district','melathiruppanthuruthi':'melattur','pallapalayam erode district':'pallipalayam','ambattur':'ammapettai erode district','aruppukottai':'aruppukkottai','sithayankottai':'sathankulam','thiruvalam':'tiruvallur','erodei':'erode','sankarankovil':'sankarankoil','changalpattu':'chengalpattu','ariyalure':'ariyalur district','thiruuvallur':'tiruvallur','sivagangai district':'sivaganga district','sipcot perundurai,':'sipcot perundurai','tirppur':'tiruppur district','mechari':'mecheri','thirukkadaiyur':'thirukkattupalli','aundipatti':'andipatti jakkampatti','arcot kuppam':'arcot','azhagappapuram':'azhagiapandipuram','thirumalpur':'tirunelveli district','thadikarankonam':'tuticorin','sidco industrial estate veerapandi salem':'sidco industrial estate pollupalli','tirumohur':'thirumuruganpoondi','salem 636005':'salem','thiruvannamalai':'tiruvannamalai district','dindigal':'dindigul','seevur':'sevur','vridhachalam':'virudhachalam','gudiyattam':'gudiyatham','trichy1':'trichy','katpadi':'kattuputhur','tiruvottiyur':'tirupathur district','pallavaram':'palavoor','nandivaram':'nandivaram guduvancheri','pallapatti':'pallapatti karur district','rameshwaram':'rameswaram','sivagiri':'sivagiri erode district','thirupuvanam':'thirupuvanam sivaganga district','gummudipoondi':'gummidipoondi','melmaruvathur':'mulanur','cheyyur':'cheyyar','arani':'arni','thirukoilure':'tirukkoyilur','memalur':'manalurpet','karunapuram':'karambakkudi','tiruvarur':'tiruppur district','ayyampettai':'ammapettai erode district','thiruvadanai':'tirupathur district','tiruchi':'trichy','aranthangi tn':'arani thiruvallur district','shivagangai':'sivaganga district','muthukulathur':'mudukulathur','paramakudi_tamilnadu':'periya negamam','ayyampalyam':'ayyampalayam','athipati':'ayothiapattinam','sri rampuram':'sriramapuram','cumbam':'cumbum','vallioor':'vellore','ottapidaram':'odaipatti','kaliakkavilai':'kaliyakkavilai','kadukkarai':'kotagiri','thiruppathur':'tirupathur district','sholinghur':'sholingur','thoppur':'thevur','palacode':'palakkodu','paramathivelur':'perundurai','anthiyour':'anthiyur','avinashi road':'avinashi','gudalur':'gudalur theni district','madurantakam':'maduranthakam','jhunjhunu':'jhunjhunun district','bharatpur':'bharatpur district','jhalawar district':'jalor district','jodhpur':'jodhpur district','barmer':'barmer district','chittaurgarh':'chittaurgarh district','jaisalmer':'jaisalmer district','banswara':'banswara district','dungarpur':'dungarpur district','sirohi district':'suratgarh','hindaun':'hindaun city','chittorgarh':'chittaurgarh district','nagar':'nagaur','sawai madhopur':'sawai madhopur district','hanumangarh district':'hanumangarh','chittorgarh district':'chittaurgarh district','ajmer district':'ajmer','bilara':'bhilwara','partapur':'pratapgarh','dhaulpur district':'dhaulpur','jalor':'jhalawar','bikaner district':'bikaner','beawar':'bari','ganganagar':'ganganagar district','bhalariya':'bhilwara','jalore':'jhalawar','sujangarh':'sheoganj','ratannagar':'ratangarh','kishangarh renwal':'kishangarh ajmer district','rajsamand district':'rajsamand','jhunjhunun':'jhunjhunun district','ramgarh alwar district':'ramgarh sikar district','riico industrial area gudli':'riico industrial area neemrana','swaimadhopur':'sawai madhopur district','riico industrial area palsana':'riico industrial area neemrana','khatu':'kota','mundwa':'mandawa','deeg':'dausa','sangaria':'sanchore','chirawa':'churu','kherli':'karauli','rani sagar riico':'reengus','baggar':'bagru','bichhiwara':'bagru','sardar shahr':'sardarshahar','govindgarh jaipur district':'govindgarh alwar district','aburoad':'abu road','nawa':'niwai','kishangarh':'kishangarh ajmer district','taranagar reni':'taranagar','riico industrial area chopanki':'riico industrial area neemrana','vijainagar ganganagar district':'vijainagar ajmer district','riico institutional area ranpur':'raisinghnagar','riico industrial area khushkhera':'riico industrial area neemrana','dhoulpur':'dhaulpur','jaislmer':'jaisalmer district','dholpur':'dhaulpur','alwer':'alwar','bhim':'bayana','dungargarh':'dungarpur district','chhapar':'chhabra','kanor':'kumher','bhusawar':'bagru','hamirgarh growth centre riico':'hamirgarh','borawar':'behror','boranada special economic zone':'baran district','kishangarh alwar district':'kishangarh ajmer district','bandik':'bandikui','bangur nagar':'banswara district','satalkheri':'sadulshahar','mount abu':'mehandipur','sagwara':'sikar','kuchera':'kekri','udaipur city':'udaipur district','amet':'antah','chirawaa':'churu','tapukara':'tapookra','bissau':'baskhoh','industrial area bidiyad':'industrial area kaladera','nagour':'nagaur','sarmathura':'sri madhopur','ringus':'reengus','sri madhopur indusrtial area':'sri madhopur','bijaynagar':'bishangarh','sojat':'suket','alwar ':'alwar','rajgarhchuru district':'rajgarh churu district','mavali':'mavli','nagor district':'nagaur district','udaipurwati':'udaipur district','udpura':'udaipur district','nainwa':'nooan','seemalwara':'simalwara','rajsamnd':'riico industrial area neemrana','bakani':'begun','hindaun city industrial area':'hindaun city','sanganer':'singhana','riico ind25ustrial area khushkhera':'riico industrial area neemrana','mahindipur balaji':'mehandipur','riico industrial area kharani':'riico industrial area neemrana','sardarshahr':'sardarshahar','sardargarh':'sardarshahar','riico industrial area kant kalwar':'riico industrial area neemrana','riico industrial area rupangarh':'riico industrial area neemrana','jaipuri':'jaipur','slumber':'salumbar','shiwar':'sirohi','jodhpur stone park industrial area':'jodhpur district','dholpur district':'dhaulpur','sadul shahar':'sadulshahar','nagor':'nagaur','industrial area botawala':'industrial area kaladera','hindon':'hindaun city','shahpura, jaipur district':'shahpura jaipur district','bar':'bari','sanderao':'samdari','jodhpur city':'jodhpur district','manohar thana':'manoharthana','kishangarh ajmer':'kishangarh ajmer district','anta':'antah','neemkathana':'neem ka thana','riico industrial area rajgarh':'riico industrial area neemrana','nimrana':'neemrana','sakar':'sikar','riico industrial area bikasar':'riico industrial area neemrana','khatoo':'kota','kapren':'kaprain','neem':'nooan','ramngarh':'ramgarh sikar district','vijainagar, ajmer':'vijainagar ajmer district','laxmangarh':'lachhmangarh','bansur':'banswara district','bassi':'baskhoh','bijainagar':'bishangarh','badnor':'badnaur','mandphiya':'mehandipur','bhatewar':'bhadra','sarada':'suroth','bonli':'bhinmal','shri dungargarh':'saradhana riico','bajore':'bagru','sultana':'sultanpur rj','buhana':'bayana','desnok':'deshnoke','ganga nagar':'ganganagar district','sriganganagar':'sri ganganagar','padampurrj':'padampur','srivijaynagar':'swaroopganj','ghator':'gothra','piparcity':'pipar city','gotan':'gothan','baytu':'bhiwadi','ramsar':'ramgarh sikar district','dhorimana':'dhorimanna','pokhran':'pokaran','north tripura':'north tripura district','west tripura district':'west tripura','kailasahar':'kailashahar','south tripura':'south tripura district','kalachhari':'kailashahar','santir bazar':'santirbazar','unakoti district':'unokoti district','teliamura district':'teliamura','sepahi jala':'sepahijala district','amarpur tp':'amarpur','aambasa':'ambassa','kapurthala district':'kapurthala','pathankot district':'pathankot','jalandhar district':'jalandhar','amritsar district':'amritsar','gurdaspur':'gurdaspur district','firozpur':'firozpur district','bathinda district':'bathinda','ferozepur':'firozpur district','bhatinda':'bathinda','faridkot district':'faridkot','fazilka district':'fazilka','batala':'baddowal','apra':'abohar','fatehgarh churian':'fatehgarh sahib','muktsar':'moga district','dera bassi industrial area':'dera bassi','dinangar':'dinanagar','barnala':'barnala district','hoshiarpur':'hoshiarpur district','fatehgarh sahib district':'fatehgarh sahib','muktsar district':'moga district','sangrur district':'sangrur','tarantaran':'tarn taran district','malaut':'maloud','samana':'sunam','rupnagar district':'rupnagar','doraha':'dhuri','hoshiarpuro':'hoshiarpur district','nangli':'nangal','gurdaspuro':'gurdaspur district','sham chauras 1':'sangrur','sansarpur':'sangrur','bhogpur':'bhagha purana','derabassi':'dera bassi','tarn taran':'tarn taran district','dina nagar':'dinanagar','makhu':'moga','sirhind':'sirhind fatehgarh sahib','bhulath':'bholath','malout':'maloud','talwandi bhai':'talwandi sabo','jandiala jalandhar district':'jandiala amritsar district','beas':'bhikhi','ferozpur city':'firozpur district','malarkotla':'malerkotla','kaprthala district':'kapurthala','moonak':'mansa','dorha':'dhuri','shaheed bhagat singh nagar':'shahid bhagat singh nagar district','rup nagar':'rupnagar','kot kapura':'kotkapura','jalandhar city':'jalandhar','dhanuala':'dhanaula','tarn ,taran':'tarn taran district','sham chaurasi':'sangrur','gidderbaha':'giddarbaha','ferozepur city':'firozpur district','tarntaran':'tarn taran district','mamoon':'mamun','baranla':'barnala district','mullanpur garib dass':'mullanpur dakha','khem karan':'khemkaran','bhankarpur':'bhawanigarh','guruharsahai':'guru har sahai','firozpur cantonment':'firozpur district','jalandhar cantt':'jalandhar','morinda, india':'morinda','pattran':'patran','machiwara':'machhiwara','mandi gobindgarh':'mandi govindgarh','dehlon':'dhilwan','bagha purana':'bhagha purana','tarn taran sahib':'tarn taran district','kathunangal':'kathanian','mahalpur':'mahilpur','garhshanker':'garhshankar','nawansahar':'nawanshahr','sultanpur lodhi':'sultanpur','sivasagar district':'sibsagar','goalpara':'goalpara district','kamrup district':'kamrup metropolitan district','dibrugarh district':'dibrugarh','nalbari district':'nalbari','tinsukia':'tinsukia district','udalguri':'udalguri district','dhing':'dhemaji','barpeta road':'barpathar','golaghat':'golaghat district','barpeta district':'barpathar','karimganj district':'karimganj','barpeta':'barpathar','hailakandi district':'hailakandi','moranhat':'moran town','sarupathar':'sarupathar bengali','biswanath chariali':'biswanath district','durga nagar part 5':'dergaon','bongaigaon district':'bongaigaon','badarpur':'badarpur rly town','kokrajhar':'kokrajhar district','narayanpur':'narayanpur district','lakhi nepali':'lakhimpur district','sonapur gaon':'sanpara','bokajan':'basugaon','marigaon':'morigaon district','morigaon':'morigaon district','duliajan no 1':'duliajan','duliajan oil town':'duliajan','narayanpur nalbari district':'narayanpur','majgaon':'makum','dima hasao district':'dhemaji district','morigan district':'morigaon district','sivasagar':'sibsagar','bongaigaon rpcl township':'bongaigaon','kamrup':'kamrup metropolitan district','lakhipur cachar district':'lakhipur goalpara district','bhuragaon':'bhuragaona','lido town':'ledotown','howly':'howli','sorbhog':'sarbhog','kamrup metropolitan':'kamrup metropolitan district','kokorajhar':'kokrajhar district','biswanath':'biswanath district','charingia gaon':'chirang district','barapeta':'barpathar','digaru gaon':'dhekorgorha','mosli pt':'mosli pt 1','thekashu pt 1':'thekashu pt 2','duliajan no 1i':'duliajan','north lakhimapur':'north lakhimpur','mosli pt i':'mosli pt 1','mosli pt 3':'mosli pt 1','borpather':'barpathar','new bongaigaon':'new bongaigaon railway colony','thekashu pt ii':'thekashu pt 2','guwahti':'guwahati','niz katigorah pt iii':'niz katigorah pt 3','darrang':'darrang district','bohari':'bahari','dhubori':'dhubri','lokhimpur district':'lakhimpur district','dima hasao':'dhemaji','bongaigano':'bongaigaon','golakganj':'golokganj','morigone':'morigaon district','lumding rly colony':'lumding','barpate':'barpathar','mari gaon':'morigaon district','mangaldai':'mangaldoi','howly8':'howli','lokhimpur':'lakhimpur district','tangl':'tangla','bandardewa iid7':'bandardewa iid','bor pata district':'barpathar','ledo town':'ledotown','sivsagar district':'sibsagar','durga nagar part 2':'dergaon','chirang':'chirang district','sonitpur':'sonitpur district','lakhipur cachar':'lakhipur goalpara district','lakhimapur district':'lakhimpur district','dalgaon':'duliajan','hailakand':'hailakandi','thekashu pt i,':'thekashu pt 2','lakhipur district goalpara':'lakhipur goalpara district','thekashu pt i':'thekashu pt 2','thekashu pt 111':'thekashu pt 2','barpetaroad':'barpathar','kanisail pt i':'kanisail pt 1','morigon':'morigaon district','surupathar':'sarupathar bengali','district dibrugarh':'district cachar','guwahat':'guwahati','khairabari':'khaira bari','naugaon':'nagaon','charaideo':'charideo','south salmara mankachar':'south salmara mankachar district','thekashu pt 3':'thekashu pt 2','naharkatia':'naharkatiya','kochapara':'kochpara','lamding':'lumding','barpeta raod':'barpathar','dima hasoa district':'dhemaji district','durga nagar part 7':'dergaon','district karimganj':'district cachar','bongaigaon city':'bongaigaon','rangiya':'rangia','hajo':'hojai','boko':'baksa','darranga mela':'darrang district','dhing town':'dhemaji district','kampur':'kampur town','lakhipur':'lakhipur goalpara district','bilashipara':'bilasipara','dotma':'dudhnoi','mongoldoi':'mangaldoi','biswanathch':'biswanath district','jamuguri':'jamugiri','balipara':'balapara','bhergaon':'bhuragaona','numaligarh':'numaligarh refinery township','titabor':'titabor town','sivsagar':'sibsagar','moran':'mariani','tengakhat':'tinsukia district','sonabarighat':'sanpara','bhaga':'baksa','karimga':'karimganj','manugur':'mancherial','karimnagar district':'karimnagar','siddipet district':'siddipet','narayanpet district':'narayanpet','suryapet':'suryapet district','nirmal district':'nirmal','ranga reddy':'rangareddy district','warangal urban district':'warangal rural district','nagarkurnool':'nagarkurnool district','rangareddy':'rangareddy district','kamareddy district':'kamareddy','wanaparthy':'wanaparthy district','kamareddi':'kamareddy','mancherial district':'mancherial','vicarabad':'vikarabad district','nakrekal':'nagarkurnool district','mahbubnagar district':'mahbubnagar','hydrbad':'hyderabad','jagtial':'jagtial district','mahabubabad district':'mahabubabad','jammikunta':'jangaon district','peddapalli':'peddapalle district','jagital':'jagtial district','mahabub nagar':'mahbubnagar','ashwaraopeta':'ashwaraopet','mahaboobnagar':'mahbubnagar','sangareddy':'sangareddy district','nalgonda':'nalgonda district','metapally':'metpalle','mahabubnagar':'mahbubnagar','shankarampet':'sangareddy district','adilabad district':'adilabad','peaddapalli':'peddapalle district','warangal industrial area':'warangal rural district','manuguru':'mancherial','mancheriala':'mancherial','nakerekal':'nagarkurnool district','ranaga reddy':'rangareddy district','ganapuram':'ghanpur nizamabad district','vemulawda':'vemulawada','jangaon':'jangaon district','pothireddipalle':'pothreddipalle','thimmapur':'thimmapur karimnagar district','peddapelli':'peddapalle district','huzurnagar':'huzur nagar','paloncha':'palwancha','kothakota':'kothagudem','peddapalle':'peddapalle district','secundrabad':'secunderabad','ghanpur warangal district':'ghanpur nizamabad district','sathupalli':'sathupally','hanamakonda':'hanamkonda','korutla':'koratla','zaheerabad':'zahirabad','manchirial district':'mancherial','hyderabad district':'hyderabad','hyderbad':'hyderabad','devarkadra':'devarakonda','sri vishnu cement limited dondapadu':'sarapaka','mahabubngar':'mahbubnagar','bellampalli':'bellampalle','armur':'armoor','secandrabad':'secunderabad','mahboobnagar':'mahbubnagar','secunderbad':'secunderabad','maheswaram industrial area':'maheshwaram','warangal urban':'warangal rural district','warangal district':'warangal rural district','chunchupalle':'chunchupalli','badepalle':'badepalli','dharmaram karimnagar district':'dharmaram warangal district','kamalapuram karimnagar district':'kamalapuram','medipalle':'metpalle','narayanapet':'narayanpet','sadasepet':'sadasivpet','kalwa kurthy':'kalwakurthy','yerupelem':'yerrabalem','kyathampalle':'kaddam peddur','ranga reddy district':'rangareddy district','bhupalapalli':'bhupalpalle','bhimaram':'bhimaram adilabad district','vikarabad':'vikarabad district','nagar kurnool district':'nagarkurnool district','nagarjuna sagar':'nagarkurnool district','metpally':'metpalle','rajanna sircilla':'rajanna sircilla district','hyderabad,':'hyderabad','mahabubunagar':'mahbubnagar','peddapalli district':'peddapalle district','jangoan':'jangaon district','vikarabada':'vikarabad district','sangaraddy':'sangareddy district','jaya shankar bhalupally':'jaya shankar bhalupally district','nalagonda':'nalgonda district','mahabubnagar district':'mahbubnagar','warangal rural':'warangal rural district','jadcharla':'jadcherla','bahadurguda':'bhadrachalam','kodada':'kodad','jagitial':'jagtial district','rajanna siricilla':'rajanna sircilla district','mahabubnager':'mahbubnagar','zharabad':'zahirabad','peddaaplli':'peddapalle district','mandamari':'mandamarri','utnoor':'utnur','nagarkarnool':'nagarkurnool district','suryapeta district':'suryapet district','deverakonda':'devarakonda','medchal':'medchal malkajgiri district','padmajiwadi':'patancheru','chinnur':'chennur','kaghaznagar':'kagaznagar','kamalapur':'kamalapuram','manthani':'mandamarri','yellareddipet':'yellareddy','ghanpur':'ghanpur nizamabad district','bhupalpally':'bhupalpalle','chintoor':'chandur','madhavram':'mahadevpur','cherla':'cherial','kusumanchi':'kisan nagar industrial area','mudigonda':'madikonda','yerrupalem':'yerrabalem','aswaraopeta':'ashwaraopet','nakerakal':'nagarkurnool district','achampeta':'achampet','madgulapally':'medchal malkajgiri district','mahbub nagar':'mahbubnagar','jogulamba gadwal':'jogulamba district','bishnupur district':'bishnupur','churachandpur':'churachandpur district','imphal east':'imphal','imphal west':'imphal','lilong thoubal':'lilong imphal west','bishenpur':'bishnupur','kakching district':'kakching','imphal east district':'imphal','imphal west district':'imphal','senapati district':'senapati','chirachandpur':'churachandpur district','lilong':'lilong imphal west','kangpopki':'kangpokpi','bagbahara':'bijapur','surajpur':'surajpur district','mahasamund':'mhasmund','mahasamund district':'mhasmund','jashpur':'jashpur district','janjgir champa':'janjgir champa district','rajnandgaon district':'rajnandgaon','dongargaon':'dongargarh','janjgir':'janjgir champa district','jaijepur':'jashpur district','baramkela':'bhairamgarh','kharsia':'kurasia','dhamtari':'dhamtari district','gariaband':'gariaband district','pendra':'pandaria','ambagarh chowki':'ambikapur','kondagaon district':'kondagaon','vishrampur0':'vishrampur','baloda bazar':'baloda bazar district','bemetra district':'bemetra','jashpurnagar':'jashpur district','bastar':'bastar district','mungeli':'mungeli district','kurud':'kawardha','chirimiri':'chirmiri','ramanujgnaj':'ramanujganj','geedam':'gidam','vishrampuri':'vishrampur','bilha':'bhilai','bhatgaon surguja district':'bhatgaon','baloda':'balod','kharod':'kawardha','balodabazar':'baloda bazar district','kunkuri':'kanker','kumhari':'khamharia','mandi r hasod':'mandhar industrial area','pandariya':'pandaria','century cement baikunth':'chandrapur','chikhalakasa':'chikhal kasa','pratappur':'paratappur','jaijaipur':'jashpur district','lafarge cement factory sonadhi':'lafarge cement factory arasmeta','jashpur nagar':'jashpur district','mahasmund':'mhasmund','dakshin bastar dantewada':'dakshin bastar dantewada district','mandir hasaud':'mandhar industrial area','keshkal':'keskal','bilaspur8':'bilaspur district','nawagarh':'nagari','chhurikala':'chhuriya kalan','doundi':'dhamdha','raigar ,,h district':'raigarh district','dondi':'dhamdha','sargaon':'saragaon','kabeerdham':'kabeerdham district','dallirajhara':'dalli rajhara','sakari':'sakri','surguja':'surguja district','baloda bazaar':'baloda bazar district','gariyaband':'gariaband district','bemetara district':'bemetra','baarsur':'barsur','bemetara':'bemetra','gariyabandh':'gariaband district','mandhar':'mandhar industrial area','shivarinarayan':'shivrinarayan','saraipalli':'saraipali','devbhog':'dipka','bijapur cg':'bijapur','surajapur':'surajpur district','west jaintia hills district':'west garo hills district','east garo hills district':'east khasi hills district','west khasi hills district':'west garo hills district','east khasi hills':'east khasi hills district','north goa':'north goa district','canacona':'chinchinim','candolim':'candola','morjim':'marcaim','sancoale':'sanquelim','marg':'margao','margoa':'margao','sankhali':'sanquelim','kangra':'kangra district','kangar district':'kangra district','himirpur':'hamirpur district','dharmsala':'dharamshala','bain attarian industrial area':'bhuntar','dharamasala':'dharamshala','sundernagar':'sundarnagar','bhota':'baddi','subathu':'sabathu','gagret industrial area':'gagret','jogindarnagar':'jais industrial area','district kangra':'district mandi','district hamirpur':'district mandi','suni':'seoni','chopal':'chaupal','rampur bushahr':'rampur','kala amb':'kala amb industrial area','kunihar':'kinnaur','salouni':'solan','sundar nagar':'sundarnagar','joginder nagar':'jais industrial area','dharampurhp':'dharampur industrial estate','jari':'jeori','nagrota surian':'nagrota bagwan','kachhera':'khajjiar','daroh':'dheera','jassur':'jhakhri','sundla':'sandhol','rakkar':'rajgarh','dehra gopipur':'dera gopipur','mokokchung':'mokokchung district','dimapur district':'dimapur','tuensang':'tuensang district','chumukidima':'chumukedima','changtongya':'chumukedima','ravangla':'rabongla','changlang':'changlang district','west kameng district':'west siang district','east kameng district':'east siang district','west siang':'west siang district','papumpare':'papum pare district','papum pare':'papum pare district','dadra& nagar haveli':'dadra and nagar haveli district','dadra & nagar haveli':'dadra and nagar haveli district','dadra and nagar haveli':'dadra and nagar haveli district','silavassa':'silvassa','puducherry district':'puducherry','karaikal district':'karaikal','lunglei district':'lunglei','lawngtlai district':'lawngtlai','siaha':'saiha','aizwal':'aizawl','chandigarh district':'chandigarh','south andaman':'south andaman district'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde72e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:24:07.239951Z",
     "start_time": "2022-05-04T11:24:05.835310Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.replace(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205c219",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:24:20.523532Z",
     "start_time": "2022-05-04T11:24:20.505494Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cae0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T11:25:03.403889Z",
     "start_time": "2022-05-04T11:24:57.803818Z"
    }
   },
   "outputs": [],
   "source": [
    "insertDataIntoSheets(df,\"City-State-Population\",\"Sheet6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db8685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:44:00.932721Z",
     "start_time": "2022-05-04T08:44:00.896793Z"
    }
   },
   "outputs": [],
   "source": [
    "df['clean_city'] = df['City'].apply(cleaned_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb36e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:45:17.624037Z",
     "start_time": "2022-05-04T08:45:17.598821Z"
    }
   },
   "outputs": [],
   "source": [
    "# del df['City']\n",
    "df = df.rename(columns={'clean_city':'City'}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067eab2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-04T08:46:01.318589Z",
     "start_time": "2022-05-04T08:46:01.276271Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('random3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6cfb8",
   "metadata": {},
   "source": [
    "# feature extraction from device details and ip address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ca1ba",
   "metadata": {},
   "source": [
    "## parsing the user agent and fetching device details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86f64a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T09:33:31.689412Z",
     "start_time": "2022-05-19T09:33:31.680561Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s = \"Mozilla/5.0 (Linux; Android 10; M2007J17I) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.79 Mobile Safari/537.36\"\n",
    "\n",
    "import httpagentparser\n",
    "\n",
    "def device_details(user_agent):\n",
    "#     return = ['platform','os']\n",
    "    if pd.isna(user_agent):\n",
    "        return None\n",
    "    x =  httpagentparser.detect(user_agent)\n",
    "#     print(x)\n",
    "    return x['platform']['name'],x['os']['name']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba153f",
   "metadata": {},
   "source": [
    "## parsing the ip address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087cebd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T22:48:07.087412Z",
     "start_time": "2022-05-12T22:48:07.076879Z"
    }
   },
   "source": [
    "### getting location from the ip address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d65570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T09:26:27.192613Z",
     "start_time": "2022-05-19T09:26:26.658658Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_location(ip_address):\n",
    "    if pd.isna(ip_address):\n",
    "        return None\n",
    "#     ip_address = get_ip()\n",
    "    response = requests.get(f'https://ipapi.co/{ip_address}/json/?key=PfUITkJKFPbOVo7th8s7bYUd8F6J1UgVpfU2wsoqzGA28XPSsv').json()\n",
    "\n",
    "    location_data = {\n",
    "        \"ip\": ip_address,\n",
    "        \"city\": response.get(\"city\"),\n",
    "        \"region\": response.get(\"region\"),\n",
    "        \"country\": response.get(\"country_name\")\n",
    "    }\n",
    "    return location_data\n",
    "\n",
    "\n",
    "get_location('185.220.101.17')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049674c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T22:48:30.117821Z",
     "start_time": "2022-05-12T22:48:30.110873Z"
    }
   },
   "source": [
    "### get blacklist check on ip address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ac19d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T11:15:08.027382Z",
     "start_time": "2022-05-20T11:14:31.443191Z"
    }
   },
   "outputs": [],
   "source": [
    "import pydnsbl\n",
    "import nest_asyncio\n",
    "\n",
    "def blacklist_or_not(ip_address):\n",
    "    if pd.isna(ip_address):\n",
    "        return None\n",
    "    ip_checker = pydnsbl.DNSBLIpChecker()\n",
    "    nest_asyncio.apply()\n",
    "    return ('exploits' in str(ip_checker.check(ip_address).detected_by))*1\n",
    "\n",
    "def blacklist_count(ip_address):\n",
    "    if pd.isna(ip_address):\n",
    "        return None\n",
    "    ip_checker = pydnsbl.DNSBLIpChecker()\n",
    "    nest_asyncio.apply()\n",
    "    return len(ip_checker.check(ip_address).detected_by)\n",
    "\n",
    "print(blacklist_count('175.101.68.11'))\n",
    "blacklist_or_not('175.101.68.11')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb746d2e",
   "metadata": {},
   "source": [
    "### trying one stop solution for ip address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45084b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T11:21:05.219289Z",
     "start_time": "2022-05-20T11:21:03.734191Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def ip_address_api_result(ip_address):\n",
    "    key = 'lLIPCpwWduNXG3BG6u7aX9zxdjS4n6bM'\n",
    "    res = requests.get(f'https://ipqualityscore.com/api/json/ip/{key}/{ip_address}').json()\n",
    "    return res\n",
    "\n",
    "ip_address_api_result_1 = ip_address_api_result('66.249.72.64')\n",
    "\n",
    "def ip_address_state_match(ip_address_api_result,state):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    if ip_address_api_result['region'].lower()==state.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def ip_address_crawler_or_not(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "#     print(ip_address_api_result)\n",
    "    return ip_address_api_result['is_crawler']*1\n",
    "\n",
    "def ip_address_vpn_or_not(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    if ip_address_api_result['vpn']==True or ip_address_api_result['active_vpn']==True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def ip_address_tor_or_not(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    if ip_address_api_result['tor']==True or ip_address_api_result['active_tor']==True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def ip_address_fraud_score(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    return ip_address_api_result['fraud_score']\n",
    "\n",
    "def ip_address_recent_abuse_or_not(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    return ip_address_api_result['recent_abuse']*1\n",
    "\n",
    "\n",
    "def ip_address_bot_or_not(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    return ip_address_api_result['bot_status']*1\n",
    "\n",
    "def ip_address_abuse_velocity(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    return ip_address_api_result['abuse_velocity']\n",
    "\n",
    "from math import cos, asin, sqrt, pi\n",
    "\n",
    "def lat_long_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a)) \n",
    "\n",
    "def ip_address_lat_long_distance(ip_address_api_result,lat,long):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    if pd.isna(lat):\n",
    "        return None\n",
    "    return lat_long_distance(lat, long, ip_address_api_result['latitude'], ip_address_api_result['longitude'])\n",
    "    \n",
    "\n",
    "def ip_address_mobile_or_not(ip_address_api_result):\n",
    "    if ip_address_api_result['success']==False:\n",
    "        return None\n",
    "    return ip_address_api_result['mobile']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce83299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T11:21:05.236755Z",
     "start_time": "2022-05-20T11:21:05.224279Z"
    }
   },
   "outputs": [],
   "source": [
    "ip_address_api_result_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3b256",
   "metadata": {},
   "source": [
    "## feature extraction from email address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1878b9e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T10:40:02.900291Z",
     "start_time": "2022-05-17T10:40:01.879700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def email_api_result(email):\n",
    "    key = 'lLIPCpwWduNXG3BG6u7aX9zxdjS4n6bM'\n",
    "    res = requests.get(f'https://ipqualityscore.com/api/json/email?key={key}&email={email}').json()\n",
    "    return res\n",
    "\n",
    "# email_api_result_1 = email_api_result('smantri291996@gmail.com')\n",
    "\n",
    "def valid_email(email_api_result):\n",
    "    return email_api_result['valid']*1\n",
    "\n",
    "def disposable_email(email_api_result):\n",
    "    return email_api_result['disposable']*1\n",
    "\n",
    "def fraud_score_email(email_api_result):\n",
    "    return email_api_result['fraud_score']\n",
    "\n",
    "def recent_abuse_email(email_api_result):\n",
    "    return email_api_result['recent_abuse']*1\n",
    "\n",
    "def common_email(email_api_result):\n",
    "    return email_api_result['common']*1\n",
    "\n",
    "def suspect_email(email_api_result):\n",
    "    return email_api_result['suspect']*1\n",
    "\n",
    "def dns_valid_email(email_api_result):\n",
    "    return email_api_result['dns_valid']*1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95181cd6",
   "metadata": {},
   "source": [
    "## feature extraction from phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbeb59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-17T10:40:08.535277Z",
     "start_time": "2022-05-17T10:40:08.037349Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def phone_api_result(phone):\n",
    "    key = 'lLIPCpwWduNXG3BG6u7aX9zxdjS4n6bM'\n",
    "    res = requests.get(f'https://ipqualityscore.com/api/json/phone/?key={key}&phone={phone}').json()\n",
    "    return res\n",
    "\n",
    "# phone_api_result_1 = phone_api_result(911408440355)\n",
    "\n",
    "def valid_phone(phone_api_result):\n",
    "    return phone_api_result['valid']*1\n",
    "\n",
    "def fraud_score_phone(phone_api_result):\n",
    "    return phone_api_result['fraud_score']\n",
    "\n",
    "def recent_abuse_phone(phone_api_result):\n",
    "    return phone_api_result['recent_abuse']*1\n",
    "\n",
    "def risky_phone(phone_api_result):\n",
    "    return phone_api_result['risky']*1\n",
    "\n",
    "def line_type_phone(phone_api_result):\n",
    "    return phone_api_result['line_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a8a62f",
   "metadata": {},
   "source": [
    "## testing on features from ip, email and phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269067e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T07:43:14.466469Z",
     "start_time": "2022-05-19T07:43:14.392047Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/shubham_mantri/Downloads/IP_TestSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f2781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T07:44:02.056673Z",
     "start_time": "2022-05-19T07:44:02.040605Z"
    }
   },
   "outputs": [],
   "source": [
    "df['rto_or_not'] = df['rejected']*1\n",
    "\n",
    "# df['ip_address_api_result']= df['browser_ip'].progress_apply(ip_address_api_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ca241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T08:51:51.610469Z",
     "start_time": "2022-05-19T08:51:51.572214Z"
    }
   },
   "outputs": [],
   "source": [
    "df['ip_address_crawler_or_not'] = df['ip_address_api_result'].apply(ip_address_crawler_or_not)\n",
    "\n",
    "df['ip_address_vpn_or_not'] = df['ip_address_api_result'].apply(ip_address_vpn_or_not)\n",
    "\n",
    "df['ip_address_tor_or_not'] = df['ip_address_api_result'].apply(ip_address_tor_or_not)\n",
    "\n",
    "df['ip_address_fraud_score'] = df['ip_address_api_result'].apply(ip_address_fraud_score)\n",
    "\n",
    "df['ip_address_recent_abuse_or_not'] = df['ip_address_api_result'].apply(ip_address_recent_abuse_or_not)\n",
    "\n",
    "df['ip_address_bot_or_not'] = df['ip_address_api_result'].apply(ip_address_bot_or_not)\n",
    "\n",
    "df['ip_address_mobile_or_not'] = df['ip_address_api_result'].apply(ip_address_mobile_or_not)\n",
    "\n",
    "df['ip_address_lat_long_distance'] = df.apply(lambda x: ip_address_lat_long_distance(x['ip_address_api_result'],x['latitude'],x['longitude']),axis=1)\n",
    "\n",
    "# df.to_csv('ip_api_result_19_05_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1f91d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T09:33:44.767397Z",
     "start_time": "2022-05-19T09:33:44.633739Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['platform','os']] = df.apply(lambda x: device_details(x['user_agent']),axis=1,result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329eee29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:01:18.146137Z",
     "start_time": "2022-05-26T15:01:18.111906Z"
    }
   },
   "outputs": [],
   "source": [
    "def bins(feature,demand='lower',label = 'rto_or_not',df = df,method='percentile',total_count_threshold=3,rto_pct_threshold=0):\n",
    "    \n",
    "    def not_null_columns(df):\n",
    "        a=[]\n",
    "        for i in df.columns:\n",
    "            if df[i].isnull().sum()==0:\n",
    "                a.append(i)\n",
    "        return a\n",
    "\n",
    "\n",
    "\n",
    "    def link(feature=feature,label=label, df = df,total_count_threshold=total_count_threshold,rto_pct_threshold=rto_pct_threshold):\n",
    "        pivot=df.pivot_table(values=[i for i in not_null_columns(df) if i not in [feature,label]][0],index=feature,columns=label,aggfunc='count')\n",
    "        pivot['sum']=pivot.sum(axis=1)\n",
    "        pivot.fillna(0,inplace=True)\n",
    "        pivot['rto_pct']=(pivot[1])/(pivot['sum'])\n",
    "        return pivot.loc[(pivot['sum']>=total_count_threshold)&(pivot['rto_pct']>=rto_pct_threshold),:]\n",
    "    \n",
    "    if demand=='equal':\n",
    "        return link(feature)\n",
    "    \n",
    "    \n",
    "    if method == 'percentile':\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['percentile','value_less/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                total = len(df.loc[df[feature]<=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_less/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['percentile','value_more/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(0,100,5)]:\n",
    "                total = len(df.loc[df[feature]>=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_more/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    else:\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['value_less/equal_than','total','rto_pct'])\n",
    "            for i in range(1,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]<=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_less/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['value_more/equal_than','total','rto_pct'])\n",
    "            for i in range(0,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]>=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_more/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    table['feature'] = feature\n",
    "    \n",
    "\n",
    "    \n",
    "    if demand == 'lower':\n",
    "        return table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_less/equal_than','total','rto_pct']].drop_duplicates()\n",
    "    else:\n",
    "        return table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_more/equal_than','total','rto_pct']].drop_duplicates()        \n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc09c04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T08:54:26.631725Z",
     "start_time": "2022-05-19T08:54:26.569588Z"
    }
   },
   "outputs": [],
   "source": [
    "link('ip_address_crawler_or_not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c33f8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T09:04:43.383573Z",
     "start_time": "2022-05-19T09:04:43.345980Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "link('ip_address_mobile_or_not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfa4aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T09:14:07.537469Z",
     "start_time": "2022-05-19T09:14:07.438173Z"
    }
   },
   "outputs": [],
   "source": [
    "bins('ip_address_lat_long_distance',demand='upper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364b29f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T10:54:08.012782Z",
     "start_time": "2022-05-19T10:54:07.784443Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['ip_address_fraud_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accfea40",
   "metadata": {},
   "source": [
    "# Python script periodic scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705d676",
   "metadata": {},
   "source": [
    "## using advance python scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2934d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T00:23:21.936063Z",
     "start_time": "2022-05-18T00:20:45.985008Z"
    }
   },
   "outputs": [],
   "source": [
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "\n",
    "def some_job():\n",
    "    print(\"Decorated job\")\n",
    "\n",
    "scheduler = BlockingScheduler()\n",
    "scheduler.add_job(some_job, 'interval', minutes=1, id='job1')\n",
    "# scheduler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25169751",
   "metadata": {},
   "source": [
    "## using crontab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f3d6d",
   "metadata": {},
   "source": [
    "# new rule analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318678e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-19T12:21:40.912155Z",
     "start_time": "2022-05-19T12:21:40.895822Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_rule_analysis(df,feature,threshold,demand='upper'):\n",
    "    from sklearn.metrics import recall_score, precision_score\n",
    "    if demand=='upper':\n",
    "        df['new_rule_rto_or_not'] = np.where(df[feature]>=threshold,1,0)\n",
    "    else:\n",
    "        df['new_rule_rto_or_not'] = np.where(df[feature]<=threshold,1,0)\n",
    "\n",
    "    df['predicted_rto_or_not_2'] = np.where((df['rto_or_not']==1)|(df['new_rule_rto_or_not']==1),1,0)\n",
    "\n",
    "    initial_recall = recall_score(df['rto_or_not'],df['predicted_rto_or_not'])\n",
    "    final_recall = recall_score(df['rto_or_not'],df['predicted_rto_or_not_2'])\n",
    "\n",
    "    initial_precision = precision_score(df['rto_or_not'],df['predicted_rto_or_not'])\n",
    "    final_precision = precision_score(df['rto_or_not'],df['predicted_rto_or_not_2'])\n",
    "\n",
    "    metric_dict = {'initial_recall':initial_recall,'initial_precision':initial_precision,'final_recall':final_recall,'final_precision':final_precision}\n",
    "\n",
    "    return metric_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e9370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T09:35:02.411099Z",
     "start_time": "2022-05-23T09:35:02.349304Z"
    }
   },
   "outputs": [],
   "source": [
    "def ip_address_api_result(ip_address):\n",
    "    key = 'lLIPCpwWduNXG3BG6u7aX9zxdjS4n6bM'\n",
    "    res = requests.get(f'https://ipqualityscore.com/api/json/ip/{key}/{ip_address}').json()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d08bcf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:11:08.572996Z",
     "start_time": "2022-05-23T13:11:08.205582Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ip_address_api_result('192.456.423.456')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef74938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:06:45.598005Z",
     "start_time": "2022-05-23T13:06:45.543366Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10faf643",
   "metadata": {},
   "source": [
    "# Row by Row applying the fuction - rather use Apply function in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670875f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:14:38.193083Z",
     "start_time": "2022-05-23T13:14:38.168159Z"
    }
   },
   "outputs": [],
   "source": [
    "rand = pd.DataFrame()\n",
    "for i,row in df.iterrows():\n",
    "    rand = rand.append(pd.DataFrame(row).T)\n",
    "    if i==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd2fa0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T13:14:39.247309Z",
     "start_time": "2022-05-23T13:14:39.212448Z"
    }
   },
   "outputs": [],
   "source": [
    "rand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc7292",
   "metadata": {},
   "source": [
    "# Apply function in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbd7ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T18:23:34.015844Z",
     "start_time": "2022-05-23T18:23:33.629465Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply_function_in_batch\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "df = df\n",
    "start = 0\n",
    "end = len(df)\n",
    "batch_size = 10\n",
    "func_col_name = 'result'\n",
    "function = 'lambda x: pin_check(x[\"customer_pincode\"])'\n",
    "\n",
    "for index in range(start, end, batch_size):\n",
    "    print(str(index) + '-' + str(index + batch_size - 1))\n",
    "    temp_df = df.iloc[index:(index + batch_size), :]\n",
    "    # eg. function='lambda x: pin_check(x[\"customer_pincode\"]'\n",
    "    temp_df[func_col_name] = temp_df.progress_apply(eval(function), axis=1)\n",
    "    output_df = output_df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d9209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-23T18:06:12.947983Z",
     "start_time": "2022-05-23T18:06:12.931344Z"
    }
   },
   "outputs": [],
   "source": [
    "def pin_check(pin):\n",
    "    if type(pin)==float:\n",
    "        pin = int(pin)\n",
    "    if str(pin).isnumeric()==False:\n",
    "        return 0\n",
    "    if len(str(pin))!=6:\n",
    "        return 0\n",
    "    if int(str(pin)[0])==0:\n",
    "        return 0\n",
    "    if int(str(pin)[0:2]) in [10,29,35,54,55,65,66,86,87,88,89]:\n",
    "        return 0\n",
    "    return 1\n",
    "            \n",
    "# df['pin_check'] = df.apply(lambda x: pin_check(x['customer_pincode']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8b706",
   "metadata": {},
   "source": [
    "# FastAPI Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI is used to create api\n",
    "\n",
    "from fastapi import FastAPI, Path\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def index():\n",
    "    return {\"name\":\"First Data\"}\n",
    "\n",
    "students = {1: {\"name\": \"john\", \"age\": 17}}\n",
    "\n",
    "#this is path parameter\n",
    "@app.get(\"/get-student/{student_id}\")\n",
    "def get_student(student_id : int = Path(None,description=\"ID of the Student\",gt=0,lt=3)): #greater than 0 and less than 3\n",
    "    return students[student_id]\n",
    "\n",
    "\n",
    "\n",
    "@app.get(\"/get-sum\")\n",
    "def sum_(a: int=0,b: int=0):\n",
    "    return a+b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136096c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-24T17:47:28.260753Z",
     "start_time": "2022-05-24T17:47:27.180817Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def correct_state_spelling(gibberish_city_state_df, state, threshold_spelling = 70,threshold_phonetics = 80):\n",
    "        if type(state)!=str:\n",
    "            return \"gibberish_state\"\n",
    "        check_list = list(gibberish_city_state_df['State/UT'].str.lower())\n",
    "        if state in check_list:\n",
    "            return(state)\n",
    "        \n",
    "        def match_pct_spelling(word):\n",
    "            return fuzz.ratio(word.lower(),state.lower())\n",
    "\n",
    "        def match_pct_phonetics(word):\n",
    "            return fuzz.ratio(jellyfish.soundex(word.lower()),jellyfish.soundex(state.lower()))\n",
    "        \n",
    "        lst_spelling = list(map(match_pct_spelling,np.array(check_list)))\n",
    "        lst_phonetics = list(map(match_pct_phonetics,np.array(check_list)))\n",
    "        \n",
    "        if max(lst_phonetics)>=threshold_phonetics:\n",
    "            return check_list[np.argmax(lst_phonetics)]\n",
    "        if max(lst_spelling)>=threshold_spelling:\n",
    "            return check_list[np.argmax(lst_spelling)]\n",
    "        else:\n",
    "            return \"gibberish_state\"\n",
    "\n",
    "\n",
    "def correct_city_spelling(gibberish_city_state_df, city, state, threshold_spelling = 70,threshold_phonetics = 80):\n",
    "        cleaned_state = correct_state_spelling(gibberish_city_state_df, state)\n",
    "        if cleaned_state == \"gibberish_state\":\n",
    "            return \"gibberish_state\"\n",
    "        if not city:\n",
    "            return \"gibberish_city\"\n",
    "        #print(gibberish_city_state_df.loc[gibberish_city_state_df['State/UT'].str.lower()==state.lower()])\n",
    "        check_list = list(gibberish_city_state_df.loc[gibberish_city_state_df['State/UT'].str.lower()==cleaned_state.lower(),'City'])\n",
    "        if city in check_list:\n",
    "            return(city)\n",
    "        #print(check_list)\n",
    "        def match_pct_spelling(word):\n",
    "            return fuzz.partial_ratio(word.lower(),city.lower())\n",
    "        def match_pct_phonetics(word):\n",
    "            return fuzz.ratio(jellyfish.soundex(word.lower()),jellyfish.soundex(city.lower()))\n",
    "        lst_spelling = list(map(match_pct_spelling,np.array(check_list)))\n",
    "        lst_phonetics = list(map(match_pct_phonetics,np.array(check_list)))\n",
    "        if max(lst_phonetics)>=threshold_phonetics:\n",
    "            return check_list[np.argmax(lst_phonetics)]\n",
    "        if max(lst_spelling)>=threshold_spelling:\n",
    "            return check_list[np.argmax(lst_spelling)]\n",
    "        else:\n",
    "            return \"gibberish_city\"\n",
    "\n",
    "        \n",
    "correct_city_spelling(gibberish_city_state_df, 'b','w bengal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38caea",
   "metadata": {},
   "source": [
    "# translate from one language to another - rather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a271eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "unidecode(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7add6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T06:49:15.616567Z",
     "start_time": "2022-05-25T06:49:14.418359Z"
    }
   },
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "from translate import Translator\n",
    "translator= Translator(to_lang=\"english\")\n",
    "# try:\n",
    "translation = translator.translate(\"\")\n",
    "print(translation)\n",
    "# except:\n",
    "#     print(\"Gibberish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538a8ba",
   "metadata": {},
   "source": [
    "# how to get the source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889bdbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T06:57:00.073326Z",
     "start_time": "2022-05-25T06:57:00.063152Z"
    }
   },
   "outputs": [],
   "source": [
    "def sum_(a,b):\n",
    "    return a+b\n",
    "\n",
    "import inspect\n",
    "lines = inspect.getsource(sum_)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f6f81",
   "metadata": {},
   "source": [
    "# Cleaning the text library + translating the words from one language to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579fee68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T07:21:02.816579Z",
     "start_time": "2022-05-25T07:21:02.808618Z"
    }
   },
   "outputs": [],
   "source": [
    "from cleantext import clean\n",
    "\n",
    "clean(\"' twf.  646'\",no_numbers=True,no_punct=True,no_digits=True,no_currency_symbols=True,replace_with_number=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8c4ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T07:33:38.864948Z",
     "start_time": "2022-05-25T07:33:38.852359Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_complete_numeric(text):\n",
    "    if len(clean(text.replace('^',''),no_numbers=True,no_punct=True,no_digits=True,no_currency_symbols=True,replace_with_number=\"\"))==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "clean('  ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804d5a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T09:41:24.233697Z",
     "start_time": "2022-05-25T09:41:22.946846Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install win32api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591ee18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T18:54:38.643278Z",
     "start_time": "2022-05-25T18:54:38.636974Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_valid_phone_number(phone):\n",
    "    if len(re.findall(\"^(\\+91[\\-\\s]?)?[0]?(91)?[789]\\d{9}$\",str(phone)))!=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8da57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T18:55:36.313537Z",
     "start_time": "2022-05-25T18:55:36.304070Z"
    }
   },
   "outputs": [],
   "source": [
    "is_valid_phone_number('0-7060334652')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d76ed68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T19:08:30.166565Z",
     "start_time": "2022-05-25T19:06:51.351188Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install phonenumbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a89c4",
   "metadata": {},
   "source": [
    "# Validation of phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install clean-text\n",
    "import phonenumbers\n",
    "from cleantext.clean import clean\n",
    "def is_valid_phone_number(number):\n",
    "    if pd.isna(number):\n",
    "        return 0\n",
    "    try :\n",
    "        number = str(number)\n",
    "        print(number)\n",
    "        number = clean(number[:3],no_punct=True)+number[3:]\n",
    "        if len(number)<10:\n",
    "            return 0\n",
    "        number = number.replace('////','$').replace('///','$').replace('//','$').replace('/','$').replace(',,,,','$').replace(',,,','$').replace(',,','$').replace(',','$')    \n",
    "        a = 0\n",
    "        for i in number.split('$'):\n",
    "            a = a or (phonenumbers.is_valid_number(phonenumbers.parse(clean(i,no_punct=True),'IN'))*1)\n",
    "        return a\n",
    "    except : \n",
    "        return 0\n",
    "\n",
    "data['Phone Number'] = data['Phone Number'].apply(is_valid_phone_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba214841",
   "metadata": {},
   "source": [
    "# Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa3837",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:33:57.643799Z",
     "start_time": "2022-05-26T00:33:57.595099Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/Users/shubham_mantri/Downloads/Cashify_Historical.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a0fc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:45:34.714756Z",
     "start_time": "2022-05-25T22:45:34.707641Z"
    }
   },
   "source": [
    "# Lazypredict -> apply all models at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b4336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the packages that we will use\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "# Running all the models\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6d9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:49:18.210158Z",
     "start_time": "2022-05-25T22:49:06.677055Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install lux-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789234bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:54:29.414977Z",
     "start_time": "2022-05-25T22:54:29.368912Z"
    }
   },
   "outputs": [],
   "source": [
    "import lux\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe25bc06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:54:23.402589Z",
     "start_time": "2022-05-25T22:54:20.456768Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install lux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4239baa3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:54:35.817328Z",
     "start_time": "2022-05-25T22:54:35.390907Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install --py luxwidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534f80d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:54:48.835878Z",
     "start_time": "2022-05-25T22:54:48.451349Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 enable --py luxwidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf82b2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:55:39.039704Z",
     "start_time": "2022-05-25T22:55:39.034337Z"
    }
   },
   "outputs": [],
   "source": [
    "lux.logger = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb079a04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:55:42.332707Z",
     "start_time": "2022-05-25T22:55:42.294146Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c038f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T22:56:27.686824Z",
     "start_time": "2022-05-25T22:56:27.678199Z"
    }
   },
   "outputs": [],
   "source": [
    "jupyter nbextensions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d72f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:00:29.793441Z",
     "start_time": "2022-05-25T23:00:01.301585Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install autoviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305cf79",
   "metadata": {},
   "source": [
    "# Auto visualisation library for Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ec785",
   "metadata": {},
   "source": [
    "## Autoviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a52b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:02:27.068405Z",
     "start_time": "2022-05-25T23:02:19.447647Z"
    }
   },
   "outputs": [],
   "source": [
    "#Here, we are importing the Autoviz class\n",
    "\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "\n",
    "\n",
    "#Here, we instantiate the Autoviz class\n",
    "\n",
    "AV = AutoViz_Class()\n",
    "\n",
    "df = AV.AutoViz('/Users/shubham_mantri/Downloads/Cashify_Historical.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855dbe42",
   "metadata": {},
   "source": [
    "### Documentation of Autoviz\n",
    "filename  You can use this argument to define the data file.\n",
    "depVar  You can use this to specify the dependent variable in the plots.\n",
    "verbose  Personally, I loved this argument most. There will be three options in this, a. 0  If mention 0, plots will be created with minimum information. b. 1  If mentioned as 1, plots will be created with full information. c. 2  If mentioned 2, no plots will be shown, but it will create a folder in your directory named Autoviz_plots and all the plots will be saved here.\n",
    "chart_format  I told you that you can save the charts by setting verbose as 2. So, you can specify the chart format as PNG, JPG or more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f93c0c6",
   "metadata": {},
   "source": [
    "## Lux library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffc540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:34:16.763893Z",
     "start_time": "2022-05-26T00:34:16.088139Z"
    }
   },
   "outputs": [],
   "source": [
    "import lux\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524712a",
   "metadata": {},
   "source": [
    "## Sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c6276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:14:52.847531Z",
     "start_time": "2022-05-25T23:14:52.812385Z"
    }
   },
   "outputs": [],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "my_report = sv.analyze([data,'train'])\n",
    "my_report.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66464781",
   "metadata": {},
   "source": [
    "# Pyforest -> Importing all libraries at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053bdf21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:36:00.477418Z",
     "start_time": "2022-05-25T23:36:00.230998Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyforest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae6a4ee",
   "metadata": {},
   "source": [
    "## how to add new library in pyforest\n",
    "\n",
    "add that library in -> /Users/shubham_mantri/opt/anaconda3/lib/python3.9/site-packages/pyforest/_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82647eeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:04:29.621597Z",
     "start_time": "2022-05-26T00:03:47.437904Z"
    }
   },
   "outputs": [],
   "source": [
    "import bamboolib as bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e8bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:56:54.458803Z",
     "start_time": "2022-05-25T23:56:52.006344Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install bamboolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec85c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:05:20.219986Z",
     "start_time": "2022-05-26T00:05:20.150709Z"
    }
   },
   "outputs": [],
   "source": [
    "bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18a712",
   "metadata": {},
   "source": [
    "# upgrade version of the library/package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41150959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:49:55.017774Z",
     "start_time": "2022-05-25T23:49:52.332937Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip3 install seaborn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352830cb",
   "metadata": {},
   "source": [
    "# check version of the package/library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40ef28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:02:13.096121Z",
     "start_time": "2022-05-26T00:01:30.376669Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77eb94",
   "metadata": {},
   "source": [
    "# install particular version of library/package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2b852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:00:46.166302Z",
     "start_time": "2022-05-26T00:00:43.912578Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install seaborn==0.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df85455",
   "metadata": {},
   "source": [
    "# Bamboolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33852756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:09:19.620993Z",
     "start_time": "2022-05-26T00:09:18.011705Z"
    }
   },
   "outputs": [],
   "source": [
    "import bamboolib as bam\n",
    "bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b537155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:14:19.222895Z",
     "start_time": "2022-05-26T00:14:19.120864Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'/Users/shubham_mantri/Downloads/Cashify_Historical.csv', sep=',', decimal='.')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5caae",
   "metadata": {},
   "source": [
    "# Pivot Table in Python - User Interface (UI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c62751c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:08:19.444901Z",
     "start_time": "2022-05-26T01:08:19.433053Z"
    }
   },
   "source": [
    "## pivottablejs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0367498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T00:35:14.524429Z",
     "start_time": "2022-05-26T00:35:14.416583Z"
    }
   },
   "outputs": [],
   "source": [
    "from pivottablejs import pivot_ui\n",
    "from IPython.display import HTML\n",
    "\n",
    "pivot_ui(data, outfile_path='pivottablejs.html')\n",
    "HTML('pivottablejs.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9372a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:08:37.226521Z",
     "start_time": "2022-05-26T01:08:37.208241Z"
    }
   },
   "source": [
    "## Mitosheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3ca77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:15:01.422559Z",
     "start_time": "2022-05-26T01:15:01.416734Z"
    }
   },
   "outputs": [],
   "source": [
    "import mitosheet\n",
    "# mitosheet.sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766eafb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:22:37.799199Z",
     "start_time": "2022-05-26T01:22:37.776586Z"
    }
   },
   "outputs": [],
   "source": [
    "mitosheet.sheet(analysis_to_replay=\"id-wsfexosgmg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e92ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:21:40.611691Z",
     "start_time": "2022-05-26T01:21:40.520903Z"
    }
   },
   "outputs": [],
   "source": [
    "from mitosheet import *; register_analysis(\"id-wsfexosgmg\");\n",
    "    \n",
    "# Imported Cashify_Historical.csv\n",
    "import pandas as pd\n",
    "Cashify_Historical = pd.read_csv(r'/Users/shubham_mantri/Downloads/Cashify_Historical.csv')\n",
    "\n",
    "# Pivoted into Cashify_Historical\n",
    "tmp_df = Cashify_Historical[['Payment Status', 'Order Status', 'Pincode']]\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['Order Status'],\n",
    "    columns=['Payment Status'],\n",
    "    values=['Order Status', 'Pincode'],\n",
    "    aggfunc={'Order Status': ['count'], 'Pincode': ['sum']}\n",
    ")\n",
    "pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1, inplace=True)\n",
    "Cashify_Historical_pivot = pivot_table.reset_index()\n",
    "\n",
    "# Pivoted into Cashify_Historical\n",
    "tmp_df = Cashify_Historical[['Payment Status', 'Order Status']]\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['Order Status'],\n",
    "    columns=['Payment Status'],\n",
    "    values=['Order Status'],\n",
    "    aggfunc={'Order Status': ['count']}\n",
    ")\n",
    "pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1, inplace=True)\n",
    "Cashify_Historical_pivot = pivot_table.reset_index()\n",
    "\n",
    "# Pivoted into Cashify_Historical\n",
    "tmp_df = Cashify_Historical[['Payment Status', 'Order Status']]\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['Order Status', 'Payment Status'],\n",
    "    values=['Order Status'],\n",
    "    aggfunc={'Order Status': ['count']}\n",
    ")\n",
    "pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1, inplace=True)\n",
    "Cashify_Historical_pivot = pivot_table.reset_index()\n",
    "\n",
    "# Pivoted into Cashify_Historical\n",
    "tmp_df = Cashify_Historical[['Payment Status', 'Order Status']]\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['Order Status', 'Payment Status'],\n",
    "    values=['Order Status'],\n",
    "    aggfunc={'Order Status': ['count']}\n",
    ")\n",
    "pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1, inplace=True)\n",
    "Cashify_Historical_pivot = pivot_table.reset_index()\n",
    "\n",
    "# Filtered Payment Status\n",
    "Cashify_Historical = Cashify_Historical[Cashify_Historical['Payment Status'].str.contains('Pendi', na=False)]\n",
    "\n",
    "# Pivoted into Cashify_Historical\n",
    "tmp_df = Cashify_Historical[['Payment Status', 'Order Status']]\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['Order Status', 'Payment Status'],\n",
    "    values=['Order Status'],\n",
    "    aggfunc={'Order Status': ['count']}\n",
    ")\n",
    "pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1, inplace=True)\n",
    "Cashify_Historical_pivot = pivot_table.reset_index()\n",
    "\n",
    "# Filtered Pincode\n",
    "Cashify_Historical = Cashify_Historical[Cashify_Historical['Pincode'] > 300000]\n",
    "\n",
    "# Pivoted into Cashify_Historical\n",
    "tmp_df = Cashify_Historical[['Payment Status', 'Order Status']]\n",
    "pivot_table = tmp_df.pivot_table(\n",
    "    index=['Order Status', 'Payment Status'],\n",
    "    values=['Order Status'],\n",
    "    aggfunc={'Order Status': ['count']}\n",
    ")\n",
    "pivot_table.set_axis([flatten_column_header(col) for col in pivot_table.keys()], axis=1, inplace=True)\n",
    "Cashify_Historical_pivot = pivot_table.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ed266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:22:49.324241Z",
     "start_time": "2022-05-26T01:22:49.309139Z"
    }
   },
   "outputs": [],
   "source": [
    "Cashify_Historical_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42249f8e",
   "metadata": {},
   "source": [
    "# Test Train split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5de36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T22:21:32.954061Z",
     "start_time": "2022-05-26T22:21:32.930714Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_validation_test(data,label_column,validation_size=0.25,test_size=0.2):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X=data.drop(columns=label_column)\n",
    "    y=data[label_column]\n",
    "    # train_feature,train_label,test_feature,test_label --> use this for variable\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=test_size, random_state=42)\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "train_feature,train_label,test_feature,test_label = train_validation_test(df,'rto_or_not')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f639d0f6",
   "metadata": {},
   "source": [
    "# General Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a6cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T22:22:37.144209Z",
     "start_time": "2022-05-26T22:22:37.119508Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_squared_log_error,accuracy_score,confusion_matrix,precision_score,recall_score\n",
    "for i in [3,5,6,7,9,12]:\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    model.fit(train_feature,train_label)\n",
    "    predict = model.predict(test_feature)\n",
    "    predict_train = model.predict(train_feature)\n",
    "    cm = pd.DataFrame(confusion_matrix(y_true=test_label,y_pred=predict))\n",
    "    #     f1_score_value = f1_score(y_true=test_label,y_pred=predict_RandomForestClassifier)\n",
    "    #     f1_score_train = f1_score(y_true=train_label,y_pred=predict_RandomForestClassifier_train)\n",
    "    precision_test = precision_score(y_true=test_label,y_pred=predict)\n",
    "    precision_train = precision_score(y_true=train_label,y_pred=predict_train)\n",
    "    recall_test = recall_score(y_true=test_label,y_pred=predict)\n",
    "    recall_train = recall_score(y_true=train_label,y_pred=predict_train)\n",
    "    print(cm)\n",
    "    print(f\"precision_test:{precision_test}, precision_train:{precision_train}, recall_test:{recall_test}, recall_train:{recall_train}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6014e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_squared_log_error,accuracy_score,confusion_matrix,precision_score,recall_score\n",
    "for i in [3,5,6,7,9,12]:\n",
    "    model = DecisionTreeClassifier(max_depth=i)\n",
    "    model.fit(X_train,y_train)\n",
    "    predict = model.predict(X_test)\n",
    "    predict_train = model.predict(X_train)\n",
    "    cm = pd.DataFrame(confusion_matrix(y_true=y_test,y_pred=predict))\n",
    "    #     f1_score_value = f1_score(y_true=y_test,y_pred=predict_RandomForestClassifier)\n",
    "    #     f1_score_train = f1_score(y_true=y_train,y_pred=predict_RandomForestClassifier_train)\n",
    "    precision_test = precision_score(y_true=y_test,y_pred=predict)\n",
    "    precision_train = precision_score(y_true=y_train,y_pred=predict_train)\n",
    "    recall_test = recall_score(y_true=y_test,y_pred=predict)\n",
    "    recall_train = recall_score(y_true=y_train,y_pred=predict_train)\n",
    "    print(cm)\n",
    "    print(f\"precision_test:{precision_test}, precision_train:{precision_train}, recall_test:{recall_test}, recall_train:{recall_train}\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e982f212",
   "metadata": {},
   "source": [
    "## Visualising the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc880d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T22:23:19.295810Z",
     "start_time": "2022-05-26T22:23:19.261101Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(30,30))  # set plot size (denoted in inches)\n",
    "tree.plot_tree(model, fontsize=12,max_depth=3,filled=True,feature_names=train_feature.columns,class_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b548a6",
   "metadata": {},
   "source": [
    "# Rules based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb666ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T22:21:05.480848Z",
     "start_time": "2022-05-26T22:21:04.179758Z"
    }
   },
   "outputs": [],
   "source": [
    "from imodels import BoostedRulesClassifier, FIGSClassifier, SkopeRulesClassifier\n",
    "from imodels import RuleFitRegressor, HSTreeRegressorCV, SLIMRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = FIGSClassifier() # initialize a model\n",
    "model.fit(X_train, y_train)   # fit model\n",
    "preds = model.predict(X_test) # predictions: shape is (n_test, 1)\n",
    "preds_proba = model.predict_proba(X_test) # predicted probabilities: shape is (n_test, n_classes)\n",
    "print(model)\n",
    "# print(len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9676535d",
   "metadata": {},
   "source": [
    "# Random sampling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "rto_df = df.loc[df['rto_or_not'] == 1, :]\n",
    "others_df = df.loc[df['rto_or_not'] == 0, :]\n",
    "\n",
    "others_random = others_df.sample(n=rto_df.shape[0] * 2, random_state=1)\n",
    "\n",
    "df = rto_df.append(others_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a2082",
   "metadata": {},
   "source": [
    "# Duplicate values in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb17f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "print([item for item, count in collections.Counter(a).items() if count > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d8d027",
   "metadata": {},
   "source": [
    "# saving and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'decision_tree_model_v1.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd33a04",
   "metadata": {},
   "source": [
    "# My classification tree model -> to output rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1558c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T09:54:20.826590Z",
     "start_time": "2022-06-01T09:54:20.685821Z"
    }
   },
   "outputs": [],
   "source": [
    "def rto_pct(data,rto='rto_or_not'):\n",
    "#     print(data[rto].value_counts())\n",
    "    try:\n",
    "        return round(data[rto].value_counts()[1]/data[rto].value_counts().sum(),4)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "opposite_sign = lambda x: 'greater' if x=='less_or_equal' else 'less_or_equal'\n",
    "\n",
    "sign = lambda x: '<=' if x=='less_or_equal' else '>'\n",
    "\n",
    "def my_classification_tree(data,depth = 1,rule=\"\",total_count_threshold = 5,rto_pct_threshold = 0.7):\n",
    "    #precision  rto_pct_threshold and recall  1/rto_pct_threshold \n",
    "    #number of rules  1/total_count_threshold\n",
    "    #number of rules  1/rto_pct_threshold  1/precision  recall\n",
    "    split_data = pd.DataFrame(columns = ['column','mid','sign','total_count','rto_pct'])\n",
    "    for col in list(set(data.columns)-{'rto_or_not'}):\n",
    "        col_values = np.sort(data[col].astype('float').unique())\n",
    "        for index in range(len(col_values)-1):\n",
    "            mid = (col_values[index]+col_values[index+1])/2\n",
    "            temp_dic_less = {'column' : col, 'mid' : mid, 'sign' : 'less_or_equal','total_count' : len(data.loc[data[col]<=mid]) , 'rto_pct' : rto_pct(data = data.loc[data[col]<=mid])}\n",
    "            temp_dic_greater = {'column' : col, 'mid' : mid, 'sign' : 'greater','total_count' : len(data.loc[data[col]>mid]) , 'rto_pct' : rto_pct(data = data.loc[data[col]>mid])}\n",
    "    #         print(temp_dic_less)\n",
    "    #         print(temp_dic_greater)\n",
    "            split_data = split_data.append(temp_dic_less,ignore_index=True)\n",
    "            split_data = split_data.append(temp_dic_greater,ignore_index=True)\n",
    "#     pdb.set_trace()\n",
    "    split_data = split_data.sort_values(by = ['rto_pct','total_count'], ascending = [False,False])\n",
    "    split_data = split_data.loc[(split_data['total_count']>=total_count_threshold)&(split_data['rto_pct']>=rto_pct_threshold),:]\n",
    "    if len(split_data)==0:\n",
    "        print('no_more_splits_possible')\n",
    "        return\n",
    "    split_dict = dict(split_data.iloc[0,:])\n",
    "    if depth==1:\n",
    "        right_rule = rule + f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    else:\n",
    "        right_rule = rule + ' & '+ f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    if depth==1:\n",
    "        left_rule = rule + f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    else:\n",
    "        left_rule = rule + ' & '+ f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "\n",
    "#     print(f'{depth}-split -> {split_dict}')\n",
    "    print(f'rule{depth} = {left_rule}  ## probability={split_dict['rto_pct']}')\n",
    "    \n",
    "    if split_dict['sign']=='less_or_equal':\n",
    "        data = data.loc[data[split_dict['column']]>split_dict['mid'],:]\n",
    "    else:\n",
    "        data = data.loc[data[split_dict['column']]<=split_dict['mid'],:]\n",
    "    df = data.copy()\n",
    "    my_classification_tree(data = df,depth=depth+1,rule = right_rule)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b2733",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "def rto_pct(data,rto='rto_or_not'):\n",
    "#     print(data[rto].value_counts())\n",
    "    try:\n",
    "        return round(data[rto].value_counts()[1]/data[rto].value_counts().sum(),4)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "opposite_sign = lambda x: 'greater' if x=='less_or_equal' else 'less_or_equal'\n",
    "\n",
    "sign = lambda x: '<=' if x=='less_or_equal' else '>'\n",
    "\n",
    "def my_classification_tree(data,depth = 1,rule=\"\",total_count_threshold = 5,rto_pct_threshold = 0.6):\n",
    "    #precision  rto_pct_threshold and recall  1/rto_pct_threshold \n",
    "    #number of rules  1/total_count_threshold\n",
    "    #number of rules  1/rto_pct_threshold  1/precision  recall\n",
    "    def threshold(count,pct,x1=3,y1=0.2,x2=10,y2=0.6):\n",
    "        m = round((y2-y1)/(x2-x1),5)\n",
    "        c = y2 - m*x2\n",
    "        result = True if ((pct>=min((m*count+c),y2)) and (count>=x1)) else False\n",
    "        return result\n",
    "    split_data = pd.DataFrame(columns = ['column','mid','sign','total_count','rto_pct'])\n",
    "    for col in list(set(data.columns)-{'rto_or_not'}):\n",
    "        col_values = np.sort(data[col].astype('float').unique())\n",
    "        for index in range(len(col_values)-1):\n",
    "            mid = round((col_values[index]+col_values[index+1])/2,2)\n",
    "            temp_dic_less = {'column' : col, 'mid' : mid, 'sign' : 'less_or_equal','total_count' : len(data.loc[data[col]<=mid]) , 'rto_pct' : rto_pct(data = data.loc[data[col]<=mid])}\n",
    "            temp_dic_greater = {'column' : col, 'mid' : mid, 'sign' : 'greater','total_count' : len(data.loc[data[col]>mid]) , 'rto_pct' : rto_pct(data = data.loc[data[col]>mid])}\n",
    "    #         print(temp_dic_less)\n",
    "    #         print(temp_dic_greater)\n",
    "            split_data = split_data.append(temp_dic_less,ignore_index=True)\n",
    "            split_data = split_data.append(temp_dic_greater,ignore_index=True)\n",
    "#     pdb.set_trace()\n",
    "    \n",
    "#     split_data = split_data.sort_values(by = ['rto_pct','total_count'], ascending = [False,False])\n",
    "#     split_data = split_data.loc[(split_data['total_count']>=total_count_threshold)&(split_data['rto_pct']>=rto_pct_threshold),:]\n",
    "    split_data['threshold'] = split_data.apply(lambda x: threshold(x['total_count'],x['rto_pct']),axis=1)\n",
    "    split_data = split_data.loc[split_data['threshold']==True,:]    \n",
    "#     split_data = split_data.sort_values(by = ['rto_pct','total_count'], ascending = [False,False])\n",
    "    split_data = split_data.sort_values(by = ['total_count'], ascending = [False])\n",
    "    a.append(split_data)\n",
    "    \n",
    "    if len(split_data)==0:\n",
    "        \n",
    "        print('no_more_splits_possible')\n",
    "        return\n",
    "    split_dict = dict(split_data.iloc[0,:])\n",
    "    if depth==1:\n",
    "        right_rule = rule + f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    else:\n",
    "        right_rule = rule + ' & '+ f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    if depth==1:\n",
    "        left_rule = rule + f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    else:\n",
    "        left_rule = rule + ' & '+ f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "\n",
    "#     print(f'{depth}-split -> {split_dict}')\n",
    "    print(f'rule{depth} = {left_rule}  ## probability={split_dict[\"rto_pct\"]} and total_count={split_dict[\"total_count\"]}')\n",
    "\n",
    "    if split_dict['sign']=='less_or_equal':\n",
    "        data = data.loc[data[split_dict['column']]>split_dict['mid'],:]\n",
    "    else:\n",
    "        data = data.loc[data[split_dict['column']]<=split_dict['mid'],:]\n",
    "    df = data.copy()\n",
    "#     if depth==2:\n",
    "#         return\n",
    "    my_classification_tree(data = df,depth=depth+1,rule = right_rule)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56624c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T09:55:04.655629Z",
     "start_time": "2022-06-01T09:55:04.621152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"my tree looks like :\")\n",
    "from IPython.display import Image\n",
    "Image(filename='/Users/shubham_mantri/Downloads/my tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f153f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T15:25:57.933872Z",
     "start_time": "2022-06-01T15:25:57.922024Z"
    }
   },
   "source": [
    "# how to import image in jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67aa027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T15:26:04.670754Z",
     "start_time": "2022-06-01T15:26:04.586147Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"my tree looks like :\")\n",
    "from IPython.display import Image\n",
    "Image(filename='/Users/shubham_mantri/Downloads/my tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d444332",
   "metadata": {},
   "source": [
    "# print in bold in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd2c95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T19:02:42.309190Z",
     "start_time": "2022-06-01T19:02:42.300441Z"
    }
   },
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "print(color.PURPLE + color.BOLD + 'Hello World !' + color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfe484",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:33:05.955480Z",
     "start_time": "2022-06-06T09:33:05.724270Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/shubham_mantri/Downloads/generic_train_31May.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4f1c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:05:26.448439Z",
     "start_time": "2022-06-06T08:05:26.410528Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_columns = [\"orders_count\",\"total_spent\",\"verified_email\",\"total_discounts\",\"total_price\",\"items_quantity\",\"items_total\",\\\n",
    "\"complete_address_len\",\"complete_address_len_number\",\"complete_address_len_letter\",\"complete_address_len_space\",\\\n",
    "\"complete_address_len_others\",\"complete_address_len_number_pc\",\"complete_address_len_letter_pc\",\"complete_address_len_space_pc\",\\\n",
    "\"complete_address_len_others_pc\",\"complete_address_num_unique_chars\",\"complete_address_pc_unique_chars_to_len\",\\\n",
    "\"complete_address_num_tokens\",\"complete_address_avg_token_len\",\"complete_address_num_unique_tokens\",\\\n",
    "\"complete_address_pc_unique_tokens_to_total_tokens\",\"order_weekend_or_not\",\"order_hour\",\"order_time_bucket\",\\\n",
    "\"unique_alphabets_count\",\"unique_alphabets_count_pct\",\"comma_count\",\"vowel_count\",\"vowel_pct\",\\\n",
    "\"special_character_count\",\"special_character_pct\",\"email_check\",\"name_check\",\"address1_address2_ratio\",\\\n",
    "\"address1_address2_partial_ratio\",\"alpha_numeric_count\",\"alpha_numeric_pct\",\"complete_address_num_common_tokens_all\",\\\n",
    "\"complete_address_num_unique_common_tokens_all\",\"complete_address_pc_common_tokens_to_total_tokens_all\",\\\n",
    "\"complete_address_num_non_common_tokens_all\",\"complete_address_num_common_tokens_del\",\"complete_address_num_unique_common_tokens_del\",\\\n",
    "\"complete_address_pc_common_tokens_to_total_tokens_del\",\"complete_address_num_non_common_tokens_del\",\"complete_address_num_common_tokens_rto\",\\\n",
    "\"complete_address_num_unique_common_tokens_rto\",\"complete_address_pc_common_tokens_to_total_tokens_rto\",\"complete_address_num_non_common_tokens_rto\",\\\n",
    "\"complete_address_most_popular_token_freq\",\"pin_check\",\"pin_city_check\",\"pin_state_check\",\"is_valid_phone\",\"gibberish_count\",\"gibberish_pct\",\\\n",
    "\"gibberish_city_or_not\",\"is_city_complete_numeric\",\"lowest_type_googlemaps\",\"gmap_addr_results_count\",\"original_addr_vs_formatted_gmap_match_pct\",\\\n",
    "\"gmap_location_type\"]\n",
    "\n",
    "# Change Feature Types\n",
    "\n",
    "float_ = ['orders_count', 'total_spent', 'total_discounts' , 'total_price', 'items_quantity', 'items_total', 'verified_email']\n",
    "for col in float_:\n",
    "#     df[col] = df[col].astype(float)\n",
    "    train[col] = train[col].astype(float)\n",
    "#     test1[col] = test1[col].astype(float)\n",
    "#     test2[col] = test2[col].astype(float)\n",
    "#     test3[col] = test3[col].astype(float)\n",
    "\n",
    "flat_features = ['orders_count', 'total_spent', 'verified_email', 'total_discounts',\n",
    "       'total_price', 'items_quantity', 'items_total', 'complete_address_len',\n",
    "       'complete_address_len_number', 'complete_address_len_letter',\n",
    "       'complete_address_len_space', 'complete_address_len_others',\n",
    "       'complete_address_len_number_pc', 'complete_address_len_letter_pc',\n",
    "       'complete_address_len_space_pc', 'complete_address_len_others_pc',\n",
    "       'complete_address_num_unique_chars',\n",
    "       'complete_address_pc_unique_chars_to_len',\n",
    "       'complete_address_num_tokens', 'complete_address_avg_token_len',\n",
    "       'complete_address_num_unique_tokens',\n",
    "       'complete_address_pc_unique_tokens_to_total_tokens',\n",
    "       'order_weekend_or_not', 'order_hour', 'unique_alphabets_count',\n",
    "       'unique_alphabets_count_pct', 'comma_count', 'vowel_count', 'vowel_pct',\n",
    "       'special_character_count',\n",
    "       'special_character_pct', 'email_check', 'name_check',\n",
    "       'address1_address2_ratio', 'address1_address2_partial_ratio',\n",
    "       'alpha_numeric_count', 'alpha_numeric_pct',\n",
    "       'complete_address_num_common_tokens_all',\n",
    "       'complete_address_num_unique_common_tokens_all',\n",
    "       'complete_address_pc_common_tokens_to_total_tokens_all',\n",
    "       'complete_address_num_non_common_tokens_all',\n",
    "       'complete_address_num_common_tokens_del',\n",
    "       'complete_address_num_unique_common_tokens_del',\n",
    "       'complete_address_pc_common_tokens_to_total_tokens_del',\n",
    "       'complete_address_num_non_common_tokens_del',\n",
    "       'complete_address_num_common_tokens_rto',\n",
    "       'complete_address_num_unique_common_tokens_rto',\n",
    "       'complete_address_pc_common_tokens_to_total_tokens_rto',\n",
    "       'complete_address_num_non_common_tokens_rto',\n",
    "       'complete_address_most_popular_token_freq', 'pin_check',\n",
    "       'pin_city_check', 'pin_state_check', 'is_valid_phone',\n",
    "       'gibberish_count', 'gibberish_pct', 'gibberish_city_or_not',\n",
    "       'is_city_complete_numeric', 'lowest_type_googlemaps',\n",
    "       'gmap_addr_results_count', 'original_addr_vs_formatted_gmap_match_pct',\n",
    "       'order_time_bucket_0-9', 'order_time_bucket_12-15',\n",
    "       'order_time_bucket_15-18', 'order_time_bucket_18-21',\n",
    "       'order_time_bucket_21-24', 'order_time_bucket_9-12',\n",
    "       'gmap_location_type_APPROXIMATE', 'gmap_location_type_Error',\n",
    "       'gmap_location_type_GEOMETRIC_CENTER', 'gmap_location_type_No Results',\n",
    "       'gmap_location_type_RANGE_INTERPOLATED', 'gmap_location_type_ROOFTOP']\n",
    "\n",
    "def add_missing_columns(df, flat_features = flat_features):\n",
    "    cols = df.columns\n",
    "    for feature in flat_features:\n",
    "        if feature not in cols:\n",
    "            df[feature] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1e3a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:05:28.431366Z",
     "start_time": "2022-06-06T08:05:28.395403Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = add_missing_columns(pd.get_dummies(train[feature_columns]))\n",
    "y_test = train['rto_or_not']\n",
    "\n",
    "\n",
    "df= pd.concat([X_test,y_test],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bc27b",
   "metadata": {},
   "source": [
    "# My regression tree -> output rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd92c58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T23:25:54.571153Z",
     "start_time": "2022-06-01T23:25:54.554452Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "\n",
    "def rto_pct(data, rto='rto_or_not'):\n",
    "    #     print(data[rto].value_counts())\n",
    "    try:\n",
    "        return round(\n",
    "            data[rto].value_counts()[1] / data[rto].value_counts().sum(), 4)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def stdev_to_mean(data, rto):\n",
    "    #     print(data[rto].value_counts())\n",
    "    try:\n",
    "        return round(\n",
    "            np.std(data[rto]) / np.mean(data[rto]), 4)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def opposite_sign(x):\n",
    "    return 'greater' if x == 'less_or_equal' else 'less_or_equal'\n",
    "\n",
    "\n",
    "def sign(x):\n",
    "    return '<=' if x == 'less_or_equal' else '>'\n",
    "\n",
    "\n",
    "def my_regression_tree(data=df,label_col = 'medv',\n",
    "            depth=1,\n",
    "            rule=\"\",\n",
    "            total_count_threshold=5,\n",
    "            stdev_to_mean_threshold=0.05):\n",
    "    # precision  rto_pct_threshold and recall  1/rto_pct_threshold\n",
    "    # number of rules  1/total_count_threshold\n",
    "    split_data = pd.DataFrame(\n",
    "        columns=['column', 'mid', 'sign', 'total_count', 'stdev_to_mean'])\n",
    "    for col in list(set(data.columns) - {label_col}):\n",
    "        col_values = np.sort(data[col].astype('float').unique())\n",
    "        for index in range(len(col_values) - 1):\n",
    "            mid = (col_values[index] + col_values[index + 1]) / 2\n",
    "            temp_dic_less = {\n",
    "                'column': col,\n",
    "                'mid': mid,\n",
    "                'sign': 'less_or_equal',\n",
    "                'total_count': len(data.loc[data[col] <= mid]),\n",
    "                'stdev_to_mean': stdev_to_mean(data=data.loc[data[col] <= mid],rto=label_col)\n",
    "            }\n",
    "            temp_dic_greater = {\n",
    "                'column': col,\n",
    "                'mid': mid,\n",
    "                'sign': 'greater',\n",
    "                'total_count': len(data.loc[data[col] > mid]),\n",
    "                'stdev_to_mean': stdev_to_mean(data=data.loc[data[col] > mid],rto=label_col)\n",
    "            }\n",
    "            #         print(temp_dic_less)\n",
    "            #         print(temp_dic_greater)\n",
    "            split_data = split_data.append(temp_dic_less, ignore_index=True)\n",
    "            split_data = split_data.append(temp_dic_greater, ignore_index=True)\n",
    "#     pdb.set_trace()\n",
    "    split_data = split_data.sort_values(by=['stdev_to_mean', 'total_count'],\n",
    "                                        ascending=[True, False])\n",
    "    split_data = split_data.loc[\n",
    "        (split_data['total_count'] >= total_count_threshold) &\n",
    "        (split_data['stdev_to_mean'] <= stdev_to_mean_threshold), :]\n",
    "    print(split_data.head())\n",
    "    if len(split_data) == 0:\n",
    "        print('no_more_splits_possible')\n",
    "        return\n",
    "    split_dict = dict(split_data.iloc[0, :])\n",
    "    print(split_dict)\n",
    "    if depth == 1:\n",
    "        right_rule = rule + \\\n",
    "            f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    else:\n",
    "        right_rule = rule + ' & ' + \\\n",
    "            f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    if depth == 1:\n",
    "        left_rule = rule + \\\n",
    "            f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "    else:\n",
    "        left_rule = rule + ' & ' + \\\n",
    "            f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "\n",
    "\n",
    "#     print(f'{depth}-split -> {split_dict}')\n",
    "    print(f'rule{depth} = {left_rule}')\n",
    "\n",
    "    if split_dict['sign'] == 'less_or_equal':\n",
    "        data = data.loc[data[split_dict['column']] > split_dict['mid'], :]\n",
    "    else:\n",
    "        data = data.loc[data[split_dict['column']] <= split_dict['mid'], :]\n",
    "    df = data.copy()\n",
    "    print(\"reached end\")\n",
    "    my_tree(data=df, depth=depth + 1, rule=right_rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5f456",
   "metadata": {},
   "source": [
    "# Importing builtin sample datasets from pydataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1862544",
   "metadata": {},
   "source": [
    "## Regression sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e21a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T23:18:39.751085Z",
     "start_time": "2022-06-01T23:18:39.729321Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "df = data('Boston')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74629cae",
   "metadata": {},
   "source": [
    "## Classification sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479291cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rom pydataset import data\n",
    "\n",
    "df = data('iris')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada54fa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-01T23:30:44.795344Z",
     "start_time": "2022-06-01T23:28:43.286083Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "my_regression_tree(data = df,stdev_to_mean_threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f751ca",
   "metadata": {},
   "source": [
    "# My random forest -> output rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_random_forest(data,total_count_threshold=5,rto_pct_threshold=0.7,no_of_trees=10,sample_pct=0.7):\n",
    "    def rto_pct(rto='rto_or_not',data = temp):\n",
    "    #     print(data[rto].value_counts())\n",
    "        try:\n",
    "            return round(data[rto].value_counts()[1]/data[rto].value_counts().sum(),4)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    opposite_sign = lambda x: 'greater' if x=='less_or_equal' else 'less_or_equal'\n",
    "\n",
    "    sign = lambda x: '<=' if x=='less_or_equal' else '>'\n",
    "\n",
    "    def my_tree(data = df,depth = 1,rule=\"\",total_count_threshold = total_count_threshold,rto_pct_threshold = rto_pct_threshold):\n",
    "        #precision  rto_pct_threshold and recall  1/rto_pct_threshold \n",
    "        #number of rules  1/total_count_threshold\n",
    "        split_data = pd.DataFrame(columns = ['column','mid','sign','total_count','rto_pct'])\n",
    "        for col in list(set(data.columns)-{'rto_or_not'}):\n",
    "            col_values = np.sort(data[col].astype('float').unique())\n",
    "            for index in range(len(col_values)-1):\n",
    "                mid = (col_values[index]+col_values[index+1])/2\n",
    "                temp_dic_less = {'column' : col, 'mid' : mid, 'sign' : 'less_or_equal','total_count' : len(data.loc[data[col]<=mid]) , 'rto_pct' : rto_pct(data = data.loc[data[col]<=mid])}\n",
    "                temp_dic_greater = {'column' : col, 'mid' : mid, 'sign' : 'greater','total_count' : len(data.loc[data[col]>mid]) , 'rto_pct' : rto_pct(data = data.loc[data[col]>mid])}\n",
    "        #         print(temp_dic_less)\n",
    "        #         print(temp_dic_greater)\n",
    "                split_data = split_data.append(temp_dic_less,ignore_index=True)\n",
    "                split_data = split_data.append(temp_dic_greater,ignore_index=True)\n",
    "    #     pdb.set_trace()\n",
    "        split_data = split_data.sort_values(by = ['rto_pct','total_count'], ascending = [False,False])\n",
    "        split_data = split_data.loc[(split_data['total_count']>=total_count_threshold)&(split_data['rto_pct']>=rto_pct_threshold),:]\n",
    "        if len(split_data)==0:\n",
    "            print('no_more_splits_possible')\n",
    "            return\n",
    "        split_dict = dict(split_data.iloc[0,:])\n",
    "        if depth==1:\n",
    "            right_rule = rule + f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "        else:\n",
    "            right_rule = rule + ' & '+ f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign(opposite_sign(split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "        if depth==1:\n",
    "            left_rule = rule + f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "        else:\n",
    "            left_rule = rule + ' & '+ f'np.array(df[\\'{split_dict[\"column\"]}\\']{sign((split_dict[\"sign\"]))}{split_dict[\"mid\"]})'\n",
    "\n",
    "    #     print(f'{depth}-split -> {split_dict}')\n",
    "        print(f'rule{depth} = {left_rule}')\n",
    "\n",
    "        if split_dict['sign']=='less_or_equal':\n",
    "            data = data.loc[data[split_dict['column']]>split_dict['mid'],:]\n",
    "        else:\n",
    "            data = data.loc[data[split_dict['column']]<=split_dict['mid'],:]\n",
    "        df = data.copy()\n",
    "        my_tree(data = df,depth=depth+1,rule = right_rule)\n",
    "\n",
    "    result_list = []    \n",
    "    for tree_number in range(1,no_of_trees+1,1):\n",
    "        print(f\"##TREE-{tree_number}-RULES##\")\n",
    "        data_temp = data.sample(n=int(len(data)*sample_pct),random_state = tree_number*10)\n",
    "        my_tree(data = data_temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d4735",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c870f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T09:46:40.311053Z",
     "start_time": "2022-06-03T09:46:38.522097Z"
    }
   },
   "outputs": [],
   "source": [
    "import phonenumbers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import jellyfish\n",
    "import requests\n",
    "import logging\n",
    "import difflib\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "\n",
    "from english_words import english_words_set\n",
    "from cleantext.clean import clean\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "LOGGER_FORMAT = '%(asctime)s %(message)s'\n",
    "logging.basicConfig(format=LOGGER_FORMAT, datefmt='[%H:%M:%S]')\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Load supporting files\n",
    "pincode_city_state_mapping = pd.read_excel(\"/Users/shubham_mantri/Downloads/City-State-Population.xlsx\", sheet_name=\"pincode_city_state\")\n",
    "gibberish_city_state_df = pd.read_excel(\"/Users/shubham_mantri/Downloads/City-State-Population.xlsx\", sheet_name=\"Sheet1\")\n",
    "hierarchy = pd.read_excel(\"/Users/shubham_mantri/Downloads/Google Maps Geocoding API response type hierarchy.xlsx\", sheet_name=\"Sheet1\")\n",
    "words_to_add_df = pd.read_excel(\"/Users/shubham_mantri/Downloads/words_to_add.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "\n",
    "rto_status_list = ['RTO']\n",
    "GOOGLE_API_KEY = 'AIzaSyBm8OiGWcbaBuR2oz-8aBmLLeoG0yxarY4'\n",
    "base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "IP_QUALITY_API_KEY = 'lLIPCpwWduNXG3BG6u7aX9zxdjS4n6bM'   \n",
    "words_to_add=set(words_to_add_df['clean_area'])\n",
    "english_words_set_ext = english_words_set.union(words_to_add)\n",
    "\n",
    "\n",
    "def time_bucket(hour):\n",
    "    if pd.isna(hour):\n",
    "        return \"missing\"\n",
    "    if 0<=hour<9:\n",
    "        return '0-9'\n",
    "    else:\n",
    "        return f'{math.floor(hour/3)*3}-{(math.floor(hour/3)+1)*3}'\n",
    "\n",
    "def is_weekend(df, required_date_col_name, feature_col_name):\n",
    "    df[feature_col_name] = np.where((df[required_date_col_name].dt.dayofweek == 5)|(df[required_date_col_name].dt.dayofweek == 6),1,0)\n",
    "    return df\n",
    "\n",
    "def get_time_bucket(df, required_date_col_name, feature_col_name):\n",
    "    hour_col_name = None\n",
    "    if required_date_col_name == 'order_placed_date':\n",
    "        hour_col_name = 'order_hour'\n",
    "    elif required_date_col_name == 'delivery_date':\n",
    "        hour_col_name = 'delivery_hour'\n",
    "\n",
    "    df[hour_col_name] = df[required_date_col_name].dt.hour\n",
    "    df[feature_col_name] = df[hour_col_name].apply(time_bucket)\n",
    "    return df\n",
    "\n",
    "def get_diff_between_dates_in_day(df, from_date_col_name, to_date_col_name, feature_col_name):\n",
    "    df[feature_col_name] = (df[to_date_col_name].dt.date - df[from_date_col_name].dt.date).dt.days\n",
    "    return df\n",
    "\n",
    "def is_status_rto(df, required_col_name, feature_col_name, rto_tag_list):\n",
    "    df[feature_col_name] = np.where(df[required_col_name].str.upper().isin(rto_tag_list), 1, 0)\n",
    "    return df\n",
    "\n",
    "def complete_address(df, required_address_1, required_address_2,feature_col_name):\n",
    "    comp_addrs = lambda address1,address2: ((str(address1) if not pd.isna(address1) else \"\") + (\" \" if not (pd.isna(address2) or pd.isna(address1)) else \"\") + (str(address2) if not pd.isna(address2) else \"\"))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_address_1],x[required_address_2]),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_tokens(s):\n",
    "    s = str(s)\n",
    "    pattern = re.compile(r'\\W+')\n",
    "    tokens = pattern.split(s)\n",
    "    return '_'.join(tokens)\n",
    "\n",
    "def get_num_tokens(t):\n",
    "    t = t.split('_')\n",
    "    return len(t)\n",
    "\n",
    "def get_avg_token_len(t):\n",
    "    tokens = t.split('_')\n",
    "    res = sum(map(len, tokens))/float(len(tokens))\n",
    "    return res\n",
    "\n",
    "def get_num_unique_tokens(t):\n",
    "    tokens = t.split('_')\n",
    "    tokens = list(filter(None, tokens))\n",
    "\n",
    "    is_integer = lambda s: s.isdigit() or (s[0] == '-' and s[1:].isdigit())\n",
    "    no_integers = list(filter(is_integer, tokens))\n",
    "    tokens_no_ints = [x for x in tokens if x not in no_integers]\n",
    "\n",
    "    num_unique_tokens = len(set(tokens_no_ints))\n",
    "    return num_unique_tokens\n",
    "\n",
    "def get_pc_unique_tokens_to_total_tokens(t):\n",
    "    tokens = t.split('_')\n",
    "    tokens = list(filter(None, tokens))\n",
    "\n",
    "    is_integer = lambda s: s.isdigit() or (s[0] == '-' and s[1:].isdigit())\n",
    "    no_integers = list(filter(is_integer, tokens))\n",
    "    tokens_no_ints = [x for x in tokens if x not in no_integers]\n",
    "\n",
    "    num_unique_tokens = len(set(tokens_no_ints))\n",
    "\n",
    "    try:\n",
    "        pc_unique_tokens_to_total_tokens = num_unique_tokens/len(set(tokens))\n",
    "    except ZeroDivisionError:\n",
    "        pc_unique_tokens_to_total_tokens = 0\n",
    "\n",
    "    return pc_unique_tokens_to_total_tokens\n",
    "\n",
    "\n",
    "def create_token_features(df, required_col_name):\n",
    "    tokenize_col_name = required_col_name + '_tokens'\n",
    "    token_num_col = required_col_name + '_num_tokens'\n",
    "    token_avg_len_col_name = required_col_name + '_avg_token_len'\n",
    "    num_unq_tkn_col_name = required_col_name + '_num_unique_tokens'\n",
    "    prcnt_unq_tkn_col_name = required_col_name + '_pc_unique_tokens_to_total_tokens'\n",
    "    df[tokenize_col_name] = df[required_col_name].apply(lambda x: get_tokens(x))\n",
    "    df[token_num_col] = df[tokenize_col_name].apply(get_num_tokens)\n",
    "    df[token_avg_len_col_name] = df[tokenize_col_name].apply(get_avg_token_len)\n",
    "    df[num_unq_tkn_col_name] = df[tokenize_col_name].apply(get_num_unique_tokens)\n",
    "    df[prcnt_unq_tkn_col_name] = df[tokenize_col_name].apply(get_pc_unique_tokens_to_total_tokens)\n",
    "    return df\n",
    "\n",
    "def get_regex_features(s):\n",
    "    s = str(s)\n",
    "    l = len(s)\n",
    "    numbers = sum(c.isdigit() for c in s)\n",
    "    letters = sum(c.isalpha() for c in s)\n",
    "    spaces  = sum(c.isspace() for c in s)\n",
    "    others  = len(s) - numbers - letters - spaces\n",
    "    num_pc = round(numbers/l,3)\n",
    "    ltr_pc = round(letters/l,3)\n",
    "    spc_pc = round(spaces/l,3)\n",
    "    otr_pc = round(others/l,3)\n",
    "    num_unique_chars = len(set(list(s)))\n",
    "    pc_unique_chars_to_len = round(num_unique_chars/l,3)\n",
    "    return numbers, letters, spaces, others, num_pc, ltr_pc, spc_pc, otr_pc, num_unique_chars, pc_unique_chars_to_len\n",
    "\n",
    "def get_length(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df[required_col_name].apply(lambda x: len(x) if not pd.isna(x) else 0)\n",
    "    return df\n",
    "\n",
    "def create_regex_features(df, required_col_name):\n",
    "    num = required_col_name + '_len_number'\n",
    "    ltr = required_col_name + '_len_letter'\n",
    "    spc = required_col_name + '_len_space'\n",
    "    otr = required_col_name + '_len_others'\n",
    "    num_pc = required_col_name + '_len_number_pc'\n",
    "    ltr_pc = required_col_name + '_len_letter_pc'\n",
    "    spc_pc = required_col_name + '_len_space_pc'\n",
    "    otr_pc = required_col_name + '_len_others_pc'\n",
    "    num_unique_chars = required_col_name + '_num_unique_chars'\n",
    "    pc_unique_chars_to_len = required_col_name +'_pc_unique_chars_to_len'\n",
    "    df[[num, ltr, spc, otr,num_pc, ltr_pc, spc_pc, otr_pc, num_unique_chars, pc_unique_chars_to_len ]] = df[[required_col_name]].apply(get_regex_features, axis = 1,  result_type='expand')\n",
    "    return df\n",
    "\n",
    "def get_unique_alphabets_count(df, required_col_name, feature_col_name):\n",
    "    comp_addrs = lambda address: np.where(type(address) == str, len(set(address)), 0)\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_col_name]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('int')\n",
    "    return df\n",
    "\n",
    "def get_unique_alphabets_count_pct(df, required_col_name, feature_col_name):\n",
    "    comp_addrs = lambda address: np.where((type(address) == str) & (len(address)>0) , round(len(set(address))/len(address),3), 0)\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_col_name]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('float')\n",
    "    return df\n",
    "\n",
    "def get_comma_count(df, required_col_name, feature_col_name):\n",
    "    comp_addrs = lambda address: np.where(pd.isna(address), 0, len(re.findall(\"[,]\",str(address))))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_col_name]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('int')\n",
    "    return df\n",
    "\n",
    "def get_vowel_count(df, required_col_name, feature_col_name):\n",
    "    comp_addrs = lambda address: np.where(pd.isna(address),0, len(re.findall(\"[aeiou]\",str(address))))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_col_name]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('int')\n",
    "    return df\n",
    "\n",
    "def get_vowel_pct(df, required_col_name, feature_col_name):\n",
    "    comp_addrs = lambda address: np.where(pd.isna(address),0, (round(len(re.findall(\"[aeiou]\",str(address)))/len(address),3) if len(address)>0 else 0))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_col_name]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('float')\n",
    "    return df\n",
    "\n",
    "def past_rto_count(df, profile_value, required_col_name, label_col_name):\n",
    "    return df.loc[(df[required_col_name]==profile_value)&(df[label_col_name]==1),:].shape[0]\n",
    "\n",
    "def past_rto_pct(df, profile_value, required_col_name, label_col_name):\n",
    "    return round(past_rto_count(df, profile_value, required_col_name, label_col_name)/df.loc[(df[required_col_name]==profile_value),:].shape[0],3) if past_rto_count(df, profile_value, required_col_name, label_col_name)>0 else 0\n",
    "\n",
    "def get_past_rto_count_by_profile_attr(df, required_col_name, feature_col_name, label_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: past_rto_count(df, x[required_col_name],required_col_name,label_col_name),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_past_rto_pct_by_profile_attr(df, required_col_name, feature_col_name, label_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: past_rto_pct(df, x[required_col_name], required_col_name, label_col_name),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_special_character_count(df, required_col_name, feature_col_name):\n",
    "    comp_addrs = lambda address: np.where(pd.isna(address), 0, len(re.findall(\"[@_!#$%^&*()<>?/|}{~]\",str(address))))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_col_name]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('int')\n",
    "    return df\n",
    "\n",
    "def get_special_character_pct(df, required_col_name, feature_col_name):\n",
    "    comp_addrs = lambda address: np.where(pd.isna(address),0, (round(len(re.findall(\"[@_!#$%^&*()<>?/|}{~]\",str(address)))/len(address),3) if len(address)>0 else 0))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_col_name]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('float')\n",
    "    return df\n",
    "\n",
    "'''def pin_check(pin):\n",
    "    if str(pin).isnumeric()==False:\n",
    "        return 0\n",
    "    if len(str(pin))!=6:\n",
    "        return 0\n",
    "    if int(str(pin)[0])==0:\n",
    "        return 0\n",
    "    if int(str(pin)[0:2]) in [10,29,35,54,55,65,66,86,87,88,89]:\n",
    "        return 0\n",
    "    return 1'''\n",
    "\n",
    "def pin_city_state(pincode_map, pincode, city, state):\n",
    "    response = {'pin_check' : 0, 'pin_state_check' : 0, 'pin_city_check' : 0}\n",
    "    if str(pincode).isnumeric()==0:\n",
    "        return([response['pin_check'], response['pin_city_check'], response['pin_state_check']])\n",
    "    pincode = int(pincode)\n",
    "    match_ = pincode_map.loc[(pincode_map['pincode'] == pincode)]\n",
    "    # pin_exists\n",
    "    if match_.shape[0] > 0:\n",
    "        response['pin_check'] = 1\n",
    "    else:\n",
    "        return([response['pin_check'], response['pin_city_check'], response['pin_state_check']])\n",
    "    # pin_state_match\n",
    "    if state and state.strip().lower() == match_['statename'].values[0].strip().lower():\n",
    "        response['pin_state_check'] = 1\n",
    "    # pin_city_match\n",
    "    if city and str(city).strip().lower() == match_['statename'].values[0].strip().lower(): # For cities like delhi\n",
    "        response['pin_city_check'] = 1\n",
    "    if city and str(city).strip().lower() == match_['district'].values[0].strip().lower():\n",
    "        response['pin_city_check'] = 1\n",
    "    if city and str(city).strip().lower() in match_['locality'].unique():\n",
    "        response['pin_city_check'] = 1\n",
    "    #print(match_)\n",
    "    return([response['pin_check'], response['pin_city_check'], response['pin_state_check']])\n",
    "    \n",
    "    \n",
    "def pin_city_state_check(df, pincode_map, req_pin_col, \\\n",
    "                   req_city_col, req_state_col, pin_ft_name, city_ft_name, state_ft_name):\n",
    "    pcs = pd.DataFrame(df.apply(lambda x: pin_city_state(pincode_map, \\\n",
    "                                               x[req_pin_col], x[req_city_col], x[req_state_col]), axis=1).tolist(), \\\n",
    "                       columns=[pin_ft_name, city_ft_name, state_ft_name])\n",
    "    df = df.join(pcs)\n",
    "    return df\n",
    "\n",
    "\n",
    "def email_check(email):\n",
    "    if pd.isna(email):\n",
    "        return 0\n",
    "    x = re.findall(\"[^@]+@[^@]+\\.[^@]+\",email)\n",
    "    if x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def name_check(name):\n",
    "    if not name:\n",
    "        return 0\n",
    "    if name.isalpha() and len(name)>=3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "'''def is_pin_valid(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: pin_check(x[required_col_name]),axis=1)\n",
    "    return df'''\n",
    "\n",
    "def is_email_valid(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: email_check(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def is_name_valid(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: name_check(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_addresses_ratio(df, required_address_1, required_address_2,feature_col_name):\n",
    "    comp_addrs = lambda address1,address2: np.where(pd.isna(address1) or pd.isna(address2),1,round(difflib.SequenceMatcher(None,str(address1),str(address2)).ratio(),3))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_address_1],x[required_address_2]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('float')\n",
    "    return df\n",
    "\n",
    "def get_addresses_partial_ratio(df, required_address_1, required_address_2,feature_col_name):\n",
    "    comp_addrs = lambda address1,address2: np.where(pd.isna(address1) or pd.isna(address2),1,fuzz.partial_ratio(str(address1),str(address2)))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[required_address_1],x[required_address_2]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('float')\n",
    "    return df\n",
    "\n",
    "def aplha_numeric(word):\n",
    "    x = re.findall(\"[a-z]\",word.lower())\n",
    "    y = re.findall(\"[0-9]\",word.lower())\n",
    "    if len(x)>=1 and len(y)>=1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def alpha_numeric_count(line):\n",
    "    if pd.isna(line):\n",
    "        return 0\n",
    "    total = 0\n",
    "    for word in line.split(\" \"):\n",
    "        if aplha_numeric(word)==1:\n",
    "            total+=1\n",
    "    return total\n",
    "\n",
    "def alpha_numeric_pct(line):\n",
    "    if pd.isna(line):\n",
    "        return 0\n",
    "    return round(alpha_numeric_count(line)/len(line.split(\" \")),3) if len(line.split(\" \"))>0 else 0\n",
    "\n",
    "def get_alpha_numeric_count(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: alpha_numeric_count(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_alpha_numeric_pct(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: alpha_numeric_pct(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def remove_ints_from_tokens(tokens):\n",
    "    tokens = list(filter(None, tokens))\n",
    "\n",
    "    is_integer = lambda s: s.isdigit() or (s[0] == '-' and s[1:].isdigit())\n",
    "    no_integers = list(filter(is_integer, tokens))\n",
    "    tokens_no_ints = [x for x in tokens if x not in no_integers]\n",
    "\n",
    "    return tokens_no_ints\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "def get_top_tokens(df):\n",
    "    all_tokens_list = df.to_list()\n",
    "    all_tokens = []\n",
    "    for li in all_tokens_list:\n",
    "        tos = remove_ints_from_tokens(li.split('_'))\n",
    "        for t in tos:\n",
    "            all_tokens.append(t.lower())\n",
    "\n",
    "    freq = collections.Counter(all_tokens)\n",
    "    freq = dict(freq)\n",
    "    sorted_freq = sorted(freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    top_tokens = sorted_freq[0 : math.floor(len(sorted_freq) * 0.1)]\n",
    "    return top_tokens\n",
    "\n",
    "def num_common_tokens(t, l):\n",
    "    l1 = []\n",
    "    for i in range(len(l)):\n",
    "        l1.append(l[i][0])\n",
    "    t = remove_ints_from_tokens(t.split('_'))\n",
    "    c = 0\n",
    "    for i in range(len(t)):\n",
    "        if t[i] in l1: c +=1\n",
    "    num_common_tokens = c\n",
    "    return num_common_tokens\n",
    "\n",
    "def num_unique_common_tokens(t, l):\n",
    "    l1 = []\n",
    "    for i in range(len(l)):\n",
    "        l1.append(l[i][0])\n",
    "    t = remove_ints_from_tokens(t.split('_'))\n",
    "    num_unique_common_tokens = len(intersection(set(t), l1))\n",
    "    return num_unique_common_tokens\n",
    "\n",
    "def most_popular_token_freq(t):\n",
    "    if pd.isna(t):\n",
    "        return 0\n",
    "    t = remove_ints_from_tokens(t.split('_'))\n",
    "    freq = collections.Counter(t)\n",
    "    freq = dict(freq)\n",
    "    sorted_freq = sorted(freq.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    try:\n",
    "        return sorted_freq[0][1]\n",
    "    except IndexError:\n",
    "        return 0\n",
    "\n",
    "def get_num_of_common_tokens(df, top_tokens_list, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df[required_col_name].apply(lambda x: num_common_tokens(x, top_tokens_list))\n",
    "    return df\n",
    "\n",
    "def get_num_of_unique_common_tokens(df, top_tokens_list, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df[required_col_name].apply(lambda x: num_unique_common_tokens(x, top_tokens_list))\n",
    "    return df\n",
    "\n",
    "def get_pc_common_tokens_to_total_tokens(df, top_tokens_list, common_tokens_col_name, total_tokens_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df[common_tokens_col_name] / df[total_tokens_col_name]\n",
    "    return df\n",
    "\n",
    "def get_num_of_non_common_tokens(df, top_tokens_list, common_tokens_col_name, total_tokens_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df[total_tokens_col_name] - df[common_tokens_col_name]\n",
    "    return df\n",
    "\n",
    "def get_most_popular_token_freq(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df[required_col_name].apply(most_popular_token_freq)\n",
    "    return df\n",
    "\n",
    "def format_date_column(df, required_col_name, format_string):\n",
    "    df[required_col_name] = pd.to_datetime(pd.to_datetime(df[required_col_name],errors='coerce').dt.strftime(format_string),errors='coerce')\n",
    "    return df\n",
    "\n",
    "def pin_based_location_check(df, required_pin_col , required_city_col, feature_col_name, pincode_based_mapping,                              pincode_mapping_col_name, location_mapping_col_name):\n",
    "    lambda_func = lambda pin,location: int(np.where(pincode_based_mapping.loc[pincode_based_mapping[pincode_mapping_col_name]==int(pin),                                                                          location_mapping_col_name].values[0].lower()==location.lower(),1,0))                         if pin_check(pin) and len(pincode_based_mapping.loc[pincode_based_mapping[pincode_mapping_col_name]==int(pin)]) > 0 else 0\n",
    "\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_pin_col],x[required_city_col]),axis=1)\n",
    "    df[feature_col_name] = df[feature_col_name].astype('int')\n",
    "    return df\n",
    "\n",
    "def correct_state_spelling(gibberish_city_state_df, state, threshold_spelling = 70,threshold_phonetics = 80):\n",
    "    if type(state)!=str:\n",
    "        return \"gibberish_state\"\n",
    "    check_list = list(set(list(gibberish_city_state_df['State/UT'].str.lower())))\n",
    "    if state in check_list:\n",
    "        return(state)\n",
    "\n",
    "    def match_pct_spelling(word):\n",
    "        return fuzz.ratio(word.lower(),state.lower())\n",
    "\n",
    "    def match_pct_phonetics(word):\n",
    "        return fuzz.ratio(jellyfish.soundex(word.lower()),jellyfish.soundex(state.lower()))\n",
    "\n",
    "    lst_spelling = list(map(match_pct_spelling,np.array(check_list)))\n",
    "    lst_phonetics = list(map(match_pct_phonetics,np.array(check_list)))\n",
    "\n",
    "    if max(lst_phonetics)>=threshold_phonetics:\n",
    "        return check_list[np.argmax(lst_phonetics)]\n",
    "    if max(lst_spelling)>=threshold_spelling:\n",
    "        return check_list[np.argmax(lst_spelling)]\n",
    "    else:\n",
    "        return \"gibberish_state\"\n",
    "\n",
    "\n",
    "def correct_city_spelling(gibberish_city_state_df, city, state, threshold_spelling = 70,threshold_phonetics = 80):\n",
    "    print(city, '-',state)\n",
    "    city = clean(city, no_numbers=True,\\\n",
    "                 no_punct=True,no_digits=True,\\\n",
    "                 no_currency_symbols=True,replace_with_number='',\\\n",
    "                 replace_with_digit='')\n",
    "    cleaned_state = correct_state_spelling(gibberish_city_state_df, state)\n",
    "    if cleaned_state == \"gibberish_state\":\n",
    "        return \"gibberish_state\"\n",
    "    if not city:\n",
    "        return \"gibberish_city\"\n",
    "    #print(gibberish_city_state_df.loc[gibberish_city_state_df['State/UT'].str.lower()==state.lower()])\n",
    "    check_list = list(gibberish_city_state_df.loc[gibberish_city_state_df['State/UT'].str.lower()==cleaned_state.lower(),'City'])\n",
    "    #check_list = list(gibberish_city_state_df.loc[gibberish_city_state_df['State/UT'].str.lower()==state.lower(),'City'])\n",
    "\n",
    "    if city in check_list:\n",
    "        return(city)\n",
    "    #print(check_list)\n",
    "    def match_pct_spelling(word):\n",
    "        return fuzz.partial_ratio(word.lower(),city.lower())\n",
    "    def match_pct_phonetics(word):\n",
    "        return fuzz.ratio(jellyfish.soundex(word.lower()),jellyfish.soundex(city.lower()))\n",
    "    lst_spelling = list(map(match_pct_spelling,np.array(check_list)))\n",
    "    lst_phonetics = list(map(match_pct_phonetics,np.array(check_list)))\n",
    "    if max(lst_phonetics)>=threshold_phonetics:\n",
    "        return check_list[np.argmax(lst_phonetics)]\n",
    "    if max(lst_spelling)>=threshold_spelling:\n",
    "        return check_list[np.argmax(lst_spelling)]\n",
    "    else:\n",
    "        return \"gibberish_city\"\n",
    "\n",
    "def bigrams(word):\n",
    "    a = []\n",
    "    for i in range(len(word)-1):\n",
    "        a.append(word[i:i+2].lower())\n",
    "    return a  \n",
    "\n",
    "def bigrams_not_possible(english_words_set_ext):\n",
    "\n",
    "    set_all = set()\n",
    "    for i in english_words_set_ext:\n",
    "        set_all = set_all.union(set(bigrams(i)))    \n",
    "\n",
    "    all_bigrams_list = []\n",
    "    for i in set_all:\n",
    "        if i.isalpha()==False:\n",
    "            pass\n",
    "        else:\n",
    "            all_bigrams_list.append(i)\n",
    "\n",
    "    all_combs = []\n",
    "    for i in string.ascii_lowercase:\n",
    "        for j in string.ascii_lowercase:\n",
    "            all_combs.append(i+j)\n",
    "\n",
    "    len(all_combs)\n",
    "\n",
    "    bigrams_not_possible_list = [i for i in all_combs if i not in all_bigrams_list]\n",
    "    return bigrams_not_possible_list\n",
    "\n",
    "def trigrams(word):\n",
    "    a = []\n",
    "    for i in range(len(word)-2):\n",
    "        a.append(word[i:i+3].lower())\n",
    "    return a\n",
    "\n",
    "def trigrams_not_possible(english_words_set_ext):\n",
    "\n",
    "    set_all = set()\n",
    "    for i in english_words_set_ext:\n",
    "        set_all = set_all.union(set(trigrams(i)))    \n",
    "\n",
    "    all_bigrams_list = []\n",
    "    for i in set_all:\n",
    "        if i.isalpha()==False:\n",
    "            pass\n",
    "        else:\n",
    "            all_bigrams_list.append(i)\n",
    "\n",
    "    all_combs = []\n",
    "    for i in string.ascii_lowercase:\n",
    "        for j in string.ascii_lowercase:\n",
    "            for k in string.ascii_lowercase:\n",
    "                all_combs.append(i+j+k)\n",
    "\n",
    "    len(all_combs)\n",
    "\n",
    "    bigrams_not_possible_list = [i for i in all_combs if i not in all_bigrams_list]\n",
    "    return bigrams_not_possible_list\n",
    "\n",
    "def gibberish_or_not(word, bigrams_not_possible_list, trigrams_not_possible_list):\n",
    "    word = word.lower()\n",
    "    lst1 = bigrams(word)\n",
    "    lst2 = bigrams_not_possible_list\n",
    "    lst3 = trigrams(word)\n",
    "    lst4 = trigrams_not_possible_list\n",
    "    for i in lst1:\n",
    "        if i in lst2:\n",
    "            return \"gibberish\"\n",
    "    for i in lst3:\n",
    "        if i in lst4:\n",
    "            return \"gibberish\"\n",
    "\n",
    "    return \"not_gibberish\"\n",
    "\n",
    "def gibberish_count(line, bigrams_not_possible_list, trigrams_not_possible_list):\n",
    "    count=0\n",
    "    if pd.isna(line):\n",
    "        return 0\n",
    "    for word in line.replace(\".\",\" \").replace(\",\",\" \").split(\" \"):\n",
    "        if (gibberish_or_not(word, bigrams_not_possible_list, trigrams_not_possible_list)==\"gibberish\") and word.isalpha():\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "def gibberish_pct(line, bigrams_not_possible_list, trigrams_not_possible_list):\n",
    "    total = 0\n",
    "    if pd.isna(line):\n",
    "        return 0\n",
    "    for word in line.replace(\".\",\" \").replace(\",\",\" \").split(\" \"):\n",
    "        if word.isalpha():\n",
    "            total+=1    \n",
    "    return round(gibberish_count(line, bigrams_not_possible_list, trigrams_not_possible_list)/total,2) if total>0 else 0\n",
    "\n",
    "def is_city_state_gibberish_or_not(df, gibberish_city_state_df, required_city_col_name, required_state_col_name, feature_col_name):\n",
    "    df['tmp'] = df.apply(lambda x: correct_city_spelling(gibberish_city_state_df, x[required_city_col_name], x[required_state_col_name]),axis=1)\n",
    "    df[feature_col_name] = np.where(df['tmp'].isin(['gibberish_city', 'gibberish_state']), 1, 0)\n",
    "    del(df['tmp'])\n",
    "    return df\n",
    "\n",
    "def is_city_numeric(df, required_col_name, feature_col_name):\n",
    "    def is_complete_numeric(text):\n",
    "        if len(clean(text.replace('^',''),no_numbers=True,no_punct=True,no_digits=True,no_currency_symbols=True,replace_with_number=\"\"))==0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df[feature_col_name] = df[required_col_name].apply(is_complete_numeric)\n",
    "    return df\n",
    "\n",
    "def get_gibberish_address_count(df, required_col_name, feature_col_name, bigrams_not_possible_list, trigrams_not_possible_list):\n",
    "    df[feature_col_name] = df.apply(lambda x: gibberish_count(x[required_col_name], bigrams_not_possible_list, trigrams_not_possible_list),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_gibberish_address_pct(df, required_col_name, feature_col_name, bigrams_not_possible_list, trigrams_not_possible_list):\n",
    "    df[feature_col_name] = df.apply(lambda x: gibberish_pct(x[required_col_name], bigrams_not_possible_list, trigrams_not_possible_list),axis=1)\n",
    "    return df\n",
    "\n",
    "def googlemaps_mapping(typ, hierarchy=hierarchy):\n",
    "    #hierarchy = pd.read_excel(\"Google Maps Geocoding API response type hierarchy.xlsx\", sheet_name=\"Sheet1\")\n",
    "    typ_rank = hierarchy.loc[hierarchy['Entity Type'] == typ, 'Rank']\n",
    "    if typ_rank.shape[0] > 0:\n",
    "        return typ_rank.values[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def extract_lat_long_via_address(address_or_zipcode, api_key, base_url):\n",
    "    endpoint = f\"{base_url}?address={address_or_zipcode}&key={api_key}\"\n",
    "\n",
    "    try:\n",
    "        r = requests.get(endpoint,timeout=10.0)\n",
    "        if r.status_code not in range(200, 299):\n",
    "            return \"wrong address\"\n",
    "        return r.json()\n",
    "\n",
    "    except:\n",
    "        return \"timeout error\"\n",
    "\n",
    "    \n",
    "def async_fetch_addr_gmap_api_results(df, required_col_name, feature_name_col, api_key, base_url, limit=40, rate=1):\n",
    "    limit = asyncio.Semaphore(limit)\n",
    "    \n",
    "    async def extract_lat_long_via_address(address, api_key, base_url, limit, rate):\n",
    "        async with limit:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                endpoint = f'{base_url}?address={address}&key={api_key}'            \n",
    "                try:\n",
    "                    resp = await session.get(endpoint, timeout=5)\n",
    "                except:\n",
    "                    return 'timeout error'\n",
    "                content = await resp.json()\n",
    "                status = resp.status\n",
    "                log.info(f'Made request {endpoint}. Status {status}')\n",
    "                if status not in range(200, 299):\n",
    "                    return 'wrong address'\n",
    "                await asyncio.sleep(rate)\n",
    "                return content\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    results = loop.run_until_complete(asyncio.gather(*[extract_lat_long_via_address(address, api_key, base_url, limit, rate) for address in df[required_col_name]]))\n",
    "    df[feature_name_col] = results\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def fetch_addr_gmap_api_results(df, required_col_name, feature_name_col, api_key, base_url):\n",
    "    df[feature_name_col] = df.apply(lambda x: extract_lat_long_via_address(x[required_col_name], api_key, base_url),axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def lowest_type_googlemaps(api_result, address): #feature\n",
    "    if api_result==\"timeout error\" or api_result==\"wrong address\":\n",
    "        return 1\n",
    "    if len(api_result['results']) == 1:\n",
    "        return max(\n",
    "            list(\n",
    "                map(googlemaps_mapping,\n",
    "                    api_result['results'][0]['types'])))\n",
    "\n",
    "    elif len(api_result['results']) > 1:\n",
    "        match = lambda i: fuzz.partial_ratio(api_result['results'][i]['formatted_address'],address)\n",
    "        partial_ratio_list = list(map(match,range(len(api_result['results']))))\n",
    "        highest_match_index = partial_ratio_list.index(max(partial_ratio_list))\n",
    "        gmap_mapping = list(map(googlemaps_mapping,\n",
    "                    api_result['results'][highest_match_index]['types']))\n",
    "        if len(gmap_mapping) > 0:\n",
    "            return max(gmap_mapping)\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_lowest_type_gmaps_rank(df, required_addr_col, required_gmap_col, feature_name_col):\n",
    "    df[feature_name_col] = df.apply(lambda x: lowest_type_googlemaps(x[required_gmap_col], x[required_addr_col]),axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def gmap_addr_results_count(df, required_col_name, feature_col_name):\n",
    "    res_cnt = lambda res: len(res['results']) if not res in ['wrong address', 'timeout error'] else 0\n",
    "    #print(required_col_name, feature_col_name, df)\n",
    "    #print(df[required_col_name])\n",
    "    df[feature_col_name] = df.apply(lambda x: res_cnt(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def match_address_original_vs_formatted(address,api_result):\n",
    "    if api_result==\"timeout error\" or api_result==\"wrong address\":\n",
    "        return 0\n",
    "    if len(api_result['results']) == 1:\n",
    "        return fuzz.ratio(api_result['results'][0]['formatted_address'],address)\n",
    "    elif len(api_result['results']) > 1:\n",
    "        match = lambda i: fuzz.partial_ratio(api_result['results'][i]['formatted_address'],address)\n",
    "        partial_ratio_list = list(map(match,range(len(api_result['results']))))\n",
    "        highest_match_index = partial_ratio_list.index(max(partial_ratio_list))\n",
    "        return fuzz.ratio(api_result['results'][highest_match_index]['formatted_address'],address)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_gmap_org_vs_formatted_addr_match_pct(df, required_addr_col, required_gmap_col, feature_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: match_address_original_vs_formatted(x[required_addr_col], x[required_gmap_col]),axis=1)\n",
    "    return df\n",
    "\n",
    "def location_type(api_result, address):\n",
    "    if api_result==\"timeout error\" or api_result==\"wrong address\":\n",
    "        return 'Error'\n",
    "    if len(api_result['results']) == 1:\n",
    "        return api_result['results'][0]['geometry']['location_type']\n",
    "    elif len(api_result['results']) > 1:\n",
    "        match = lambda i: fuzz.partial_ratio(api_result['results'][i]['formatted_address'],address)\n",
    "        partial_ratio_list = list(map(match,range(len(api_result['results']))))\n",
    "        highest_match_index = partial_ratio_list.index(max(partial_ratio_list))\n",
    "        return api_result['results'][highest_match_index]['geometry']['location_type']\n",
    "    else:\n",
    "        return 'No Results'\n",
    "\n",
    "def get_gmap_location_type(df, required_addr_col, required_gmap_col, feature_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: location_type(x[required_gmap_col], x[required_addr_col]),axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def async_ip_address_api_result(df, required_col_name, feature_name_col, api_key, limit=20, rate=1):\n",
    "    limit = asyncio.Semaphore(limit)\n",
    "    async def get_ip_details(ip, api_key, limit, rate):    \n",
    "        async with limit:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                endpoint = f'https://ipqualityscore.com/api/json/ip/{api_key}/{ip}'    \n",
    "                try:\n",
    "                    resp = await session.get(endpoint, timeout=5)\n",
    "                except:\n",
    "                    return 'timeout error'\n",
    "                content = await resp.json()\n",
    "                status = resp.status\n",
    "                log.info(f'Made request {endpoint}. Status {status}')\n",
    "                await asyncio.sleep(rate)\n",
    "                return content\n",
    "    loop = asyncio.get_event_loop()\n",
    "    results = loop.run_until_complete(asyncio.gather(*[get_ip_details(ip, api_key, limit, rate) for ip in df[required_col_name]]))\n",
    "    df[feature_name_col] = results\n",
    "    return df\n",
    "\n",
    "def ip_address_api_result(df, ip_address_col_name, feature_col_name, key):\n",
    "    lambda_func = lambda ip_address, key: requests.get(f'https://ipqualityscore.com/api/json/ip/{key}/{ip_address}').json()\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[ip_address_col_name], key),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_state_match(df, ip_api_result_col_name, state_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result, state: np.where(api_result['region'].lower()==state.lower(), 1, 0)  if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[ip_api_result_col_name], x[state_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_crawler_or_not(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: api_result['is_crawler']*1 if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_vpn_or_not(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: np.where(api_result['vpn']==True or api_result['active_vpn']==True, 1, 0)  if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_tor_or_not(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: np.where(api_result['tor']==True or api_result['active_tor']==True, 1, 0)  if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_fraud_score(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: api_result['fraud_score']  if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_recent_abuse_or_not(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: api_result['recent_abuse']*1  if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_bot_or_not(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: api_result['bot_status']*1 if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_abuse_velocity(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: api_result['abuse_velocity'] if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def lat_long_distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a))\n",
    "\n",
    "def ip_address_lat_long_distance(df, ip_api_result_col_name, lat_col_name, long_col_name):\n",
    "    df[feature_col_name] = df.apply(lambda x: lat_long_distance(x[lat_col_name], x[long_col_name],                                                                 x[ip_api_result_col_name]['latitude'],                                                                 x[ip_api_result_col_name]['longitude']) if api_result['success'] == True else None, axis=1)\n",
    "    return df\n",
    "\n",
    "def ip_address_mobile_or_not(df, required_col_name, feature_col_name):\n",
    "    lambda_func = lambda api_result: api_result['mobile']*1 if api_result['success'] == True else 0\n",
    "    df[feature_col_name] = df.apply(lambda x: lambda_func(x[required_col_name]),axis=1)\n",
    "    return df\n",
    "\n",
    "def extended_address(df, address, city, state, pincode, feature_col_name, country ='India'):\n",
    "    comp_addrs = lambda address,city,state,pincode,country: ' '.join(filter(None, [address,city,state,pincode,country]))\n",
    "    df[feature_col_name] = df.apply(lambda x: comp_addrs(x[address], x[city], x[state], x[pincode], country),axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def is_valid_phone_number(number):\n",
    "    if pd.isna(number):\n",
    "        return 0\n",
    "    try :\n",
    "        number = str(number)\n",
    "        #print(number)\n",
    "        number = clean(number[:3],no_punct=True)+number[3:]\n",
    "        if len(number)<10:\n",
    "            return 0\n",
    "        number = number.replace('////','$').replace('///','$').replace('//','$').replace('/','$').replace(',,,,','$').replace(',,,','$').replace(',,','$').replace(',','$')    \n",
    "        a = 0\n",
    "        for i in number.split('$'):\n",
    "            a = a or (phonenumbers.is_valid_number(phonenumbers.parse(clean(i,no_punct=True),'IN'))*1)\n",
    "        return a\n",
    "    except : \n",
    "        return 0\n",
    "\n",
    "def is_valid_phone(df, required_col_name, feature_col_name):\n",
    "    df[feature_col_name] = df[required_col_name].apply(is_valid_phone_number)\n",
    "    return df\n",
    "\n",
    "\n",
    "rto_status_list = ['RTO','DTO','RTO In Transit','RTO Delivered','RTO ACKNOWLEDGED','UNDELIVERED-2ND ATTEMPT','RTO_OFD','RTO DELIVERED','RTO INITIATED','RTO IN TRANSIT','UNDELIVERED','UNDELIVERED-3RD ATTEMPT','RTO Initiated']\n",
    "GOOGLE_API_KEY = 'AIzaSyBm8OiGWcbaBuR2oz-8aBmLLeoG0yxarY4'\n",
    "base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "IP_QUALITY_API_KEY = 'lLIPCpwWduNXG3BG6u7aX9zxdjS4n6bM'\n",
    "#print(\"Before processing: df.columns = {}\".format(df.columns))\n",
    "\n",
    "words_to_add=set(words_to_add_df['clean_area'])\n",
    "english_words_set_ext = english_words_set.union(words_to_add)\n",
    "\n",
    "\n",
    "bigrams_not_possible_list = bigrams_not_possible(english_words_set_ext)\n",
    "trigrams_not_possible_list = trigrams_not_possible(english_words_set_ext)\n",
    "\n",
    "df = is_status_rto(df, 'current_status', 'rto_or_not', rto_status_list)\n",
    "df = format_date_column(df, 'order_placed_date', '%m/%d/%Y %H:%M:%S')\n",
    "df = complete_address(df, 'address_line_1', 'address_line_2','complete_address')\n",
    "df = get_length(df, 'complete_address', 'complete_address_len')\n",
    "df = create_regex_features(df, 'complete_address')\n",
    "df = create_token_features(df, 'complete_address')\n",
    "df = is_weekend(df, 'order_placed_date', 'order_weekend_or_not')\n",
    "\n",
    "#df = is_weekend(df, 'expected_delivery_date', 'expected_delivery_weekend_or_not')\n",
    "#df = is_weekend(df, 'delivery_date', 'delivery_weekend_or_not')\n",
    "df = get_time_bucket(df, 'order_placed_date', 'order_time_bucket')\n",
    "#df = get_time_bucket(df, 'expected_delivery_date', 'expected_delivery_time_bucket')\n",
    "#df = get_time_bucket(df, 'delivery_date', 'delivery_time_bucket')\n",
    "#df = get_diff_between_dates_in_day(df, 'order_placed_date', 'expected_delivery_date', 'delivery-order')\n",
    "#df = get_diff_between_dates_in_day(df, 'expected_delivery_date', 'delivery_date', 'delivery-expected_delivery')\n",
    "df = get_unique_alphabets_count(df, 'complete_address', 'unique_alphabets_count')\n",
    "df = get_unique_alphabets_count_pct(df, 'complete_address', 'unique_alphabets_count_pct')\n",
    "df = get_comma_count(df, 'complete_address', 'comma_count')\n",
    "df = get_vowel_count(df, 'complete_address', 'vowel_count')\n",
    "df = get_vowel_pct(df, 'complete_address', 'vowel_pct')\n",
    "\n",
    "df = get_past_rto_count_by_profile_attr(df, 'consignee_mob_no', 'past_rto_count_mob_number','rto_or_not')\n",
    "df = get_past_rto_pct_by_profile_attr(df, 'consignee_mob_no', 'past_rto_pct_mob_number', 'rto_or_not')\n",
    "df = get_past_rto_count_by_profile_attr(df, 'consignee_email', 'past_rto_count_email','rto_or_not')\n",
    "df = get_past_rto_pct_by_profile_attr(df, 'consignee_email', 'past_rto_pct_email', 'rto_or_not')\n",
    "df = get_past_rto_count_by_profile_attr(df, 'consignee_pincode', 'past_rto_count_pincode','rto_or_not')\n",
    "df = get_past_rto_pct_by_profile_attr(df, 'consignee_pincode', 'past_rto_pct_pincode', 'rto_or_not')\n",
    "\n",
    "df = get_special_character_count(df, 'complete_address', 'special_character_count')\n",
    "df = get_special_character_pct(df, 'complete_address', 'special_character_pct')\n",
    "#df = is_pin_valid(df, 'consignee_pincode', 'pin_check')\n",
    "df = is_email_valid(df, 'consignee_email', 'email_check')\n",
    "df = is_name_valid(df, 'consignee_name', 'name_check')\n",
    "df = get_addresses_ratio(df, 'address_line_1', 'address_line_2','address1_address2_ratio')\n",
    "df = get_addresses_partial_ratio(df, 'address_line_1', 'address_line_2','address1_address2_partial_ratio')\n",
    "df = get_alpha_numeric_count(df, 'complete_address', 'alpha_numeric_count')\n",
    "df = get_alpha_numeric_pct(df, 'complete_address', 'alpha_numeric_pct')\n",
    "df_del = df.loc[df['current_status'] == 'DELIVERED']\n",
    "df_rto = df.loc[df['current_status'].isin(['RTO'])]\n",
    "top_tokens_all = get_top_tokens(df['complete_address_tokens'])\n",
    "top_tokens_del = get_top_tokens(df_del['complete_address_tokens'])\n",
    "top_tokens_rto = get_top_tokens(df_rto['complete_address_tokens'])\n",
    "df = get_num_of_common_tokens(df, top_tokens_all, 'complete_address_tokens', 'complete_address_num_common_tokens_all')\n",
    "df = get_num_of_unique_common_tokens(df, top_tokens_all, 'complete_address_tokens', 'complete_address_num_unique_common_tokens_all')\n",
    "df = get_pc_common_tokens_to_total_tokens(df, top_tokens_all, 'complete_address_num_common_tokens_all', 'complete_address_num_tokens', 'complete_address_pc_common_tokens_to_total_tokens_all')\n",
    "df = get_num_of_non_common_tokens(df, top_tokens_all, 'complete_address_num_common_tokens_all', 'complete_address_num_tokens', 'complete_address_num_non_common_tokens_all')\n",
    "df = get_num_of_common_tokens(df, top_tokens_del, 'complete_address_tokens', 'complete_address_num_common_tokens_del')\n",
    "df = get_num_of_unique_common_tokens(df, top_tokens_del, 'complete_address_tokens', 'complete_address_num_unique_common_tokens_del')\n",
    "df = get_pc_common_tokens_to_total_tokens(df, top_tokens_del, 'complete_address_num_common_tokens_del', 'complete_address_num_tokens', 'complete_address_pc_common_tokens_to_total_tokens_del')\n",
    "df = get_num_of_non_common_tokens(df, top_tokens_del, 'complete_address_num_common_tokens_del', 'complete_address_num_tokens', 'complete_address_num_non_common_tokens_del')\n",
    "df = get_num_of_common_tokens(df, top_tokens_rto, 'complete_address_tokens', 'complete_address_num_common_tokens_rto')\n",
    "df = get_num_of_unique_common_tokens(df, top_tokens_rto, 'complete_address_tokens', 'complete_address_num_unique_common_tokens_rto')\n",
    "df = get_pc_common_tokens_to_total_tokens(df, top_tokens_rto, 'complete_address_num_common_tokens_rto', 'complete_address_num_tokens', 'complete_address_pc_common_tokens_to_total_tokens_rto')\n",
    "df = get_num_of_non_common_tokens(df, top_tokens_rto, 'complete_address_num_common_tokens_rto', 'complete_address_num_tokens', 'complete_address_num_non_common_tokens_rto')\n",
    "df = get_most_popular_token_freq(df, 'complete_address', 'complete_address_most_popular_token_freq')\n",
    "df = pin_city_state_check(df, pincode_city_state_mapping, 'consignee_pincode', 'consignee_city', 'consignee_state', 'pin_check', 'pin_city_check', 'pin_state_check')\n",
    "df = is_valid_phone(df, 'consignee_mob_no', 'is_valid_phone')\n",
    "\n",
    "df = get_gibberish_address_count(df, 'complete_address', 'gibberish_count', bigrams_not_possible_list, trigrams_not_possible_list)\n",
    "df = get_gibberish_address_pct(df, 'complete_address', 'gibberish_pct', bigrams_not_possible_list, trigrams_not_possible_list)\n",
    "\n",
    "\n",
    "df = is_city_state_gibberish_or_not(df, gibberish_city_state_df, 'consignee_city', 'consignee_state', 'gibberish_city_or_not')\n",
    "\n",
    "df = is_city_numeric(df, 'consignee_city', 'is_city_complete_numeric')\n",
    "\n",
    "df = extended_address(df, 'complete_address', 'consignee_city', 'consignee_state', 'consignee_pincode', 'extended_address','India')\n",
    "df = async_fetch_addr_gmap_api_results(df, 'extended_address', 'gmap_api_result', GOOGLE_API_KEY, base_url)\n",
    "\n",
    "df = get_lowest_type_gmaps_rank(df, 'extended_address', 'gmap_api_result', 'lowest_type_googlemaps')\n",
    "df = gmap_addr_results_count(df, 'gmap_api_result', 'gmap_addr_results_count')\n",
    "df = get_gmap_org_vs_formatted_addr_match_pct(df, 'extended_address', 'gmap_api_result', 'original_addr_vs_formatted_gmap_match_pct')\n",
    "df = get_gmap_location_type(df, 'extended_address', 'gmap_api_result', 'gmap_location_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85b020",
   "metadata": {},
   "source": [
    "# Rules verison 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee056e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fig_rules(df):\n",
    "rule1 = np.array(df['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df['complete_address_len'] <= 10.500)\n",
    "rule2 = np.array(df['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df['complete_address_len'] > 10.500) & \\\n",
    "        np.array(df['complete_address_len_number_pc'] <= 0.071) & \\\n",
    "        np.array(df['vowel_count'] <= 15.000)\n",
    "rule3 = np.array(df['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df['complete_address_len'] > 10.500) & \\\n",
    "        np.array(df['complete_address_len_number_pc'] > 0.071) & \\\n",
    "        np.array(df['address1_address2_partial_ratio'] <= 0.500) & \\\n",
    "        np.array(df['complete_address_pc_unique_tokens_to_total_tokens'] > 0.944)\n",
    "rule4 = np.array(df['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df['complete_address_len'] > 10.500) & \\\n",
    "        np.array(df['complete_address_len_number_pc'] > 0.071) & \\\n",
    "        np.array(df['address1_address2_partial_ratio'] <= 0.500) & \\\n",
    "        np.array(df['complete_address_pc_unique_tokens_to_total_tokens'] <= 0.944) & \\\n",
    "        np.array(df['complete_address_num_non_common_tokens_all'] > 4.500)\n",
    "rule5 = np.array(df['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df['complete_address_len'] <= 11.500) & \\\n",
    "        np.array(df['complete_address_len_space_pc'] > 0.177) & \\\n",
    "        np.array(df['address1_address2_ratio'] <= 0.700)\n",
    "rule6 = np.array(df['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df['complete_address_len'] > 11.500) & \\\n",
    "        np.array(df['order_hour'] <= 0.500) & \\\n",
    "        np.array(df['vowel_pct'] <= 0.108)\n",
    "rule7 = np.array(df['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df['complete_address_len'] > 11.500) & \\\n",
    "        np.array(df['order_hour'] <= 0.500) & \\\n",
    "        np.array(df['vowel_pct'] > 0.108) & \\\n",
    "        np.array(df['is_valid_phone'] <= 0.500)\n",
    "rule8 = np.array(df['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df['complete_address_len'] > 11.500) & \\\n",
    "        np.array(df['order_hour'] > 0.500) & \\\n",
    "        np.array(df['complete_address_num_tokens'] <= 2.500) & \\\n",
    "        np.array(df['complete_address_len_others_pc'] > 0.067)\n",
    "#     return(rule1 | rule2 | rule3 | rule4 | rule5 | rule6 | rule7 | rule8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab7049f",
   "metadata": {},
   "source": [
    "# Feature Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_analysis(feature,demand='lower',label = 'rto_or_not',df = df,method='percentile',total_count_threshold=3,rto_pct_threshold=0):\n",
    "    \n",
    "    print(feature)\n",
    "    def not_null_columns(df):\n",
    "        a=[]\n",
    "        for i in df.columns:\n",
    "            if df[i].isnull().sum()==0:\n",
    "                a.append(i)\n",
    "        return a\n",
    "\n",
    "\n",
    "\n",
    "    def link(feature=feature,label=label, df = df,total_count_threshold=total_count_threshold,rto_pct_threshold=rto_pct_threshold):\n",
    "        pivot=df.pivot_table(values=[i for i in not_null_columns(df) if i not in [feature,label]][0],index=feature,columns=label,aggfunc='count')\n",
    "        pivot['sum']=pivot.sum(axis=1)\n",
    "        pivot.fillna(0,inplace=True)\n",
    "        pivot['rto_pct']=(pivot[1])/(pivot['sum'])\n",
    "        return pivot.loc[(pivot['sum']>=total_count_threshold)&(pivot['rto_pct']>=rto_pct_threshold),:]\n",
    "    \n",
    "    if demand=='equal':\n",
    "        return print(link(feature))\n",
    "    \n",
    "    \n",
    "    if method == 'percentile':\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['percentile','value_less/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                total = len(df.loc[df[feature]<=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_less/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['percentile','value_more/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(0,100,5)]:\n",
    "                total = len(df.loc[df[feature]>=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_more/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    else:\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['value_less/equal_than','total','rto_pct'])\n",
    "            for i in range(1,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]<=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_less/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['value_more/equal_than','total','rto_pct'])\n",
    "            for i in range(0,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]>=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_more/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    table['feature'] = feature\n",
    "    \n",
    "\n",
    "    \n",
    "    if demand == 'lower':\n",
    "        return print(table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_less/equal_than','total','rto_pct']].drop_duplicates())\n",
    "    else:\n",
    "        return print(table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_more/equal_than','total','rto_pct']].drop_duplicates())        \n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b09dd",
   "metadata": {},
   "source": [
    "# clean pincode function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b0cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T14:49:08.782035Z",
     "start_time": "2022-06-05T14:49:08.770853Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_pincode(lat):\n",
    "    if pd.isna(lat):\n",
    "        return 0\n",
    "    print(lat)\n",
    "    lat = str(lat)\n",
    "    lat = lat.replace(\"-\",\"\")\n",
    "    import re\n",
    "    if (len(lat) in [0,1]) or pd.isna(lat):\n",
    "        return 0\n",
    "#     if lat.replace(\".\",\"\").isdigit()==False:\n",
    "#         print(lat)\n",
    "#     print(lat)\n",
    "    if len(lat)<=5:\n",
    "        return lat\n",
    "    if lat[2]==\".\" and lat[5]==\".\":\n",
    "        lat = lat[:5]+lat[6:]\n",
    "    if lat[2]==\".\" and lat[4]==\".\":\n",
    "        lat = lat[:4]+lat[5:]\n",
    "    if len(re.findall('[a-z]',lat))>0:\n",
    "        return 0\n",
    "    \n",
    "    return float(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832bd17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T14:19:49.776453Z",
     "start_time": "2022-06-05T14:19:49.753567Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77f09905",
   "metadata": {},
   "source": [
    "# Exception handling in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92d515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T14:59:04.147363Z",
     "start_time": "2022-06-05T14:59:04.123111Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  print(1/0)\n",
    "except:\n",
    "  print(\"wojo\")\n",
    "else:\n",
    "    print(\"this is else\")\n",
    "finally:\n",
    "  print(\"this is finally\")\n",
    "\n",
    "raise Exception(\"this is raise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d8d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e595f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:13:07.284678Z",
     "start_time": "2022-06-06T08:13:07.205997Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = add_missing_columns(pd.get_dummies(train[feature_columns]))\n",
    "y_test = train['rto_or_not']\n",
    "\n",
    "\n",
    "df_generic = pd.concat([X_test,y_test],axis=1)\n",
    "\n",
    "\n",
    "# def fig_rules(df_generic):\n",
    "rule1 = np.array(df_generic['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] <= 10.500)\n",
    "rule2 = np.array(df_generic['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] > 10.500) & \\\n",
    "        np.array(df_generic['complete_address_len_number_pc'] <= 0.071) & \\\n",
    "        np.array(df_generic['vowel_count'] <= 15.000)\n",
    "rule3 = np.array(df_generic['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] > 10.500) & \\\n",
    "        np.array(df_generic['complete_address_len_number_pc'] > 0.071) & \\\n",
    "        np.array(df_generic['address1_address2_partial_ratio'] <= 0.500) & \\\n",
    "        np.array(df_generic['complete_address_pc_unique_tokens_to_total_tokens'] > 0.944)\n",
    "rule4 = np.array(df_generic['complete_address_len_space'] <= 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] > 10.500) & \\\n",
    "        np.array(df_generic['complete_address_len_number_pc'] > 0.071) & \\\n",
    "        np.array(df_generic['address1_address2_partial_ratio'] <= 0.500) & \\\n",
    "        np.array(df_generic['complete_address_pc_unique_tokens_to_total_tokens'] <= 0.944) & \\\n",
    "        np.array(df_generic['complete_address_num_non_common_tokens_all'] > 4.500)\n",
    "rule5 = np.array(df_generic['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] <= 11.500) & \\\n",
    "        np.array(df_generic['complete_address_len_space_pc'] > 0.177) & \\\n",
    "        np.array(df_generic['address1_address2_ratio'] <= 0.700)\n",
    "rule6 = np.array(df_generic['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] > 11.500) & \\\n",
    "        np.array(df_generic['order_hour'] <= 0.500) & \\\n",
    "        np.array(df_generic['vowel_pct'] <= 0.108)\n",
    "rule7 = np.array(df_generic['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] > 11.500) & \\\n",
    "        np.array(df_generic['order_hour'] <= 0.500) & \\\n",
    "        np.array(df_generic['vowel_pct'] > 0.108) & \\\n",
    "        np.array(df_generic['is_valid_phone'] <= 0.500)\n",
    "rule8 = np.array(df_generic['complete_address_len_space'] > 9.500) & \\\n",
    "        np.array(df_generic['complete_address_len'] > 11.500) & \\\n",
    "        np.array(df_generic['order_hour'] > 0.500) & \\\n",
    "        np.array(df_generic['complete_address_num_tokens'] <= 2.500) & \\\n",
    "        np.array(df_generic['complete_address_len_others_pc'] > 0.067)\n",
    "#     return(rule1 | rule2 | rule3 | rule4 | rule5 | rule6 | rule7 | rule8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,9,1):\n",
    "    df_generic[f'rule{i}']=np.where(eval(f'rule{i}'),1,0)\n",
    "# df_generic['predicted_rto_or_not']=np.where(eval((' | ').join([f'rule{i}' for i in range(1,10,1)])),1,0)\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error,r2_score,mean_squared_log_error,accuracy_score,confusion_matrix,precision_score,recall_score\n",
    "\n",
    "# print(confusion_matrix(df_generic['rto_or_not'],df_generic['predicted_rto_or_not']))\n",
    "\n",
    "# print('precision_score' + \"-\" + str(precision_score(df_generic['rto_or_not'],df_generic['predicted_rto_or_not'])))\n",
    "\n",
    "# print('recall_score' + '-' + str(recall_score(df_generic['rto_or_not'],df_generic['predicted_rto_or_not'])))\n",
    "\n",
    "# red_flagging_rate = df_generic['predicted_rto_or_not'].value_counts()[1]/df_generic['predicted_rto_or_not'].value_counts().sum()\n",
    "\n",
    "# print('red flagging rate - ' + str(red_flagging_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76a934",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:31:35.285951Z",
     "start_time": "2022-06-06T08:31:34.676693Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('/Users/shubham_mantri/Downloads/generic_data_rule_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90666b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:32:31.203933Z",
     "start_time": "2022-06-06T09:32:31.162882Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.concat([train,df_generic],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e310f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T09:32:32.864681Z",
     "start_time": "2022-06-06T09:32:32.833468Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce027487",
   "metadata": {},
   "source": [
    "# clean adddress function by ayushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923d017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:38:06.213586Z",
     "start_time": "2022-06-06T08:38:06.194244Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_address(address):\n",
    "    #Rule1: remove urls\n",
    "    address = re.sub(r'(https?://\\S+)', \"\", address)\n",
    "    #Rule2: replace \"escape chars\" by \"space\"\n",
    "    address = re.sub(\"[\\n\\t\\r]\", \" \", address)\n",
    "    #Rule3: replace 'apostrophe s' by 's'\n",
    "    address = re.sub(\"[\\'\\\"\\`]s\", \"s\", address)\n",
    "    #Rule4: remove single/double quotes having space on either side\n",
    "    address = re.sub(\"[\\'\\\"] \", \" \", address)\n",
    "    address = re.sub(\" [\\'\\\"]\", \" \", address)\n",
    "    #Rule5: replace \"single/double quotes surrounded by multiple alphabets on both sides\" by \"space\"\n",
    "    address = re.sub(\"[a-zA-Z]{2,}[\\'\\\"][a-zA-Z]{2,}\", \" \", address)\n",
    "    #Rule6: replace 'equal to', 'colon', 'tilde' by  'hyphen'\n",
    "    address = re.sub(\"[\\=\\:\\~]\", \"-\", address)\n",
    "    #Rule7: replace 'square and curly brackets' by  'round brackets'\n",
    "    address = re.sub(\"[\\[\\{]\", \"(\", address)\n",
    "    address = re.sub(\"[\\]\\}]\", \")\", address)\n",
    "    #Rule8: replace 'pipe and backslash' by  'forward slash'\n",
    "    address = re.sub(\"[\\|\\\\\\]\", \"/\", address)\n",
    "    #Rule9: replace 'semicolon and question mark' by  'comma'\n",
    "    address = re.sub(\"[;\\?]\", \",\", address)\n",
    "    #Rule10: replace '` ! $ @ * % < > _ ^' by  'space'\n",
    "    address = re.sub(\"[`\\!\\$@\\*%\\<\\>_\\^]\", \" \", address)\n",
    "    #Rule10: replace repeated special chars by single char\n",
    "    address = re.sub(\",+\", \",\", address)\n",
    "    address = re.sub(\"\\.+\", \".\", address)\n",
    "    address = re.sub(\"\\++\", \"+\", address)\n",
    "    address = re.sub(\"\\-+\", \"-\", address)\n",
    "    address = re.sub(\"\\(+\", \"(\", address)\n",
    "    address = re.sub(\"\\)+\", \")\", address)\n",
    "    address = re.sub(\"\\&+\", \"&\", address)\n",
    "    address = re.sub(\"\\#+\", \"#\", address)\n",
    "    address = re.sub(\"\\/+\", \"/\", address)\n",
    "    address = re.sub(\"\\\"+\", '\"', address)\n",
    "    address = re.sub(\"\\'+\", \"'\", address)\n",
    "    address = re.sub(\" +\", \" \", address)\n",
    "    #Rule11: remove special chars from start and end of string\n",
    "    address = address.strip()\n",
    "    address = re.sub(\"^[\\.\\,\\-\\+\\/\\)]\", \"\", address)\n",
    "    address = re.sub(\"[\\.\\,\\-\\+\\/\\(]$\", \"\", address)\n",
    "    address = address.strip()            \n",
    "    return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319996d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:36:17.513984Z",
     "start_time": "2022-06-06T08:36:17.478470Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_address(\"anj    jfnajel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f69ce0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:43:37.912462Z",
     "start_time": "2022-06-06T08:43:37.874444Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset=['orderid']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9541e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T08:50:40.035228Z",
     "start_time": "2022-06-06T08:50:40.026032Z"
    }
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bae87f6",
   "metadata": {},
   "source": [
    "# phone number blacklist code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5716ec",
   "metadata": {},
   "source": [
    "## Blacklist function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e33a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blacklist(data,col):\n",
    "    blacklist = data.groupby(by=[f'{col}']).agg({'orderid':'count','rto_or_not':'sum'}).reset_index()\n",
    "\n",
    "    blacklist['rto_pct'] = round(blacklist['rto_or_not']/blacklist['orderid'],4)\n",
    "\n",
    "    total_count_threshold,rto_pct_threshold = (5,0.6) if col==\"consignee_pincode\" else (1,0.5)\n",
    "\n",
    "    def blacklist_or_not(total_count,rto_pct,total_count_threshold=total_count_threshold,rto_pct_threshold=rto_pct_threshold):\n",
    "        if total_count>total_count_threshold and rto_pct>rto_pct_threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    blacklist['blacklist_or_not'] = blacklist.apply(lambda x: blacklist_or_not(x['orderid'],x['rto_pct']),axis=1)\n",
    "\n",
    "    blacklist_series = blacklist.loc[blacklist['blacklist_or_not']==1,f'{col}']\n",
    "    \n",
    "    return blacklist_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb0114",
   "metadata": {},
   "source": [
    "## blacklist list - single list for all merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971edbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T11:27:15.132810Z",
     "start_time": "2022-06-06T11:27:14.717713Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import phonenumbers\n",
    "from cleantext.clean import clean\n",
    "import phonenumbers\n",
    "def cleaned_phone_number(number):\n",
    "#     print(number)\n",
    "#     time.sleep(1/300)\n",
    "    if pd.isna(number):\n",
    "        return 0\n",
    "    number = str(number)\n",
    "    sum_ = sum_(i.isdigit() for i in number)\n",
    "    if sum_<10:\n",
    "        return 0\n",
    "#     if len(number)>17:\n",
    "#         return 0\n",
    "    number = number.replace(\"/\",\",\").replace(\".0\",\"\")\n",
    "    if \",\" in number:\n",
    "        number = number.split(\",\")[0]\n",
    "        \n",
    "#     print(number)\n",
    "#     print(len(number))\n",
    "    if len(number)>17:\n",
    "        return 0\n",
    "    z = phonenumbers.parse(clean(number,no_punct=True),'IN').national_number\n",
    "    if len(str(z))==10:\n",
    "        return z\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train['cleaned_phone_number'] = train['consignee_mob_no'].apply(cleaned_phone_number)\n",
    "\n",
    "blacklist = train.groupby(by=['cleaned_phone_number']).agg({'order_placed_date':'count','rto_or_not':'sum'}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blacklist['rto_pct'] = blacklist['rto_or_not']/blacklist['order_placed_date']\n",
    "\n",
    "def blacklist_or_not(total_count,rto_pct):\n",
    "    if total_count>1 and rto_pct>0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "blacklist['blacklist_or_not'] = blacklist.apply(lambda x: blacklist_or_not(x['order_placed_date'],x['rto_pct']),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blacklist = blacklist.loc[blacklist['blacklist_or_not']==1]\n",
    "\n",
    "blacklist_phone_number_list = list(set(blacklist['cleaned_phone_number'].to_list())-{0})\n",
    "\n",
    "# blacklist_dict = blacklist.groupby('merchant_store_name').apply(lambda x: list(x.cleaned_phone_number)).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5f89f",
   "metadata": {},
   "source": [
    "## blacklist dictionary - individual list for every merchant (not in use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb0670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T11:52:52.357743Z",
     "start_time": "2022-06-06T11:52:51.923893Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaned_phone_number(number):\n",
    "#     print(number)\n",
    "    if pd.isna(number):\n",
    "        return 0\n",
    "    number = str(number)\n",
    "    sum_ = sum(i.isdigit() for i in number)\n",
    "    if sum_<10:\n",
    "        return 0\n",
    "    if len(number)>18:\n",
    "        return 0\n",
    "    number = number.replace(\"/\",\",\")\n",
    "    if \",\" in number:\n",
    "        number = number.split(\",\")[0]\n",
    "    z = phonenumbers.parse(clean(number,no_punct=True),'IN').national_number\n",
    "    if len(str(z))==10:\n",
    "        return z\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "train['cleaned_phone_number'] = train['consignee_mob_no'].apply(cleaned_phone_number)\n",
    "\n",
    "blacklist = train.groupby(by=['merchant_store_name','cleaned_phone_number']).agg({'order_placed_date':'count','rto_or_not':'sum'}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blacklist['rto_pct'] = blacklist['rto_or_not']/blacklist['order_placed_date']\n",
    "\n",
    "def blacklist_or_not(total_count,rto_pct):\n",
    "    if total_count>1 and rto_pct>0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "blacklist['blacklist_or_not'] = blacklist.apply(lambda x: blacklist_or_not(x['order_placed_date'],x['rto_pct']),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blacklist = blacklist.loc[(blacklist['blacklist_or_not']==1)&(blacklist['cleaned_phone_number']!=0)]\n",
    "\n",
    "# blacklist_phone_number_list = list(set(blacklist['cleaned_phone_number'].to_list())-{0})\n",
    "\n",
    "blacklist_dict = blacklist.groupby('merchant_store_name').apply(lambda x: list(x.cleaned_phone_number)).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89adbae8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T11:52:54.682623Z",
     "start_time": "2022-06-06T11:52:54.670157Z"
    }
   },
   "outputs": [],
   "source": [
    "blacklist_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc344d15",
   "metadata": {},
   "source": [
    "# clean phone number function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67123f80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T11:03:56.942125Z",
     "start_time": "2022-06-06T11:03:56.926413Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleaned_phone_number(number):\n",
    "    print(number)\n",
    "    if pd.isna(number):\n",
    "        return 0\n",
    "    number = str(number)\n",
    "    sum_ = sum(i.isdigit() for i in number)\n",
    "    if sum_<10:\n",
    "        return 0\n",
    "    if len(number)>18:\n",
    "        return 0\n",
    "    number = number.replace(\"/\",\",\")\n",
    "    if \",\" in number:\n",
    "        number = number.split(\",\")[0]\n",
    "    z = phonenumbers.parse(clean(number,no_punct=True),'IN').national_number\n",
    "    if len(str(z))==10:\n",
    "        return z\n",
    "    else:\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e6587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T11:07:36.177766Z",
     "start_time": "2022-06-06T11:07:36.158284Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_phone_number(\"cqeqncaejnla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_user_input(user_input = 1, message = \"\"):\n",
    "\n",
    "    if user_input == 0:\n",
    "        play_some_sound(sound = \"check the console and input the required fields.\")\n",
    "        text = input(message)\n",
    "        \n",
    "        if text == \"Y\" or text == \"y\":\n",
    "            pass\n",
    "        else:\n",
    "            raise CustomErrorForCode(play_some_sound(\"Please check the make year wise triggers, the code has now stopped\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50522e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T11:38:07.809573Z",
     "start_time": "2022-06-07T11:38:07.803454Z"
    }
   },
   "source": [
    "# All special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea00d09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T11:37:57.859072Z",
     "start_time": "2022-06-07T11:37:57.857212Z"
    }
   },
   "outputs": [],
   "source": [
    "all_specials_characteres = \"[@_!#$%^&*()<>?/|}{~:;\\]\\[`'\\\"+=-]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e4d75c",
   "metadata": {},
   "source": [
    "# Name check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa001152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T10:09:57.796016Z",
     "start_time": "2022-06-08T10:09:57.789621Z"
    }
   },
   "outputs": [],
   "source": [
    "def name_check(name):\n",
    "    unaccented_string = unidecode.unidecode(name).strip()\n",
    "    if bool(re.match(\"^[a-zA-Z]+(([',. -][a-zA-Z ])?[a-zA-Z]*)*$\",str(unaccented_string))):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c369a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T10:10:05.524582Z",
     "start_time": "2022-06-08T10:10:05.505030Z"
    }
   },
   "outputs": [],
   "source": [
    "name_check(\"shubh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e177bc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T23:18:49.314436Z",
     "start_time": "2022-06-08T23:18:49.305785Z"
    }
   },
   "outputs": [],
   "source": [
    "\"first\" if need==\"first\" else (\"second\" if need==\"second\" else \"third\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0789d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T23:23:09.261549Z",
     "start_time": "2022-06-08T23:23:09.252525Z"
    }
   },
   "outputs": [],
   "source": [
    "input_list = [1, 2, 3, 4, 4, 5, 6, 7, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e57a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T23:25:28.740599Z",
     "start_time": "2022-06-08T23:25:28.731883Z"
    }
   },
   "outputs": [],
   "source": [
    "[i if i%2==0 else 0 for i in input_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70e2c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T23:31:10.391996Z",
     "start_time": "2022-06-08T23:31:10.387341Z"
    }
   },
   "outputs": [],
   "source": [
    "not(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16800a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-08T23:31:16.218767Z",
     "start_time": "2022-06-08T23:31:16.212836Z"
    }
   },
   "outputs": [],
   "source": [
    "not(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ae780c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T08:01:17.079668Z",
     "start_time": "2022-06-09T08:01:16.064661Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://email-checker.p.rapidapi.com/verify/v1\"\n",
    "\n",
    "querystring = {\"email\":\"smantri291996@gmail.com\"}\n",
    "\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"95d44cdf9emshc641a9b7805bbabp1d097cjsnb9e6865a2793\",\n",
    "\t\"X-RapidAPI-Host\": \"email-checker.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=querystring)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd640e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "773102fd",
   "metadata": {},
   "source": [
    "# Playing with the random function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7eaaab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T15:09:14.975493Z",
     "start_time": "2022-06-16T15:09:14.965116Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "a = random.random()\n",
    "b = random.randint(10, 100)\n",
    "c = random.sample(range(10, 40), 5) \n",
    "a,b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c03996",
   "metadata": {},
   "source": [
    "# Fetch Data from Shopify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e6c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T07:13:40.038752Z",
     "start_time": "2022-06-17T07:13:19.159058Z"
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = 'b49230aeceb0c43541b29a2f66706984'\n",
    "API_SECRET = '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'\n",
    "access_token = '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'\n",
    "\n",
    "import shopify\n",
    "shopify.Session.setup(api_key=API_KEY, secret=API_SECRET)\n",
    "\n",
    "shop_url = \"conscious-chemist.myshopify.com\"\n",
    "api_version = '2022-04'\n",
    "session = shopify.Session(shop_url, api_version, access_token)\n",
    "shopify.ShopifyResource.activate_session(session)\n",
    "\n",
    "shop = shopify.Shop.current() # Get the current shop\n",
    "# product = shopify.Product.find(179761209) # Get a specific product\n",
    "order = shopify.Customer()\n",
    "num = order.count()\n",
    "\n",
    "result = shopify.GraphQL().execute(\"\"\"{orders(first: 10 query: \"email:='smantriiitr@gmail.com'\") {edges {node {customerJourney {customerOrderIndex daysToConversion firstVisit {occurredAt} lastVisit {occurredAt} moments {occurredAt ... on CustomerVisit {id landingPage landingPageHtml occurredAt referralCode referralInfoHtml referrerUrl source sourceDescription sourceType utmParameters {campaign content medium source term } } } } legacyResourceId riskLevel risks{level message} physicalLocation{id addressVerified} lineItems(first:5){edges{node{name quantity product{totalInventory}}}} customer {legacyResourceId validEmailAddress verifiedEmail tags numberOfOrders lifetimeDuration lastOrder {id name createdAt} createdAt amountSpent{amount} orders(first:5){edges{node{createdAt}}} } } cursor } pageInfo {hasNextPage } } }\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5342145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-17T07:13:40.082443Z",
     "start_time": "2022-06-17T07:13:40.077708Z"
    }
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3de0669",
   "metadata": {},
   "source": [
    "## code not working but CURL version working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2fbc6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T15:09:42.950945Z",
     "start_time": "2022-06-16T15:09:42.112174Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "access_token = \"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\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/graphql\",\n",
    "    \"X-Shopify-Storefront-Access-Token\" : \"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\"\n",
    "}\n",
    "\n",
    "# query = \"\"\"\n",
    "# {\n",
    "#   shop {\n",
    "#     collections(first: 5) {\n",
    "#       edges {\n",
    "#         node {\n",
    "#           id\n",
    "#           handle\n",
    "#         }\n",
    "#       }\n",
    "#       pageInfo {\n",
    "#         hasNextPage\n",
    "#       }\n",
    "#     }\n",
    "#   }\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "query = \"\"\"\n",
    "  {\n",
    "    products(first: 3) {\n",
    "      edges {\n",
    "        node {\n",
    "          id\n",
    "          title\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\"\"\"\n",
    "\n",
    "\n",
    "# request = requests.post('https://richkitchindia.myshopify.com/api/graphql', json={'query': query}, headers=headers)\n",
    "\n",
    "request = requests.post('https://conscious-chemist.myshopify.com/admin/api/2022-04/graphql.json', json={'query': query}, headers=headers)\n",
    "\n",
    "# https://{store_name}.myshopify.com/admin/api/2022-04/graphql.json\n",
    "\n",
    "print(request.status_code)\n",
    "# result = request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558147e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T11:34:07.283882Z",
     "start_time": "2022-06-16T11:34:07.274807Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6c9d55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T11:34:43.011752Z",
     "start_time": "2022-06-16T11:34:42.731206Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/shubham_mantri/Downloads/generic_data_rule_testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f73c95a",
   "metadata": {},
   "source": [
    "# Clustering function for email and phone number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef092b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T14:59:35.986451Z",
     "start_time": "2022-06-16T14:59:35.961297Z"
    }
   },
   "outputs": [],
   "source": [
    "def clustering_phone_email(df):\n",
    "\n",
    "    from cleantext.clean import clean\n",
    "    import phonenumbers\n",
    "\n",
    "    def cleaned_phone_number(number):\n",
    "        #     print(number)\n",
    "        #     time.sleep(1/300)\n",
    "        if pd.isna(number):\n",
    "            return 0\n",
    "        number = str(number)\n",
    "        sum_ = sum(i.isdigit() for i in number)\n",
    "        if sum_ < 10:\n",
    "            return 0\n",
    "    #     if len(number)>17:\n",
    "    #         return 0\n",
    "        number = number.replace(\"/\", \",\").replace(\".0\", \"\")\n",
    "        if \",\" in number:\n",
    "            number = number.split(\",\")[0]\n",
    "\n",
    "    #     print(number)\n",
    "    #     print(len(number))\n",
    "        if len(number) > 17:\n",
    "            return 0\n",
    "        z = phonenumbers.parse(clean(number, no_punct=True),\n",
    "                               'IN').national_number\n",
    "        if len(str(z)) == 10:\n",
    "            return z\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df['cleaned_phone_number'] = df['consignee_mob_no'].apply(\n",
    "        cleaned_phone_number)\n",
    "\n",
    "    temp = df[['consignee_email', 'cleaned_phone_number']].drop_duplicates()\n",
    "\n",
    "    temp = temp.dropna()\n",
    "\n",
    "    temp = temp.loc[temp['cleaned_phone_number'] != 0, :]\n",
    "\n",
    "    temp['cleaned_phone_number'] = temp['cleaned_phone_number'].astype(str)\n",
    "\n",
    "    group_email = temp.groupby(by=['consignee_email']).agg({\n",
    "        'cleaned_phone_number':\n",
    "        lambda x: list(x)\n",
    "    }).reset_index()\n",
    "\n",
    "    group_phone = temp.groupby(by=['cleaned_phone_number']).agg({\n",
    "        'consignee_email':\n",
    "        lambda x: list(x)\n",
    "    }).reset_index()\n",
    "\n",
    "    def email_to_phone(email_list):\n",
    "        all_phone_list = []\n",
    "        for email in email_list:\n",
    "            #         print(\"1-\",group_email.loc[group_email['consignee_email']==email,'cleaned_phone_number'].values[0])\n",
    "            phone_list = group_email.loc[\n",
    "                group_email['consignee_email'] == email,\n",
    "                'cleaned_phone_number'].drop_duplicates().values[0]\n",
    "            #         print(\"2-\",phone_list)\n",
    "            all_phone_list = all_phone_list + phone_list\n",
    "        all_phone_list = list(set(all_phone_list))\n",
    "        return all_phone_list\n",
    "\n",
    "    group_phone['phone_list'] = group_phone['consignee_email'].apply(\n",
    "        email_to_phone)\n",
    "\n",
    "    group_phone = group_phone.rename(columns={'consignee_email': 'email_list'})\n",
    "\n",
    "    group_phone['email_list_str'] = group_phone['email_list'].astype(str)\n",
    "    group_phone['phone_list_str'] = group_phone['phone_list'].astype(str)\n",
    "\n",
    "    cluster = group_phone.drop_duplicates(\n",
    "        subset=['email_list_str', 'phone_list_str'])[[\n",
    "            'email_list', 'phone_list'\n",
    "        ]].reset_index().rename(columns={'index': 'uid'})\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced98a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T15:00:18.925766Z",
     "start_time": "2022-06-16T15:00:12.113177Z"
    }
   },
   "outputs": [],
   "source": [
    "clustering_phone_email(df).to_csv('cluster_email_phone.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9e7ce",
   "metadata": {},
   "source": [
    "# Creating Address Precision score from google maps geocoding api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ff1c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T13:35:31.769088Z",
     "start_time": "2022-06-21T13:35:31.365607Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from cleantext.clean import clean\n",
    "tqdm.pandas()\n",
    "GOOGLE_API_KEY = 'AIzaSyBm8OiGWcbaBuR2oz-8aBmLLeoG0yxarY4' \n",
    "\n",
    "result_list = {}\n",
    "\n",
    "def extract_lat_long_via_address(address_or_zipcode):\n",
    "    \"\"\"\n",
    "    this function returns the response of google maps geocoding api for the given address\n",
    "    \"\"\"\n",
    "#     print(address_or_zipcode)\n",
    "    #removing the punctuations marks -> #,& (majorly response for error)\n",
    "    address_or_zipcode = clean(address_or_zipcode,no_punct=True)\n",
    "    lat, lng = None, None\n",
    "    api_key = GOOGLE_API_KEY\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    endpoint = f\"{base_url}?address={address_or_zipcode}&key={api_key}\"\n",
    "#     time.sleep(0.5)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(endpoint,timeout=10.0)\n",
    "        if r.status_code not in range(200, 299):\n",
    "            result_list[address_or_zipcode]=\"wrong address\"\n",
    "            return \"wrong address\"\n",
    "        result_list[address_or_zipcode]=r.json()\n",
    "        #this condition will again trigger the api with the cleaned address\n",
    "        if result_list[address_or_zipcode]['status']==\"ZERO_RESULTS\":\n",
    "#             zero result case : 26/9, east patel nagar, east patel nagar east patel nagar New Delhi Delhi 110008 India\n",
    "            def clean_address_if_zero_results(extended_address):\n",
    "                \"\"\"\n",
    "                this functions cleans the duplicates in the address bcz of which zero results was popping out\n",
    "                \"\"\"\n",
    "                extended_address = clean(extended_address,no_punct=True).split(\" \")\n",
    "                a = []\n",
    "                for i in extended_address:\n",
    "                    if i in a:\n",
    "                        continue\n",
    "                    else:\n",
    "                        a.append(i)\n",
    "                return \" \".join(a)\n",
    "            address_or_zipcode = clean_address_if_zero_results(address_or_zipcode)\n",
    "            endpoint = f\"{base_url}?address={address_or_zipcode}&key={api_key}\"\n",
    "            r = requests.get(endpoint,timeout=10.0)\n",
    "            if r.status_code not in range(200, 299):\n",
    "                result_list[address_or_zipcode]=\"wrong address\"\n",
    "                return \"wrong address\"\n",
    "            result_list[address_or_zipcode]=r.json()\n",
    "        return result_list[address_or_zipcode]\n",
    "#         results = r.json()['results'][0]\n",
    "#         lat = results['geometry']['location']['lat']\n",
    "#         lng = results['geometry']['location']['lng']\n",
    "    except:\n",
    "        result_list[address_or_zipcode]=\"timeout error\"\n",
    "        return \"timeout error\"\n",
    "    \n",
    "\n",
    "import pyforest\n",
    "\n",
    "hierarchy = pd.read_excel(\n",
    "    \"/Users/shubham_mantri/Downloads/Google Maps Geocoding API response type hierarchy.xlsx\", \"Sheet1\")\n",
    "\n",
    "def address_precision_score(gmaps_api_result,result_index, state, city, pincode, complete_address):\n",
    "    \"\"\"\n",
    "    this function returns the score of the precision of the address for particular result\n",
    "\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "\n",
    "    for i in range(len(gmaps_api_result['results'][result_index]['address_components'])):\n",
    "        long_name = gmaps_api_result['results'][result_index]['address_components'][i]['long_name']\n",
    "        types = gmaps_api_result['results'][result_index]['address_components'][i]['types']\n",
    "        result_dict[long_name] = types\n",
    "\n",
    "    del result_dict['India']\n",
    "\n",
    "    temp = pd.DataFrame(result_dict.items(), columns=['long_name', 'types'])\n",
    "\n",
    "    def types_to_min_score(lst):\n",
    "        # minimum logic -> city comes in administrative_area_level_2,locality and sublocality\n",
    "        \"\"\"\n",
    "        this function converts the types list to score which is minimum of all\n",
    "    \n",
    "        \"\"\"\n",
    "        a = []\n",
    "        for i in lst:\n",
    "            if i == 'political':\n",
    "                continue\n",
    "            rank = hierarchy.loc[hierarchy['Entity Type']\n",
    "                                 == i, 'Rank'].values[0]\n",
    "            a.append(rank)\n",
    "        return np.min(a)\n",
    "\n",
    "    temp['score'] = temp['types'].apply(types_to_min_score)\n",
    "\n",
    "    temp = temp.sort_values(by='score')\n",
    "\n",
    "    import fuzzywuzzy\n",
    "    from fuzzywuzzy import fuzz\n",
    "\n",
    "    # state = \"Uttar Pradesh\"\n",
    "    # city = \"SAHARANPUR\"\n",
    "    # pincode = 247001\n",
    "    # complete_address = \"Madan hosiery Mishran street, khalapar\"\n",
    "\n",
    "    overall_score = 0\n",
    "    value = 0\n",
    "    state_count = 0\n",
    "    city_count = 0\n",
    "    pin_count = 0\n",
    "    \n",
    "    #creating a score\n",
    "    for i in range(len(temp)):\n",
    "        name = temp.iloc[i, 0]\n",
    "        score = temp.iloc[i, 2]\n",
    "        if score == 2:\n",
    "            if state_count>0:\n",
    "                continue\n",
    "            state_count+=1\n",
    "            if fuzz.ratio(name.lower(), state.lower()) < 90:\n",
    "                value = 0\n",
    "                print(\"State does not match\")\n",
    "                # return \"State does not match\"\n",
    "            else:\n",
    "                value = 100*1\n",
    "        elif score == 3:\n",
    "            if city_count>0:\n",
    "                continue\n",
    "            city_count+=1\n",
    "            # partial ratio bcz Delhi and New Delhi\n",
    "            if fuzz.partial_ratio(city.lower(),name.lower()) < 80:\n",
    "                value = 0\n",
    "                print(\"City does not match\")\n",
    "                # return \"City does not match\"\n",
    "            else:\n",
    "                value = fuzz.partial_ratio(city.lower(),name.lower())*1\n",
    "        elif score == 4:\n",
    "            if pin_count>0:\n",
    "                continue\n",
    "            pin_count+=1\n",
    "            if abs(int(name) - int(pincode)) > 10:\n",
    "                value = 0\n",
    "                print(\"Pincode does not match\")\n",
    "                # return \"Pincode does not match\"\n",
    "            else:\n",
    "                value = max(13-abs(int(name) - int(pincode)),10)*10*1\n",
    "        else:\n",
    "            value = score*(fuzz.partial_ratio(name.lower(),\n",
    "                           complete_address.lower()))/10*1.5\n",
    "            \n",
    "            # this line is for handling case like '7','c6' which resulted in 100 partial ratio thereby creating noise\n",
    "            value = value*0.25 if len(name)<=3 else value\n",
    "\n",
    "        print(name ,\"-\" ,value)\n",
    "        overall_score = overall_score + value\n",
    "    return overall_score\n",
    "\n",
    "def final_address_precision_score(gmaps_api_result, state, city, pincode, complete_address):\n",
    "    \"\"\"\n",
    "    this function returns the final precision score of the address considering all the results in gmaps json and corresponding index\n",
    "\n",
    "    \"\"\"\n",
    "    if pd.isna(gmaps_api_result):\n",
    "        return (0,0)\n",
    "    \n",
    "    if gmaps_api_result['status']==\"OK\":\n",
    "        score_list = []\n",
    "        #creating list of score for all possbile results and fetching the max possible score\n",
    "        for i in range(len(gmaps_api_result['results'])):\n",
    "            print(\"result_index:\",i)\n",
    "            score_list.append(address_precision_score(gmaps_api_result = gmaps_api_result,result_index=i, state=state, city=city, pincode=pincode, complete_address=complete_address))\n",
    "        print(score_list)\n",
    "        return np.argmax(score_list),np.max(score_list)\n",
    "    else:\n",
    "        return gmaps_api_result['status'],0\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49976023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T13:35:34.821882Z",
     "start_time": "2022-06-21T13:35:34.783409Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "result1 = {'results': [{'address_components': [{'long_name': '47MG+CVG',\n",
    " 'short_name': '47MG+CVG',\n",
    " 'types': ['plus_code']},\n",
    "{'long_name': 'Jorethang',\n",
    " 'short_name': 'Jorethang',\n",
    " 'types': ['locality', 'political']},\n",
    "{'long_name': 'West Sikkim',\n",
    " 'short_name': 'West Sikkim',\n",
    " 'types': ['administrative_area_level_2', 'political']},\n",
    "{'long_name': 'Sikkim',\n",
    " 'short_name': 'SK',\n",
    " 'types': ['administrative_area_level_1', 'political']},\n",
    "{'long_name': 'India',\n",
    " 'short_name': 'IN',\n",
    " 'types': ['country', 'political']},\n",
    "{'long_name': '737121', 'short_name': '737121', 'types': ['postal_code']}],\n",
    "'formatted_address': '47MG+CVG, Jorethang, Sikkim 737121, India',\n",
    "'geometry': {'location': {'lat': 27.1329311, 'lng': 88.27626819999999},\n",
    "'location_type': 'GEOMETRIC_CENTER',\n",
    "'viewport': {'northeast': {'lat': 27.1342506802915,\n",
    "  'lng': 88.27763498029151},\n",
    " 'southwest': {'lat': 27.1315527197085, 'lng': 88.27493701970849}}},\n",
    "'partial_match': True,\n",
    "'place_id': 'ChIJ-4B8t7Ap5DkRWVwJLwlitpw',\n",
    "'types': ['establishment', 'point_of_interest']},\n",
    "{'address_components': [{'long_name': 'Namchi - Nayabazar Road',\n",
    " 'short_name': 'Namchi - Nayabazar Rd',\n",
    " 'types': ['route']},\n",
    "{'long_name': 'Jorethang',\n",
    " 'short_name': 'Jorethang',\n",
    " 'types': ['locality', 'political']},\n",
    "{'long_name': 'South Sikkim',\n",
    " 'short_name': 'South Sikkim',\n",
    " 'types': ['administrative_area_level_2', 'political']},\n",
    "{'long_name': 'Sikkim',\n",
    " 'short_name': 'SK',\n",
    " 'types': ['administrative_area_level_1', 'political']},\n",
    "{'long_name': 'India',\n",
    " 'short_name': 'IN',\n",
    " 'types': ['country', 'political']}],\n",
    "'formatted_address': 'Namchi - Nayabazar Rd, Jorethang, Sikkim, India',\n",
    "'geometry': {'bounds': {'northeast': {'lat': 27.13565240000002,\n",
    "  'lng': 88.27965979999999},\n",
    " 'southwest': {'lat': 27.13295449999998, 'lng': 88.27711409999999}},\n",
    "'location': {'lat': 27.1342939, 'lng': 88.2781571},\n",
    "'location_type': 'GEOMETRIC_CENTER',\n",
    "'viewport': {'northeast': {'lat': 27.1356524302915,\n",
    "  'lng': 88.2797359302915},\n",
    " 'southwest': {'lat': 27.1329544697085, 'lng': 88.27703796970849}}},\n",
    "'partial_match': True,\n",
    "'place_id': 'Ei9OYW1jaGkgLSBOYXlhYmF6YXIgUmQsIEpvcmV0aGFuZywgU2lra2ltLCBJbmRpYSIuKiwKFAoSCSlcU3T_J-Q5EcaKLmGV-TvPEhQKEgndUvK5synkORGDztAJAGsmwQ',\n",
    "'types': ['route']},\n",
    "{'address_components': [{'long_name': 'Rock Garden Road',\n",
    " 'short_name': 'Rock Garden Rd',\n",
    " 'types': ['route']},\n",
    "{'long_name': 'Darjeeling',\n",
    " 'short_name': 'Darjeeling',\n",
    " 'types': ['administrative_area_level_2', 'political']},\n",
    "{'long_name': 'West Bengal',\n",
    " 'short_name': 'WB',\n",
    " 'types': ['administrative_area_level_1', 'political']},\n",
    "{'long_name': 'India',\n",
    " 'short_name': 'IN',\n",
    " 'types': ['country', 'political']},\n",
    "{'long_name': '734102', 'short_name': '734102', 'types': ['postal_code']}],\n",
    "'formatted_address': 'Rock Garden Rd, West Bengal 734102, India',\n",
    "'geometry': {'bounds': {'northeast': {'lat': 27.0307809, 'lng': 88.2400333},\n",
    " 'southwest': {'lat': 27.0242836, 'lng': 88.22542589999999}},\n",
    "'location': {'lat': 27.0265254, 'lng': 88.2323551},\n",
    "'location_type': 'GEOMETRIC_CENTER',\n",
    "'viewport': {'northeast': {'lat': 27.0307809, 'lng': 88.2400333},\n",
    " 'southwest': {'lat': 27.0242836, 'lng': 88.22542589999999}}},\n",
    "'partial_match': True,\n",
    "'place_id': 'ChIJGQaS5i0s5DkR73FYcRVpIVI',\n",
    "'types': ['route']}],\n",
    "'status': 'OK'}\n",
    "\n",
    "final_score1=final_address_precision_score(result1,\"Sikkim\",\"Jorethang\",737121,\"sisney, p/o & p/s naya bazar sisney rock garden road\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9300ade1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T13:35:43.757097Z",
     "start_time": "2022-06-21T13:35:43.751051Z"
    }
   },
   "outputs": [],
   "source": [
    "final_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151df96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T11:48:04.822129Z",
     "start_time": "2022-06-21T11:48:04.780250Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "result2 = {'results': [{'address_components': [{'long_name': 'c6',\n",
    "     'short_name': 'c6',\n",
    "     'types': ['subpremise']},\n",
    "    {'long_name': '7', 'short_name': '7', 'types': ['premise']},\n",
    "    {'long_name': 'Pocket 5',\n",
    "     'short_name': 'Pocket 5',\n",
    "     'types': ['political', 'sublocality', 'sublocality_level_3']},\n",
    "    {'long_name': 'Sector C',\n",
    "     'short_name': 'Sector C',\n",
    "     'types': ['political', 'sublocality', 'sublocality_level_2']},\n",
    "    {'long_name': 'Vasant Kunj',\n",
    "     'short_name': 'Vasant Kunj',\n",
    "     'types': ['political', 'sublocality', 'sublocality_level_1']},\n",
    "    {'long_name': 'New Delhi',\n",
    "     'short_name': 'New Delhi',\n",
    "     'types': ['locality', 'political']},\n",
    "    {'long_name': 'New Delhi',\n",
    "     'short_name': 'New Delhi',\n",
    "     'types': ['administrative_area_level_2', 'political']},\n",
    "    {'long_name': 'Delhi',\n",
    "     'short_name': 'DL',\n",
    "     'types': ['administrative_area_level_1', 'political']},\n",
    "    {'long_name': 'India',\n",
    "     'short_name': 'IN',\n",
    "     'types': ['country', 'political']},\n",
    "    {'long_name': '110070', 'short_name': '110070', 'types': ['postal_code']}],\n",
    "   'formatted_address': 'c6, 7, Pocket 5, Sector C, Vasant Kunj, New Delhi, Delhi 110070, India',\n",
    "   'geometry': {'location': {'lat': 28.5388252, 'lng': 77.1467188},\n",
    "    'location_type': 'ROOFTOP',\n",
    "    'viewport': {'northeast': {'lat': 28.5401047802915,\n",
    "      'lng': 77.14819608029151},\n",
    "     'southwest': {'lat': 28.5374068197085, 'lng': 77.1454981197085}}},\n",
    "   'partial_match': True,\n",
    "   'place_id': 'EkZjNiwgNywgUG9ja2V0IDUsIFNlY3RvciBDLCBWYXNhbnQgS3VuaiwgTmV3IERlbGhpLCBEZWxoaSAxMTAwNzAsIEluZGlhIh4aHAoWChQKEglVVVXhMhwNORECrxhrPeViSRICYzY',\n",
    "   'types': ['subpremise']},\n",
    "  {'address_components': [{'long_name': 'Pocket 6',\n",
    "     'short_name': 'Pocket 6',\n",
    "     'types': ['political', 'sublocality', 'sublocality_level_3']},\n",
    "    {'long_name': 'Sector C',\n",
    "     'short_name': 'Sector C',\n",
    "     'types': ['political', 'sublocality', 'sublocality_level_2']},\n",
    "    {'long_name': 'Vasant Kunj',\n",
    "     'short_name': 'Vasant Kunj',\n",
    "     'types': ['political', 'sublocality', 'sublocality_level_1']},\n",
    "    {'long_name': 'New Delhi',\n",
    "     'short_name': 'New Delhi',\n",
    "     'types': ['locality', 'political']},\n",
    "    {'long_name': 'South West Delhi',\n",
    "     'short_name': 'South West Delhi',\n",
    "     'types': ['administrative_area_level_2', 'political']},\n",
    "    {'long_name': 'Delhi',\n",
    "     'short_name': 'DL',\n",
    "     'types': ['administrative_area_level_1', 'political']},\n",
    "    {'long_name': 'India',\n",
    "     'short_name': 'IN',\n",
    "     'types': ['country', 'political']},\n",
    "    {'long_name': '110070', 'short_name': '110070', 'types': ['postal_code']}],\n",
    "   'formatted_address': 'Pocket 6, Sector C, Vasant Kunj, New Delhi, Delhi 110070, India',\n",
    "   'geometry': {'bounds': {'northeast': {'lat': 28.5384423, 'lng': 77.1474767},\n",
    "     'southwest': {'lat': 28.5347854, 'lng': 77.14357129999999}},\n",
    "    'location': {'lat': 28.5365363, 'lng': 77.14528070000001},\n",
    "    'location_type': 'ROOFTOP',\n",
    "    'viewport': {'northeast': {'lat': 28.5384423, 'lng': 77.1474767},\n",
    "     'southwest': {'lat': 28.5347854, 'lng': 77.14357129999999}}},\n",
    "   'partial_match': True,\n",
    "   'place_id': 'ChIJmcfFfTIcDTkRRcb7npoXZlI',\n",
    "   'types': ['establishment', 'premise']}],\n",
    " 'status': 'OK'}\n",
    "\n",
    "final_score2 = final_address_precision_score(result2,\"Delhi\",\"Delhi\",\"110070\",\"c-6 & 7, vasant kunj 6444\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d857fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T11:48:08.013596Z",
     "start_time": "2022-06-21T11:48:07.990948Z"
    }
   },
   "outputs": [],
   "source": [
    "result3 = {'results': [{'address_components': [{'long_name': '797115',\n",
    "     'short_name': '797115',\n",
    "     'types': ['postal_code']},\n",
    "    {'long_name': 'Dimapur',\n",
    "     'short_name': 'Dimapur',\n",
    "     'types': ['administrative_area_level_2', 'political']},\n",
    "    {'long_name': 'Nagaland',\n",
    "     'short_name': 'NL',\n",
    "     'types': ['administrative_area_level_1', 'political']},\n",
    "    {'long_name': 'India',\n",
    "     'short_name': 'IN',\n",
    "     'types': ['country', 'political']}],\n",
    "   'formatted_address': 'Nagaland 797115, India',\n",
    "   'geometry': {'bounds': {'northeast': {'lat': 25.9045791,\n",
    "      'lng': 93.79605219999999},\n",
    "     'southwest': {'lat': 25.8133576, 'lng': 93.7331772}},\n",
    "    'location': {'lat': 25.8393641, 'lng': 93.75366629999999},\n",
    "    'location_type': 'APPROXIMATE',\n",
    "    'viewport': {'northeast': {'lat': 25.9045791, 'lng': 93.79605219999999},\n",
    "     'southwest': {'lat': 25.8133576, 'lng': 93.7331772}}},\n",
    "   'partial_match': True,\n",
    "   'place_id': 'ChIJPRpxOrYJRjcRTysg7ty6L1s',\n",
    "   'postcode_localities': ['2  Mile',\n",
    "    '3rd Mile',\n",
    "    '4th Mile',\n",
    "    '5Th Mile Model',\n",
    "    '5th Mile',\n",
    "    '6th Mile',\n",
    "    '7th Mile',\n",
    "    'Ao Yimti',\n",
    "    'Aoyimti',\n",
    "    'Chekiye',\n",
    "    'Chumukeidma',\n",
    "    'Dimapur',\n",
    "    \"Diphupar 'B'\",\n",
    "    'Diphupar A',\n",
    "    'Diphupar B',\n",
    "    'Dubagaon',\n",
    "    'Ekrani Pathar',\n",
    "    'Eralibil',\n",
    "    'J.V.Perhereilie',\n",
    "    'Padampukhuri',\n",
    "    'Sugar Mill Colony',\n",
    "    'Thelikhu'],\n",
    "   'types': ['postal_code']}],\n",
    " 'status': 'OK'}\n",
    "\n",
    "final_score3 = final_address_precision_score(result3,\"Nagaland\",\"Dimapur\",\"797115\",\"artc&s sokhuvi no3 trg bn hs no 37\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1f328",
   "metadata": {},
   "source": [
    "# Matplotlib commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f8213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:14:58.033760Z",
     "start_time": "2022-06-19T02:14:58.023637Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.sort([np.random.randint(1,1000) for i in range(100)])\n",
    "b = np.sort([np.random.randint(1,1000) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7afe9f",
   "metadata": {},
   "source": [
    "## Simple Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac9ecdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:15:00.422918Z",
     "start_time": "2022-06-19T02:15:00.325334Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d08c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:15:01.871741Z",
     "start_time": "2022-06-19T02:15:01.772086Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(a,b,'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a828c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:15:03.731799Z",
     "start_time": "2022-06-19T02:15:03.631057Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(a,b,linestyle=\"dashed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fd2ba",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179eca17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:15:15.312569Z",
     "start_time": "2022-06-19T02:15:15.210957Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(a,bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee197e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:15:29.168967Z",
     "start_time": "2022-06-19T02:15:29.071935Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(a,bins=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a5c64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:17:11.960198Z",
     "start_time": "2022-06-19T02:17:11.880254Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(a,bins=[0,100,500,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21908eba",
   "metadata": {},
   "source": [
    "## Multiples in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd2a34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:16:22.143021Z",
     "start_time": "2022-06-19T02:16:22.044110Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(a,b)\n",
    "plt.plot(b,a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd392c",
   "metadata": {},
   "source": [
    "## Scatter plot + Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e419a31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:18:57.557417Z",
     "start_time": "2022-06-19T02:18:57.448370Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(a,b)\n",
    "plt.xlabel(\"X-Axis\")\n",
    "plt.ylabel(\"Y-Axis\")\n",
    "plt.title('Title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2e351",
   "metadata": {},
   "source": [
    "## Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebfc0d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:22:21.503292Z",
     "start_time": "2022-06-19T02:22:21.499735Z"
    }
   },
   "outputs": [],
   "source": [
    "x = [\"A\",\"B\",\"C\",\"D\"]\n",
    "y = [12,43,132,68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f52be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:22:39.684655Z",
     "start_time": "2022-06-19T02:22:39.591824Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e8b1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:23:24.105340Z",
     "start_time": "2022-06-19T02:23:24.011856Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.barh(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29cd65",
   "metadata": {},
   "source": [
    "## Pie charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f414df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:26:12.649469Z",
     "start_time": "2022-06-19T02:26:12.644493Z"
    }
   },
   "outputs": [],
   "source": [
    "x = [10,40,20,30]\n",
    "y = [\"A\",\"B\",\"C\",\"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927b4d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:27:04.384697Z",
     "start_time": "2022-06-19T02:27:04.298867Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.pie(x, labels=y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac40d5c",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef89e3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:31:03.267390Z",
     "start_time": "2022-06-19T02:31:03.255838Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.sort([np.random.randint(50,100) for i in range(100)])\n",
    "b = np.sort([np.random.randint(10,300) for i in range(100)])\n",
    "c = np.sort([np.random.randint(0,500) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd4960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:32:06.267997Z",
     "start_time": "2022-06-19T02:32:06.169196Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.boxplot([a,b,c],labels = ['A',\"B\",\"C\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d600324f",
   "metadata": {},
   "source": [
    "## Violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09247b40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T02:33:24.657201Z",
     "start_time": "2022-06-19T02:33:24.542327Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.violinplot([a,b,c])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b3c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T09:37:35.357130Z",
     "start_time": "2022-06-21T09:37:35.350862Z"
    }
   },
   "source": [
    "# *Args and **Kwargs in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4a4c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T09:33:26.496331Z",
     "start_time": "2022-06-21T09:33:26.490860Z"
    }
   },
   "outputs": [],
   "source": [
    "def func(*argv):\n",
    "    for i in argv:\n",
    "        print(i)\n",
    "\n",
    "func(\"Args\",\"is\",\"non\",\"keyword\",\"argument\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e097fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T10:28:21.215766Z",
     "start_time": "2022-06-21T10:28:21.209946Z"
    }
   },
   "outputs": [],
   "source": [
    "def func(**kwargs):\n",
    "    for key,value in kwargs.items():\n",
    "        print(key,\"-\",value)\n",
    "        \n",
    "\n",
    "func(argument1 = \"value1\",argument2 =\"value2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24125a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T10:39:51.972098Z",
     "start_time": "2022-06-21T10:39:51.966457Z"
    }
   },
   "outputs": [],
   "source": [
    "a = {1:2}\n",
    "b = {3:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7202826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T10:39:52.392053Z",
     "start_time": "2022-06-21T10:39:52.387383Z"
    }
   },
   "outputs": [],
   "source": [
    "c = a.update(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e9140",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T10:39:52.709815Z",
     "start_time": "2022-06-21T10:39:52.704367Z"
    }
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557e1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T10:41:59.364972Z",
     "start_time": "2022-06-21T10:41:59.358723Z"
    }
   },
   "outputs": [],
   "source": [
    "a|b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb723b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T11:21:57.627841Z",
     "start_time": "2022-06-21T11:21:57.620492Z"
    }
   },
   "outputs": [],
   "source": [
    "b;a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9684218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-21T11:23:33.606055Z",
     "start_time": "2022-06-21T11:23:33.599839Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Statement1\");print(\"Statement2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574e406",
   "metadata": {},
   "source": [
    "# how to create virtual environment in terminal"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e88ebca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T16:18:24.062233Z",
     "start_time": "2022-06-27T16:18:24.054995Z"
    }
   },
   "source": [
    "virtualenv project_name\n",
    "source project_name/bin/activate\n",
    "deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f36b8c",
   "metadata": {},
   "source": [
    "# phone number blacklist code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518162c",
   "metadata": {},
   "source": [
    "## Blacklist function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6352b5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:49:53.889821Z",
     "start_time": "2022-06-28T02:49:53.870730Z"
    }
   },
   "outputs": [],
   "source": [
    "def blacklist(data,col):\n",
    "    blacklist = data.groupby(by=[f'{col}']).agg({'orderid':'count','rto_or_not':'sum'}).reset_index()\n",
    "\n",
    "    blacklist['rto_pct'] = round(blacklist['rto_or_not']/blacklist['orderid'],4)\n",
    "\n",
    "    total_count_threshold,rto_pct_threshold = (5,0.6) if col==\"consignee_pincode\" else (1,0.5)\n",
    "\n",
    "    def blacklist_or_not(total_count,rto_pct,total_count_threshold=total_count_threshold,rto_pct_threshold=rto_pct_threshold):\n",
    "        if total_count>total_count_threshold and rto_pct>rto_pct_threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    blacklist['blacklist_or_not'] = blacklist.apply(lambda x: blacklist_or_not(x['orderid'],x['rto_pct']),axis=1)\n",
    "\n",
    "    blacklist_series = blacklist.loc[blacklist['blacklist_or_not']==1,f'{col}']\n",
    "    \n",
    "    return blacklist_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac5deb",
   "metadata": {},
   "source": [
    "## blacklist list - single list for all merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be39c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:49:59.899659Z",
     "start_time": "2022-06-28T02:49:59.521080Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import phonenumbers\n",
    "from cleantext.clean import clean\n",
    "import phonenumbers\n",
    "def cleaned_phone_number(number):\n",
    "#     print(number)\n",
    "#     time.sleep(1/300)\n",
    "    if pd.isna(number):\n",
    "        return 0\n",
    "    number = str(number)\n",
    "    sum_ = sum_(i.isdigit() for i in number)\n",
    "    if sum_<10:\n",
    "        return 0\n",
    "#     if len(number)>17:\n",
    "#         return 0\n",
    "    number = number.replace(\"/\",\",\").replace(\".0\",\"\")\n",
    "    if \",\" in number:\n",
    "        number = number.split(\",\")[0]\n",
    "        \n",
    "#     print(number)\n",
    "#     print(len(number))\n",
    "    if len(number)>17:\n",
    "        return 0\n",
    "    z = phonenumbers.parse(clean(number,no_punct=True),'IN').national_number\n",
    "    if len(str(z))==10:\n",
    "        return z\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train['cleaned_phone_number'] = train['consignee_mob_no'].apply(cleaned_phone_number)\n",
    "\n",
    "blacklist = train.groupby(by=['cleaned_phone_number']).agg({'order_placed_date':'count','rto_or_not':'sum'}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blacklist['rto_pct'] = blacklist['rto_or_not']/blacklist['order_placed_date']\n",
    "\n",
    "def blacklist_or_not(total_count,rto_pct):\n",
    "    if total_count>1 and rto_pct>0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "blacklist['blacklist_or_not'] = blacklist.apply(lambda x: blacklist_or_not(x['order_placed_date'],x['rto_pct']),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blacklist = blacklist.loc[blacklist['blacklist_or_not']==1]\n",
    "\n",
    "blacklist_phone_number_list = list(set(blacklist['cleaned_phone_number'].to_list())-{0})\n",
    "\n",
    "# blacklist_dict = blacklist.groupby('merchant_store_name').apply(lambda x: list(x.cleaned_phone_number)).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c35ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T02:52:31.022225Z",
     "start_time": "2022-06-28T02:52:31.015099Z"
    }
   },
   "source": [
    "### putting blacklist tables in S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "AWS_S3_BUCKET = \"bucket_name\"\n",
    "AWS_ACCESS_KEY_ID = \"key_id\"\n",
    "AWS_SECRET_ACCESS_KEY = \"secret_key\"\n",
    "REGION_NAME = \"eu-west-1\"\n",
    "\n",
    "\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name = REGION_NAME\n",
    "#     aws_session_token=AWS_SESSION_TOKEN,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "with io.StringIO() as csv_buffer:\n",
    "    table.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    response = s3_client.put_object(\n",
    "        Bucket=AWS_S3_BUCKET, Key=f\"files/table.csv\", Body=csv_buffer.getvalue()\n",
    "    )\n",
    "\n",
    "    status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "    if status == 200:\n",
    "        print(f\"Successful S3 put_object response. Status - {status}\")\n",
    "    else:\n",
    "        print(f\"Unsuccessful S3 put_object response. Status - {status}\")\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e219f7",
   "metadata": {},
   "source": [
    "# Playing with time,date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "date.today() + relativedelta(years=3)\n",
    "\n",
    "import datetime\n",
    "datetime.datetime.now(),datetime.datetime.now() + relativedelta(minutes=3,days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fb555",
   "metadata": {},
   "source": [
    "# Airflow dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96469b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from datetime import datetime\n",
    "from airflow.operators.python import PythonOperator\n",
    "\n",
    "def message():\n",
    "    print(\"First DAG executed Successfully!!\")\n",
    "\n",
    "with DAG(dag_id=\"FirstDAG\", start_date=datetime(2022,6,29), schedule_interval=\"@hourly\",\n",
    "         catchup=False) as dag:\n",
    "\n",
    "    task = PythonOperator(\n",
    "        task_id=\"task\",\n",
    "        python_callable=message)\n",
    "\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a33e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.utils.dates import datetime\n",
    "from airflow.utils.dates import timedelta\n",
    "from airflow.operators.dummy_operator import DummyOperator\n",
    "from airflow.operators.python import PythonOperator\n",
    "from sqlalchemy import create_engine\n",
    "import yaml\n",
    "\n",
    "def message():\n",
    "    print(\"First DAG executed Successfully!!\")         \n",
    "\n",
    "default_args = {\n",
    "    'depends_on_past': False,\n",
    "    'email': ['shubham@bureau.id'],\n",
    "    'email_on_failure': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    dag_id='FirstDAG',\n",
    "    default_args=default_args,\n",
    "    start_date=datetime(2022, 6, 30),\n",
    "    schedule_interval=\"@daily\"\n",
    ")\n",
    "\n",
    "\n",
    "task = PythonOperator(\n",
    "    task_id = 'FirstDAG',\n",
    "    dag=dag,\n",
    "    python_callable=message,\n",
    ")\n",
    "\n",
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb410155-d3ff-4ed7-8530-2a0d14dfe53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686b1ae-3275-4f1b-a214-6482f5c5fbe8",
   "metadata": {},
   "source": [
    "# OOPS / Classes and Objects in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386625a2-e103-4f74-b92a-45d9f3b60f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Test:\n",
    "    \"\"\"\n",
    "    this is test class\n",
    "    \"\"\"\n",
    "    fix_att = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def fix_method(a,b):\n",
    "        return a*b\n",
    "    \n",
    "    def __init__(self,att1,att2):\n",
    "        self.att1 = att1\n",
    "        self.att2 = att2\n",
    "        self.fix = 10\n",
    "    \n",
    "    #this is instance method\n",
    "    def method(self,text,text2=\"\"):\n",
    "        \"\"\"\n",
    "        this is method1 docstring\n",
    "        \"\"\"\n",
    "        return text + text2 + self.att1\n",
    "    \n",
    "    @classmethod\n",
    "    def class_method(cls,text):\n",
    "        return cls.fix_att\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d26f3-0e3d-45b4-be0f-1159de91d4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "object1.fix_method(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211571f-7f15-43bf-8342-1ab598b7ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.fix_method(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b63e5bf-326e-4283-b837-d7d1df1103a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "object1 = Test(\"Att1\",\"Att2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450a398-3351-4598-9bf3-2f329e75f8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "object1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800a8e7-fc33-4cd0-9c80-3e347347d4eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "object1.method(\" text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcabb3e-8654-4d91-aee0-923d48aded51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Test.class_method(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6299e-f920-44c6-8ff0-15b43c4b74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "object1.class_method(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d652045-a4fd-4848-a58d-678f053000dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "object1.fix_att = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982efbd-94cf-450f-9181-a25e34e6f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "object1.fix_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1508d9-e82f-4f3c-9351-1076235ec77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "object1.fix = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dcc558-10e3-49fe-937b-8f7ff7a10ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "object1.fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74423979-1476-4dc8-8391-e5bd0f8ab75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "object2 = Test(\"Att1\",\"Att2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920bd42-3ff4-4b01-af61-77e05e770014",
   "metadata": {},
   "outputs": [],
   "source": [
    "object2.fix_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287244a5-6fd0-439a-afd7-c79d2fcbfce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calling static method on class\n",
    "Test.fix_method(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29368fbb-b4e0-4f64-a1a1-e6ed72ffdd62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calling static method on object\n",
    "object1.fix_method(10,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f60219-c5d4-4a47-ad6f-67ae4946adbf",
   "metadata": {},
   "source": [
    "# keras neural netowrk code flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052c43e-7718-47ed-967e-c66ead510c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load the dataset\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62298abb-e7b0-4f6d-b6f9-de198e07eed5",
   "metadata": {},
   "source": [
    "# Connection to prod DB??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e4c22-2356-4224-b591-015472118be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "connection_string_prod = create_engine('postgresql://beau-metrics-prd-redshift-adminuser:vD3NJQKQhuch8yE@10.30.24.48:5439/elt')\n",
    "query2 = \"\"\"select count(*) from otc.order_logs;\"\"\"\n",
    "df = pd.read_sql(query2, con=connection_string_prod)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73670773-033a-464a-bffc-fa744334a15b",
   "metadata": {},
   "source": [
    "# parallelism / threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bbdbc-eb27-423d-97a4-1055f5fc9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def async_fetch_addr_gmap_api_results(df, required_col_name, feature_name_col, api_key, base_url, limit=40, rate=1):\n",
    "    limit = asyncio.Semaphore(limit)\n",
    "    \n",
    "    async def extract_lat_long_via_address(address, api_key, base_url, limit, rate):\n",
    "        async with limit:\n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                if address in gmap_results:\n",
    "                    return gmap_results[address]\n",
    "                endpoint = f'{base_url}?address={address}&key={api_key}'            \n",
    "                try:\n",
    "                    resp = await session.get(endpoint, timeout=5)\n",
    "                except:\n",
    "                    return 'timeout error'\n",
    "                content = await resp.json()\n",
    "                status = resp.status\n",
    "                #log.info(f'Made request {endpoint}. Status {status}')\n",
    "                if status not in range(200, 299):\n",
    "                    return 'wrong address'\n",
    "                await asyncio.sleep(rate)\n",
    "                return content\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    results = loop.run_until_complete(asyncio.gather(*[extract_lat_long_via_address(address, api_key, base_url, limit, rate) for address in df[required_col_name]]))\n",
    "    df[feature_name_col] = results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4f6bc-c4c5-42cf-a573-269a18d8e56e",
   "metadata": {},
   "source": [
    "# Fetching customer behaviour data from shopify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11facd8-1be2-429d-baa2-d3937c530e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_shopify_data(orderid, shop_url=\"conscious-chemist.myshopify.com\"):\n",
    "    time.sleep(0.3)\n",
    "    base_url = \"https://api.blaze.prd.bureau.id/graphql\"\n",
    "    headers = {\n",
    "              'X-BLAZE-ADMIN-AUTH': 'D442F6E9-14E8-4775-A5DB-792004A36587',\n",
    "              'Content-Type': 'application/json'\n",
    "            }\n",
    "    query = f\"\"\"{{\n",
    "      order(id: \"gid://shopify/Order/{orderid}\") {{\n",
    "        id\n",
    "        createdAt\n",
    "        customerJourney {{\n",
    "          customerOrderIndex\n",
    "          daysToConversion\n",
    "          moments {{\n",
    "            occurredAt\n",
    "            ... on CustomerVisit {{\n",
    "              id\n",
    "              landingPage\n",
    "              occurredAt\n",
    "              referrerUrl\n",
    "              source\n",
    "              sourceDescription\n",
    "              sourceType\n",
    "            }}\n",
    "          }}\n",
    "          firstVisit {{\n",
    "            id\n",
    "            landingPage\n",
    "            occurredAt\n",
    "            referrerUrl\n",
    "            source\n",
    "            sourceDescription\n",
    "            sourceType\n",
    "          }}\n",
    "          lastVisit {{\n",
    "            id\n",
    "            landingPage\n",
    "            occurredAt\n",
    "            referrerUrl\n",
    "            source\n",
    "            sourceDescription\n",
    "            sourceType\n",
    "          }}\n",
    "        }}\n",
    "        riskLevel\n",
    "        risks(first: 20) {{\n",
    "          level\n",
    "          message\n",
    "        }}\n",
    "        customer {{\n",
    "          legacyResourceId\n",
    "          createdAt\n",
    "          lifetimeDuration\n",
    "          validEmailAddress\n",
    "          verifiedEmail\n",
    "          ordersCount\n",
    "          addresses(first: 20) {{\n",
    "            address1\n",
    "            address2\n",
    "            city\n",
    "            country\n",
    "            company\n",
    "            countryCode\n",
    "            firstName\n",
    "            lastName\n",
    "            id\n",
    "            latitude\n",
    "            longitude\n",
    "            name\n",
    "            phone\n",
    "            province\n",
    "            provinceCode\n",
    "            zip\n",
    "          }}\n",
    "          orders(first: 20){{\n",
    "            edges {{\n",
    "              node {{\n",
    "                createdAt\n",
    "              }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "      }}\n",
    "    }}\"\"\"\n",
    "    payload = json.dumps({\n",
    "      \"store\": shop_url,\n",
    "      \"query\": query\n",
    "    })\n",
    "    response = requests.post(base_url, headers=headers, data=payload)\n",
    "    # return response\n",
    "    if response.status_code == 200:\n",
    "        return(json.loads(response.text))\n",
    "    else:\n",
    "        return\n",
    "\n",
    "sample_shopify = get_shopify_data(4454059901030)\n",
    "\n",
    "sample_shopify\n",
    "\n",
    "\n",
    "# df['shopify_gql_result'] = df.apply(lambda x: get_shopify_data(x['order_id']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9884281-8151-4663-8792-221da0e45158",
   "metadata": {},
   "source": [
    "## deriving features from shopify customer json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa18982-fed0-43f5-8591-c7b166527270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_features_from_shopify_gql_result(shopify_gql_result):\n",
    "    try:\n",
    "        if pd.isna(shopify_gql_result):\n",
    "            return pd.NA\n",
    "        order_placed_date = shopify_gql_result['data']['order']['createdAt']\n",
    "        \n",
    "        overall_risk_level = shopify_gql_result['data']['order']['riskLevel']\n",
    "\n",
    "        low_count=0\n",
    "        risk_list = shopify_gql_result['data']['order']['risks']\n",
    "        for i in risk_list:\n",
    "            if i['level']==\"LOW\":\n",
    "                low_count+=1\n",
    "\n",
    "        medium_count=0\n",
    "        risk_list = shopify_gql_result['data']['order']['risks']\n",
    "        for i in risk_list:\n",
    "            if i['level']==\"MEDIUM\":\n",
    "                medium_count+=1\n",
    "\n",
    "        high_count=0\n",
    "        risk_list = shopify_gql_result['data']['order']['risks']\n",
    "        for i in risk_list:\n",
    "            if i['level']==\"HIGH\":\n",
    "                high_count+=1\n",
    "    except:\n",
    "        return pd.NA\n",
    "    \n",
    "    return order_placed_date, overall_risk_level, low_count, medium_count, high_count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df[['order_placed_date', 'overall_risk_level', 'low_count', 'medium_count', 'high_count']] = df.apply(lambda x: basic_features_from_shopify_gql_result(x['shopify_gql_result']),axis=1,result_type=\"expand\")\n",
    "\n",
    "def customer_features_from_shopify_gql_result(shopify_gql_result):\n",
    "    try:\n",
    "        if pd.isna(shopify_gql_result):\n",
    "            return pd.NA\n",
    "        customer_created_at = shopify_gql_result['data']['order']['customer']['createdAt']\n",
    "\n",
    "        lifetimeDuration = shopify_gql_result['data']['order']['customer']['lifetimeDuration']\n",
    "\n",
    "        ordersCount = shopify_gql_result['data']['order']['customer']['ordersCount']\n",
    "\n",
    "        customer_address_count = len(shopify_gql_result['data']['order']['customer']['addresses'])\n",
    "\n",
    "        validEmailAddress = shopify_gql_result['data']['order']['customer']['validEmailAddress']*1\n",
    "\n",
    "        verifiedEmail = shopify_gql_result['data']['order']['customer']['verifiedEmail']*1\n",
    "    except:\n",
    "        return pd.NA\n",
    "    return customer_created_at, lifetimeDuration, ordersCount, customer_address_count, validEmailAddress, verifiedEmail \n",
    "        \n",
    "df[['customer_created_at', 'lifetimeDuration', 'ordersCount', 'customer_address_count', 'validEmailAddress', 'verifiedEmail']] = df.apply(lambda x: customer_features_from_shopify_gql_result(x['shopify_gql_result']),axis=1,result_type=\"expand\")\n",
    "\n",
    "def customer_journey_features_from_shopify_gql_result(shopify_gql_result):\n",
    "    try:\n",
    "        if pd.isna(shopify_gql_result):\n",
    "            return pd.NA\n",
    "        daysToConversion = shopify_gql_result['data']['order']['customerJourney']['daysToConversion']\n",
    "\n",
    "        moments_count = len(shopify_gql_result['data']['order']['customerJourney']['moments'])\n",
    "\n",
    "        firstvisit_time = shopify_gql_result['data']['order']['customerJourney']['firstVisit']['occurredAt']\n",
    "\n",
    "        lastvisit_time = shopify_gql_result['data']['order']['customerJourney']['lastVisit']['occurredAt'] if moments_count>1 else firstvisit_time\n",
    "        \n",
    "        source = shopify_gql_result['data']['order']['customerJourney']['moments'][-1]['source']\n",
    "    except:\n",
    "        return pd.NA\n",
    "    return daysToConversion, moments_count, lastvisit_time, firstvisit_time, source\n",
    "\n",
    "df[['daysToConversion', 'moments_count', 'lastvisit_time', 'firstvisit_time', 'source']] = df.apply(lambda x: customer_journey_features_from_shopify_gql_result(x['shopify_gql_result']),axis=1,result_type=\"expand\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## converting datetime columns to correct types\n",
    "\n",
    "df['order_placed_date'] = pd.to_datetime(df['order_placed_date'])\n",
    "df['customer_created_at'] = pd.to_datetime(df['customer_created_at'])\n",
    "df['lastvisit_time'] = pd.to_datetime(df['lastvisit_time'])\n",
    "df['firstvisit_time'] = pd.to_datetime(df['firstvisit_time'])\n",
    "\n",
    "\n",
    "## derived features\n",
    "\n",
    "df['age_of_customer'] = (df['order_placed_date']-df['customer_created_at']).dt.total_seconds()\n",
    "\n",
    "df['order_lastvisit'] = (df['order_placed_date']-df['lastvisit_time']).dt.total_seconds()\n",
    "\n",
    "df['order_firstvisit'] = (df['order_placed_date']-df['firstvisit_time']).dt.total_seconds()\n",
    "\n",
    "\n",
    "def high_impulsive_behaviour(moment_count,order_count,order_lastvisit):\n",
    "    try:\n",
    "        if (int(moment_count)==1) and (int(order_count)==1):\n",
    "            return order_lastvisit\n",
    "        else:\n",
    "            return pd.NA\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "\n",
    "df['high_impulsive_behaviour'] = df.apply(lambda x: high_impulsive_behaviour(x['moments_count'],x['ordersCount'],x['order_lastvisit']),axis=1)\n",
    "                                                                               \n",
    "                                                                               \n",
    "                                                                               \n",
    "\n",
    "def label_encoding_risk(risk_level):\n",
    "    try:\n",
    "        if pd.isna(risk_level):\n",
    "            return pd.NA\n",
    "        if risk_level==\"LOW\":\n",
    "            return 1\n",
    "        elif risk_level==\"MEDIUM\":\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "df['label_encoding_risk'] = df['overall_risk_level'].apply(label_encoding_risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6cb46c-5ae6-4205-b71b-d198b125dfd3",
   "metadata": {},
   "source": [
    "# Feature Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde97cf9-b6d5-48a5-bf2c-6e4a117bb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_analysis(feature,demand='lower',label = 'rto_or_not',df = df,method='percentile',total_count_threshold=0,rto_pct_threshold=0):\n",
    "    \n",
    "    print(feature)\n",
    "    def not_null_columns(df):\n",
    "        a=[]\n",
    "        for i in df.columns:\n",
    "            if df[i].isnull().sum()==0:\n",
    "                a.append(i)\n",
    "        return a\n",
    "\n",
    "\n",
    "\n",
    "    def link(feature=feature,label=label, df = df,total_count_threshold=total_count_threshold,rto_pct_threshold=rto_pct_threshold):\n",
    "        pivot=df.pivot_table(values=[i for i in not_null_columns(df) if i not in [feature,label]][0],index=feature,columns=label,aggfunc='count')\n",
    "        pivot['sum']=pivot.sum(axis=1)\n",
    "        pivot.fillna(0,inplace=True)\n",
    "        pivot['rto_pct']=(pivot[1])/(pivot['sum'])\n",
    "        return pivot.loc[(pivot['sum']>=total_count_threshold)&(pivot['rto_pct']>=rto_pct_threshold),:]\n",
    "    \n",
    "    if demand=='equal':\n",
    "        return print(link(feature))\n",
    "    \n",
    "    \n",
    "    if method == 'percentile':\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['percentile','value_less/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(5,100,5)]:\n",
    "                total = len(df.loc[df[feature]<=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_less/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['percentile','value_more/equal_than','total','rto_pct'])\n",
    "            for i in [x/100 for x in range(0,100,5)]:\n",
    "                total = len(df.loc[df[feature]>=df[feature].quantile(i),:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=df[feature].quantile(i))&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'percentile':i,'value_more/equal_than':df[feature].quantile(i),'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    else:\n",
    "        if demand == 'lower':\n",
    "            table = pd.DataFrame(columns=['value_less/equal_than','total','rto_pct'])\n",
    "            for i in range(1,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]<=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]<=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_less/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "        else:\n",
    "            table = pd.DataFrame(columns=['value_more/equal_than','total','rto_pct'])\n",
    "            for i in range(0,int(df[feature].max()+1),1):\n",
    "                total = len(df.loc[df[feature]>=i,:])\n",
    "                rto_pct = len(df.loc[(df[feature]>=i)&(df[label]==1),:])/total if total>0 else 0\n",
    "                table = table.append({'value_more/equal_than':i,'total':total,'rto_pct':rto_pct},ignore_index=True)\n",
    "    table['feature'] = feature\n",
    "    \n",
    "\n",
    "    \n",
    "    if demand == 'lower':\n",
    "        return print(table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_less/equal_than','total','rto_pct']].drop_duplicates())\n",
    "    else:\n",
    "        return print(table.loc[(table['total']>total_count_threshold)&(table['rto_pct']>rto_pct_threshold),:][['value_more/equal_than','total','rto_pct']].drop_duplicates())        \n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb213b51-9407-4586-8bd0-1823a16c9966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75fe5106",
   "metadata": {},
   "source": [
    "# how to work with yaml file for configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748175f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T21:28:58.000113Z",
     "start_time": "2022-07-12T21:28:57.979511Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"/Users/shubham_mantri/Downloads/Bureau RTO/credentials.yaml\", \"r\") as credentials:\n",
    "    try:\n",
    "        key = yaml.safe_load(credentials)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f1454b",
   "metadata": {},
   "source": [
    "# working with counter in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabfef7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T12:30:12.144555Z",
     "start_time": "2022-07-27T12:30:12.128695Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "list1 = ['x','y','z','x','x','x','y', 'z']\n",
    "counter = Counter(list1)\n",
    "print(counter)\n",
    "print(counter['x'])\n",
    "\n",
    "print(Counter(\"geeksforgeeks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b4b64",
   "metadata": {},
   "source": [
    "# working with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1200f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T17:24:00.968337Z",
     "start_time": "2022-07-25T17:24:00.960303Z"
    }
   },
   "outputs": [],
   "source": [
    "re.findall(\"h[is]{2,4}\",\"hisist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b6600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-25T17:27:39.711564Z",
     "start_time": "2022-07-25T17:27:39.702212Z"
    }
   },
   "outputs": [],
   "source": [
    "re.findall(\"\\w\",\"hisist34\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b262d-211e-4897-9b8e-b54851d98dde",
   "metadata": {},
   "source": [
    "# performance metrics for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0ff84-5b2f-4f05-8848-8eedc48b0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Test Metrics\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "def viz_classification_preds(probs, y_test):\n",
    "    '''look at prediction breakdown\n",
    "    '''\n",
    "    plt.subplot(121)\n",
    "    plt.hist(probs[:, 1][y_test==0], label='Not_RTO')\n",
    "    plt.hist(probs[:, 1][y_test==1], label='RTO', alpha=0.8)\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Predicted probability of RTO')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    plt.title('ROC curve')\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def pred_metrics(y_test, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.5)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='large') \n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Actuals', fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.show()\n",
    "    print('Actual RTO %: {:0.2f} %'.format((len(y_test[y_test==1])/len(y_test))*100))\n",
    "    print('Flagging Rate: {:0.2f} %'.format((len(y_pred[y_pred==1])/len(y_pred))*100))\n",
    "    print('Precision: {:0.3f}'.format(precision_score(y_test, y_pred)))\n",
    "    print('Recall: {:0.3f}'.format(recall_score(y_test, y_pred)))\n",
    "    print('Accuracy: {:0.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: {:0.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade49269-5e39-4a07-abe4-1080777f2145",
   "metadata": {},
   "source": [
    "# performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a2e91c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T10:21:43.178162Z",
     "start_time": "2022-07-27T10:21:43.156706Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = scaled_df.loc[:,scaled_df.columns[:-1]]\n",
    "y = scaled_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "def performance_metrics(model, X_test, y_test, X_train, y_train, threshold=0.5):\n",
    "    #y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    y_pred = [(y_prob[i][1]>=threshold)*1 for i in range(len(y_prob))]\n",
    "    #y_pred_train = model.predict(X_train)\n",
    "    y_prob_train = model.predict_proba(X_train)\n",
    "    y_pred_train = [(y_prob_train[i][1]>=threshold)*1 for i in range(len(y_prob_train))]\n",
    "    print(\"precision_test: \",precision_score(y_test,y_pred), \"|| precision_train: \",precision_score(y_train, y_pred_train))\n",
    "    print(\"recall_test: \",recall_score(y_test,y_pred), \"|| recall_train: \",recall_score(y_train, y_pred_train))\n",
    "    print(\"accuracy_test: \",accuracy_score(y_test,y_pred), \"|| accuracy_train: \",accuracy_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d952db5f",
   "metadata": {},
   "source": [
    "# Different classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be07c7",
   "metadata": {},
   "source": [
    "## svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c95d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T09:44:46.707197Z",
     "start_time": "2022-07-27T09:44:39.428763Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(probability=True)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "performance_metrics(model, X_test, y_test, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882571f7",
   "metadata": {},
   "source": [
    "## knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c4980",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T10:22:34.617601Z",
     "start_time": "2022-07-27T10:22:34.277860Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "performance_metrics(model, X_test, y_test, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a789b2",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294aaf5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T09:45:00.103301Z",
     "start_time": "2022-07-27T09:45:00.046956Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "performance_metrics(model, X_test, y_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d6fb6",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b61e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T10:04:06.563316Z",
     "start_time": "2022-07-27T10:04:06.491388Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=6)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "performance_metrics(model, X_test, y_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1d57e",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0445a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T12:31:13.106300Z",
     "start_time": "2022-07-27T12:31:12.093077Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=6)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "performance_metrics(model, X_test, y_test, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f1ef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T09:51:14.374895Z",
     "start_time": "2022-07-27T09:51:14.367245Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## multi layered perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77b5b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-27T10:02:07.416985Z",
     "start_time": "2022-07-27T10:01:22.511777Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "for i in range(5,25,5):\n",
    "    for j in range(5,25,5):\n",
    "        print(i,\",\",j)\n",
    "        model = MLPClassifier(hidden_layer_sizes=(i,j))\n",
    "        model.fit(X_train,y_train)\n",
    "        performance_metrics(model, X_test, y_test, X_train)\n",
    "        print(\"#\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fab680",
   "metadata": {},
   "source": [
    "# TSNE -> dimensionality reduction technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed00b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tsne to detect right number of numbers\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "X = trained_df_filtered[trained_df_filtered.columns[1:]]\n",
    "y = trained_df_filtered[0]\n",
    "tsne = TSNE()\n",
    "X_embedded = tsne.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08418247",
   "metadata": {},
   "source": [
    "# Kmeans clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9101bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering code snippet\n",
    "from sklearn.cluster import KMeans\n",
    "X = trained_df_filtered[trained_df_filtered.columns[1:]]\n",
    "y = trained_df_filtered[0]\n",
    "kmeans = KMeans(n_clusters=2,random_state=11).fit(X) #either 2 or 4\n",
    "print(kmeans.labels_)\n",
    "from collections import Counter\n",
    "print(Counter(kmeans.labels_))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace5067e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T06:44:58.247287Z",
     "start_time": "2022-08-02T06:44:58.237576Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_pincode(pin):\n",
    "    \"\"\"\n",
    "    this function cleans the pincode else return 0\n",
    "    \"\"\"\n",
    "    temp = [i for i in str(pin) if i.isnumeric()]\n",
    "    temp = \"\".join(temp)\n",
    "    try:\n",
    "        #         print(pin,\"-\",int(float(pin)))\n",
    "        if len(temp)==6:\n",
    "            print(temp)\n",
    "            return int(float(temp))\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9013b38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T06:48:27.874920Z",
     "start_time": "2022-08-02T06:48:27.869363Z"
    }
   },
   "outputs": [],
   "source": [
    "def name_check(name):\n",
    "    temp = \"\".join([i for i in str(name) if ((i.isalpha()==False) and (i!=\".\") and (i!=\" \"))])\n",
    "    print(temp)\n",
    "    return (0 if len(temp)>0 else 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13b3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T06:48:39.567423Z",
     "start_time": "2022-08-02T06:48:39.559906Z"
    }
   },
   "outputs": [],
   "source": [
    "name_check(\"Mr. SH@#@$ubha1m\")\n",
    "     \n",
    "name_check('Srinivasarao.ventapalli,annammagathi,,d/n 52-12-21,ganeshcolany,wardno22, turangi,, kakinadarural,kakinada,East Godavari Dist 533002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a55d9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T11:15:22.404259Z",
     "start_time": "2022-08-02T11:15:22.380098Z"
    }
   },
   "outputs": [],
   "source": [
    "def pin_city_state(pincode_map, pincode, city, state):\n",
    "    response = {'pin_check' : 0, 'pin_state_check' : 0, 'pin_city_check' : 0}\n",
    "    if str(pincode).isnumeric()==0:\n",
    "        return([response['pin_check'], response['pin_city_check'], response['pin_state_check']])\n",
    "    pincode = int(pincode)\n",
    "    match_ = pincode_map.loc[(pincode_map['pincode'] == pincode)]\n",
    "    \n",
    "    # pin_exists\n",
    "    if match_.shape[0] > 0:\n",
    "        response['pin_check'] = 1\n",
    "    else:\n",
    "        return([response['pin_check'], response['pin_city_check'], response['pin_state_check']])\n",
    "    # pin_state_match\n",
    "    print(match_['locality'])\n",
    "    print([x.lower() for x in catch_json(match_['locality'].values[0])])\n",
    "    if state and (state.strip().lower() == match_['statename'].values[0].strip().lower() or \\\n",
    "                  state.strip().lower() == match_['stateabbv'].values[0].strip().lower()):\n",
    "        response['pin_state_check'] = 1\n",
    "    # pin_city_match\n",
    "    if city and city.strip().lower() == match_['statename'].values[0].strip().lower(): # For cities like delhi\n",
    "        response['pin_city_check'] = 1\n",
    "    elif city and (np.max(np.array([fuzz.partial_ratio(city.strip().lower(),i) for i in match_['city'].str.lower().unique()]))>=75):\n",
    "        response['pin_city_check'] = 1\n",
    "    elif city and city.strip().lower() in [x.lower() for x in catch_json(match_['locality'].values[0])]:\n",
    "        response['pin_city_check'] = 1\n",
    "    #print(match_)\n",
    "    return([response['pin_check'], response['pin_city_check'], response['pin_state_check']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd467395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-02T08:18:20.291955Z",
     "start_time": "2022-08-02T08:18:20.285731Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "def catch_json(js):\n",
    "    try:\n",
    "        js = ast.literal_eval(js)\n",
    "        return js\n",
    "    except:\n",
    "        return js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbc30d-58b9-4958-bd81-763c502c432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0b16c5-1401-4f8a-9847-b1d33e9cfe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
